# Chapter 13: Self-Healing AI ì‹œìŠ¤í…œ

> "ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ìŠ¤ìŠ¤ë¡œ ì¹˜ìœ í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤." â€” Netflix Engineering Team

## ê°œìš”

ì´ ì±•í„°ì—ì„œëŠ” ìê°€ ì¹˜ìœ  AI ì‹œìŠ¤í…œ(Self-Healing AI Systems)ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. GitHub, Google DeepMind, Netflixê°€ ì‹¤ì „ ë°°í¬í•œ ì‹œìŠ¤í…œì„ ë¶„ì„í•˜ê³ , LangGraphë¥¼ í™œìš©í•œ ì‹¤ì „ êµ¬í˜„ ë°©ë²•ì„ ìµí™ë‹ˆë‹¤.

### ì´ ì±•í„°ì—ì„œ ë°°ìš¸ ê²ƒ

- Self-Healing AI ì‹œìŠ¤í…œì˜ 5ë‹¨ê³„ ì‚¬ì´í´ ì´í•´
- Error Detectionë¶€í„° Learningê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- LangGraphë¡œ ììœ¨ ë³µêµ¬ ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
- ì‹¤ì „ ì‚¬ë¡€ ë¶„ì„ (GitHub, Google, Netflix)
- í•œê³„ì™€ í•´ê²°ì±… ì´í•´

### í•„ìš”í•œ ì‚¬ì „ ì§€ì‹

- Python ê¸°ë³¸ ë¬¸ë²•
- LLM API ì‚¬ìš© ê²½í—˜ (OpenAI, Anthropic ë“±)
- Git ë° GitHub ê¸°ë³¸ ì§€ì‹
- ê¸°ë³¸ì ì¸ DevOps ê°œë…

---

## Recipe 13.1: Self-Healing ê°œë… ì´í•´

### ë¬¸ì œ (Problem)

ì „í†µì ì¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ ì—ëŸ¬ë¥¼ ê°ì§€í•˜ë©´ ì—”ì§€ë‹ˆì–´ì—ê²Œ ì•Œë¦¼ì„ ë³´ë‚´ê³ , ì‚¬ëŒì´ ìˆ˜ë™ìœ¼ë¡œ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€:

- <strong>í‰ê·  ë³µêµ¬ ì‹œê°„(MTTR)</strong>ì´ ìˆ˜ ì‹œê°„ì—ì„œ ìˆ˜ì¼
- ì•¼ê°„/ì£¼ë§ ì¥ì•  ì‹œ ëŒ€ì‘ ì§€ì—°
- ë°˜ë³µì ì¸ ë™ì¼ ë¬¸ì œì— ë§¤ë²ˆ ìˆ˜ë™ ëŒ€ì‘
- ì¸ë ¥ ì˜ì¡´ìœ¼ë¡œ í™•ì¥ì„± ë¶€ì¡±

### í•´ê²°ì±… (Solution)

ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œì€ **ê°ì§€ â†’ ë¶„ì„ â†’ ìˆ˜ì • â†’ ë°°í¬**ë¥¼ ì™„ì „ ììœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

#### 5ë‹¨ê³„ ì‚¬ì´í´

```mermaid
graph TD
    A[1. Error Detection<br/>ì—ëŸ¬ ê°ì§€] --> B[2. Root Cause Analysis<br/>ê·¼ë³¸ ì›ì¸ ë¶„ì„]
    B --> C[3. Fix Generation<br/>íŒ¨ì¹˜ ìƒì„±]
    C --> D[4. Testing<br/>í…ŒìŠ¤íŠ¸]
    D --> E{í†µê³¼?}
    E -->|ì‹¤íŒ¨| F[Self-Correction<br/>ìì²´ ìˆ˜ì •]
    F --> D
    E -->|ì„±ê³µ| G[5. Learning & Deployment<br/>í•™ìŠµ ë° ë°°í¬]
    E -->|3íšŒ ì‹¤íŒ¨| H[Rollback<br/>ë¡¤ë°±]
```

ê° ë‹¨ê³„ì˜ ì—­í• :

1. <strong>Error Detection</strong>: ì´ìƒ ì§•í›„ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€
2. <strong>Root Cause Analysis</strong>: ì—ëŸ¬ì˜ ê·¼ë³¸ ì›ì¸ì„ LLMìœ¼ë¡œ ë¶„ì„
3. <strong>Fix Generation</strong>: ìë™ìœ¼ë¡œ ìˆ˜ì • ì½”ë“œ ìƒì„±
4. <strong>Testing</strong>: ìˆ˜ì • ì‚¬í•­ì„ ê²€ì¦í•˜ê³ , ì‹¤íŒ¨ ì‹œ ìì²´ ìˆ˜ì •
5. <strong>Learning & Deployment</strong>: ì„±ê³µí•œ ìˆ˜ì •ì„ ë°°í¬í•˜ê³  í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### ì „í†µì  ë°©ì‹ vs Self-Healing ë¹„êµ

```python
# âŒ ì „í†µì  ëª¨ë‹ˆí„°ë§: ê°ì§€ë§Œ í•˜ê³  ìˆ˜ë™ ìˆ˜ì •
def traditional_monitoring():
    if error_detected():
        send_alert_to_engineer()  # ì‚¬ëŒì´ ê¹¨ì–´ë‚˜ ìˆ˜ë™ ìˆ˜ì •
        wait_for_fix()            # ë‹¤ìš´íƒ€ì„ ë°œìƒ
        # MTTR: ìˆ˜ ì‹œê°„ ã€œ ìˆ˜ì¼

# âœ… Self-Healing: ê°ì§€ â†’ ë¶„ì„ â†’ ìˆ˜ì • â†’ ë°°í¬ (ìë™)
async def self_healing_monitor():
    while True:
        if error := detect_anomaly():
            # 1. ê·¼ë³¸ ì›ì¸ ë¶„ì„
            root_cause = await analyze_error(error)

            # 2. íŒ¨ì¹˜ ìƒì„±
            fix = await generate_patch(root_cause)

            # 3. í…ŒìŠ¤íŠ¸
            if await test_fix(fix):
                # 4. ë°°í¬
                await deploy(fix)

                # 5. í•™ìŠµ
                await learn_from_fix(fix)
            else:
                # ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ì ‘ê·¼ë²• ì‹œë„
                await retry_with_different_approach()

        await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
```

### ì„¤ëª… (Explanation)

#### ì™œ ì§€ê¸ˆ Self-Healing ì‹œìŠ¤í…œì¸ê°€?

<strong>ì‹œì¥ ê·œëª¨</strong>:
- AI ì‹œì¥: 2030ë…„ê¹Œì§€ $826.70B ì˜ˆìƒ
- AIOps í”Œë«í¼: 2023ë…„ $11.7B â†’ 2028ë…„ $32.4B (3ë°° ì„±ì¥)

<strong>ì±„íƒ í˜„í™©</strong> (2025ë…„ ê¸°ì¤€):
- <strong>GitHub</strong>: í•˜ë£¨ 4ì²œë§Œ ê°œ ì‘ì—…ì—ì„œ ìê°€ ì¹˜ìœ  ì—ì´ì „íŠ¸ ìš´ì˜
- <strong>Google DeepMind</strong>: CodeMenderê°€ 6ê°œì›”ê°„ 72ê°œ ë³´ì•ˆ íŒ¨ì¹˜ ìë™ ê¸°ì—¬
- <strong>Netflix</strong>: 270M ì‚¬ìš©ì ëŒ€ìƒ 99.99% ê°€ë™ë¥  ìœ ì§€
- <strong>Meta</strong>: AutoPatchBench ë²¤ì¹˜ë§ˆí¬ë¡œ í‘œì¤€í™” ì£¼ë„

#### Self-Healingì˜ í•µì‹¬ ì¥ì 

| í•­ëª© | ì „í†µì  ë°©ì‹ | Self-Healing |
|------|------------|--------------|
| MTTR | ìˆ˜ ì‹œê°„ ã€œ ìˆ˜ì¼ | <strong>ìˆ˜ ë¶„ ì´ë‚´</strong> |
| ìš´ì˜ ì‹œê°„ | ì—…ë¬´ ì‹œê°„ë§Œ | <strong>24/7 ììœ¨ ìš´ì˜</strong> |
| ì¬ë°œ ëŒ€ì‘ | ë§¤ë²ˆ ìˆ˜ë™ ìˆ˜ì • | <strong>ì¦‰ì‹œ ìë™ í•´ê²°</strong> |
| í™•ì¥ì„± | ì¸ë ¥ ì˜ì¡´ | <strong>ë¬´í•œ í™•ì¥ ê°€ëŠ¥</strong> |

### ë³€í˜• (Variations)

#### 1. ë¶€ë¶„ ììœ¨ ì‹œìŠ¤í…œ (Human-in-the-Loop)

ì™„ì „ ììœ¨ì´ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ë©´ ì‹ ë¢°ë„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ëŒ ê²€ì¦ì„ ì¶”ê°€:

```python
async def hybrid_self_healing(error):
    fix = await generate_fix(error)

    if fix.confidence >= 0.9:
        # ë†’ì€ ì‹ ë¢°ë„: ìë™ ë°°í¬
        await auto_deploy(fix)
    elif fix.confidence >= 0.7:
        # ì¤‘ê°„ ì‹ ë¢°ë„: ë¹„ë™ê¸° ë¦¬ë·° ìš”ì²­
        await request_human_review(fix)
    else:
        # ë‚®ì€ ì‹ ë¢°ë„: í•„ìˆ˜ ìŠ¹ì¸
        await block_until_approved(fix)
```

#### 2. ë„ë©”ì¸ íŠ¹í™” Self-Healing

íŠ¹ì • ë„ë©”ì¸ì—ë§Œ ì ìš©:

- <strong>ë³´ì•ˆ íŒ¨ì¹˜</strong>: Google CodeMender ë°©ì‹
- <strong>ì„±ëŠ¥ ìµœì í™”</strong>: Netflix Auto-Scaling
- <strong>í…ŒìŠ¤íŠ¸ ìˆ˜ì •</strong>: GitHub CI/CD íŒŒì´í”„ë¼ì¸

---

## Recipe 13.2: Error Detection êµ¬í˜„

### ë¬¸ì œ (Problem)

Self-Healingì˜ ì²« ë‹¨ê³„ëŠ” ì—ëŸ¬ë¥¼ ì •í™•í•˜ê²Œ ê°ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ë„ì „ ê³¼ì œê°€ ìˆìŠµë‹ˆë‹¤:

- ì •ìƒ ë™ì‘ê³¼ ì´ìƒ ì§•í›„ë¥¼ ì–´ë–»ê²Œ êµ¬ë¶„í•  ê²ƒì¸ê°€?
- ê°„í—ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ì–´ë–»ê²Œ í¬ì°©í•  ê²ƒì¸ê°€?
- ê±°ì§“ ì–‘ì„±(False Positive)ì„ ì–´ë–»ê²Œ ì¤„ì¼ ê²ƒì¸ê°€?

### í•´ê²°ì±… (Solution)

3ê°€ì§€ ë°©ë²•ë¡ ì„ ì¡°í•©í•©ë‹ˆë‹¤:

1. <strong>ì´ìƒ íƒì§€ (Anomaly Detection)</strong>: ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ ì •ìƒ íŒ¨í„´ í•™ìŠµ
2. <strong>ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§</strong>: Prometheus, Datadog ë“±ìœ¼ë¡œ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
3. <strong>ì‹œë§¨í‹± ë¶„ì„</strong>: CodeQLë¡œ ì •ì  ì½”ë“œ ë¶„ì„

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### 1. ì´ìƒ íƒì§€ (Isolation Forest)

```python
from sklearn.ensemble import IsolationForest
import numpy as np

class AnomalyDetector:
    def __init__(self, contamination=0.1):
        """
        contamination: ì´ìƒì¹˜ ë¹„ìœ¨ (0.1 = 10%)
        """
        self.model = IsolationForest(
            contamination=contamination,
            random_state=42
        )
        self.is_trained = False

    def train(self, normal_metrics):
        """ì •ìƒ ë©”íŠ¸ë¦­ìœ¼ë¡œ í•™ìŠµ

        Args:
            normal_metrics: shape (n_samples, n_features)
                ì˜ˆ: [[cpu, memory, latency], ...]
        """
        self.model.fit(normal_metrics)
        self.is_trained = True

    def detect(self, current_metrics):
        """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ë¶„ì„

        Returns:
            True: ì´ìƒ ê°ì§€
            False: ì •ìƒ
        """
        if not self.is_trained:
            raise RuntimeError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        prediction = self.model.predict([current_metrics])
        return prediction[0] == -1  # -1 = ì´ìƒ, 1 = ì •ìƒ

# ì‚¬ìš© ì˜ˆì‹œ
detector = AnomalyDetector()

# 1ì£¼ì¼ê°„ ì •ìƒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
normal_data = [
    [20.5, 512, 0.15],  # [cpu%, memory_mb, latency_sec]
    [22.1, 530, 0.18],
    # ... ìˆ˜ì²œ ê°œ ìƒ˜í”Œ
]
detector.train(normal_data)

# ì‹¤ì‹œê°„ ê°ì§€
current = [85.3, 1024, 2.5]  # CPU ê¸‰ì¦, ë©”ëª¨ë¦¬ ì¦ê°€, ì§€ì—° ì¦ê°€
if detector.detect(current):
    print("âš ï¸ ì´ìƒ ê°ì§€! Self-Healing ì‹œì‘")
```

#### 2. ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§ (Prometheus)

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
import random

# ë©”íŠ¸ë¦­ ì •ì˜
error_counter = Counter(
    'app_errors_total',
    'Total number of errors',
    ['error_type']
)

response_time = Histogram(
    'http_response_time_seconds',
    'HTTP response time in seconds',
    ['endpoint']
)

active_connections = Gauge(
    'active_connections',
    'Number of active connections'
)

# FastAPI/Flask ì˜ˆì‹œ
from fastapi import FastAPI, Request
import asyncio

app = FastAPI()

@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    """ëª¨ë“  ìš”ì²­ ëª¨ë‹ˆí„°ë§"""

    # í™œì„± ì—°ê²° ì¦ê°€
    active_connections.inc()

    # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    start = time.time()

    try:
        response = await call_next(request)

        # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
        duration = time.time() - start
        response_time.labels(endpoint=request.url.path).observe(duration)

        return response

    except Exception as e:
        # ì—ëŸ¬ ì¹´ìš´íŠ¸
        error_counter.labels(error_type=type(e).__name__).inc()
        raise

    finally:
        # í™œì„± ì—°ê²° ê°ì†Œ
        active_connections.dec()

@app.get("/api/users")
async def get_users():
    # ì˜ë„ì ìœ¼ë¡œ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    if random.random() < 0.1:  # 10% í™•ë¥ ë¡œ ëŠë¦° ì‘ë‹µ
        await asyncio.sleep(2)

    if random.random() < 0.05:  # 5% í™•ë¥ ë¡œ ì—ëŸ¬
        raise ValueError("Database connection failed")

    return {"users": []}

# Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ (í¬íŠ¸ 8000)
if __name__ == "__main__":
    start_http_server(8000)
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)
```

#### 3. ì‹œë§¨í‹± ë¶„ì„ (CodeQL)

```ql
// CodeQL ì¿¼ë¦¬: SQL ì¸ì ì…˜ ì·¨ì•½ì  íƒì§€
import python

from StringLiteral sql, Call query_call, StringFormatting fmt
where
  // execute() í•¨ìˆ˜ í˜¸ì¶œì„ ì°¾ìŒ
  query_call.getFunc().getName() = "execute" and

  // ì²« ë²ˆì§¸ ì¸ìê°€ SQL ë¬¸ìì—´
  sql.getParentNode*() = query_call.getArg(0) and

  // ë¬¸ìì—´ í¬ë§·íŒ… ì‚¬ìš© (ì·¨ì•½ì !)
  fmt.getASubExpression*() = sql

select query_call,
  "SQL injection vulnerability detected: unsanitized user input in query"
```

Python ì½”ë“œ ì˜ˆì‹œ (ì·¨ì•½í•œ ì½”ë“œ):

```python
# âŒ ì·¨ì•½í•œ ì½”ë“œ (CodeQLì´ íƒì§€)
def get_user(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"  # ìœ„í—˜!
    cursor.execute(query)
    return cursor.fetchone()

# âœ… ì•ˆì „í•œ ì½”ë“œ
def get_user_safe(user_id):
    query = "SELECT * FROM users WHERE id = %s"  # íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬
    cursor.execute(query, (user_id,))
    return cursor.fetchone()
```

#### 4. í†µí•© ì—ëŸ¬ ê°ì§€ ì‹œìŠ¤í…œ

```python
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ErrorEvent:
    timestamp: datetime
    source: str  # 'anomaly', 'runtime', 'static'
    severity: str  # 'low', 'medium', 'high', 'critical'
    message: str
    metadata: Dict

class IntegratedErrorDetector:
    def __init__(self):
        self.anomaly_detector = AnomalyDetector()
        self.error_history: List[ErrorEvent] = []

    async def monitor(self):
        """3ê°€ì§€ ë°©ë²•ë¡  í†µí•© ëª¨ë‹ˆí„°ë§"""

        while True:
            errors = []

            # 1. ì´ìƒ íƒì§€
            current_metrics = await self.get_current_metrics()
            if self.anomaly_detector.detect(current_metrics):
                errors.append(ErrorEvent(
                    timestamp=datetime.now(),
                    source='anomaly',
                    severity='high',
                    message='Anomaly detected in system metrics',
                    metadata={'metrics': current_metrics}
                ))

            # 2. ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§
            prometheus_alerts = await self.check_prometheus_alerts()
            for alert in prometheus_alerts:
                errors.append(ErrorEvent(
                    timestamp=datetime.now(),
                    source='runtime',
                    severity=alert['severity'],
                    message=alert['summary'],
                    metadata=alert
                ))

            # 3. ì‹œë§¨í‹± ë¶„ì„ (ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰)
            if datetime.now().hour == 2:  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
                codeql_results = await self.run_codeql_scan()
                for issue in codeql_results:
                    errors.append(ErrorEvent(
                        timestamp=datetime.now(),
                        source='static',
                        severity='critical',
                        message=f'Security vulnerability: {issue["type"]}',
                        metadata=issue
                    ))

            # ì—ëŸ¬ ë°œê²¬ ì‹œ Self-Healing íŠ¸ë¦¬ê±°
            if errors:
                await self.trigger_self_healing(errors)

            await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

    async def get_current_metrics(self) -> List[float]:
        """í˜„ì¬ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # ì‹¤ì œ êµ¬í˜„: Prometheus API í˜¸ì¶œ
        return [45.2, 768, 0.25]  # [cpu%, memory_mb, latency_sec]

    async def check_prometheus_alerts(self) -> List[Dict]:
        """Prometheus ì•Œë¦¼ í™•ì¸"""
        # ì‹¤ì œ êµ¬í˜„: Prometheus Alertmanager API
        return []

    async def run_codeql_scan(self) -> List[Dict]:
        """CodeQL ìŠ¤ìº” ì‹¤í–‰"""
        # ì‹¤ì œ êµ¬í˜„: CodeQL CLI í˜¸ì¶œ
        return []

    async def trigger_self_healing(self, errors: List[ErrorEvent]):
        """Self-Healing í”„ë¡œì„¸ìŠ¤ ì‹œì‘"""
        print(f"ğŸš¨ {len(errors)}ê°œ ì—ëŸ¬ ê°ì§€, Self-Healing ì‹œì‘")
        for error in errors:
            print(f"  - [{error.severity}] {error.message}")
        # ë‹¤ìŒ ë ˆì‹œí”¼ì—ì„œ êµ¬í˜„
```

### ì„¤ëª… (Explanation)

#### ê° ë°©ë²•ë¡ ì˜ ì¥ë‹¨ì 

| ë°©ë²• | ì¥ì  | ë‹¨ì  | ì ìš© ì‹œê¸° |
|------|------|------|----------|
| <strong>ì´ìƒ íƒì§€</strong> | ì•Œë ¤ì§€ì§€ ì•Šì€ íŒ¨í„´ ë°œê²¬ | ê±°ì§“ ì–‘ì„± ê°€ëŠ¥ | íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„ |
| <strong>ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§</strong> | ì‹¤ì‹œê°„, ì •í™•í•¨ | ë©”íŠ¸ë¦­ ì •ì˜ í•„ìš” | ì•Œë ¤ì§„ ë¬¸ì œ ê°ì§€ |
| <strong>ì‹œë§¨í‹± ë¶„ì„</strong> | ë°°í¬ ì „ ë°œê²¬ | ëŠë¦¼, ì •ì  ë¶„ì„ í•œê³„ | ë³´ì•ˆ, ì½”ë“œ í’ˆì§ˆ |

#### ê±°ì§“ ì–‘ì„± ì¤„ì´ê¸°

```python
class SmartAlertingSystem:
    def __init__(self, threshold=3):
        self.threshold = threshold  # 3ë²ˆ ì—°ì† ë°œìƒ ì‹œì—ë§Œ ì•Œë¦¼
        self.error_counts = {}

    async def should_alert(self, error_signature: str) -> bool:
        """ì—°ì† ë°œìƒ íšŸìˆ˜ ê¸°ë°˜ ì•Œë¦¼"""

        self.error_counts[error_signature] = \
            self.error_counts.get(error_signature, 0) + 1

        if self.error_counts[error_signature] >= self.threshold:
            # ì•Œë¦¼ í›„ ì¹´ìš´í„° ë¦¬ì…‹
            self.error_counts[error_signature] = 0
            return True

        return False
```

### ë³€í˜• (Variations)

#### 1. í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ëª¨ë‹ˆí„°ë§

```python
# AWS CloudWatch í†µí•©
import boto3

cloudwatch = boto3.client('cloudwatch')

def check_cloudwatch_alarms():
    response = cloudwatch.describe_alarms(
        StateValue='ALARM'
    )

    return response['MetricAlarms']

# Datadog í†µí•©
from datadog import api, initialize

initialize(api_key='YOUR_API_KEY', app_key='YOUR_APP_KEY')

def check_datadog_monitors():
    monitors = api.Monitor.get_all(
        group_states='alert'
    )

    return monitors
```

#### 2. ë¡œê·¸ ê¸°ë°˜ ì—ëŸ¬ ê°ì§€

```python
import re
from collections import defaultdict

class LogBasedDetector:
    ERROR_PATTERNS = [
        r'ERROR',
        r'FATAL',
        r'Exception',
        r'Traceback',
        r'ConnectionRefusedError'
    ]

    def __init__(self, log_file: str):
        self.log_file = log_file
        self.error_counts = defaultdict(int)

    async def monitor_logs(self):
        """ë¡œê·¸ íŒŒì¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""

        with open(self.log_file, 'r') as f:
            # íŒŒì¼ ëìœ¼ë¡œ ì´ë™
            f.seek(0, 2)

            while True:
                line = f.readline()

                if not line:
                    await asyncio.sleep(0.1)
                    continue

                # ì—ëŸ¬ íŒ¨í„´ ë§¤ì¹­
                for pattern in self.ERROR_PATTERNS:
                    if re.search(pattern, line):
                        self.error_counts[pattern] += 1

                        if self.error_counts[pattern] >= 5:
                            yield ErrorEvent(
                                timestamp=datetime.now(),
                                source='logs',
                                severity='high',
                                message=f'Pattern {pattern} detected 5+ times',
                                metadata={'line': line}
                            )
```

---

## Recipe 13.3: Root Cause Analysis

### ë¬¸ì œ (Problem)

ì—ëŸ¬ë¥¼ ê°ì§€í–ˆë‹¤ë©´, ë‹¤ìŒ ë‹¨ê³„ëŠ” <strong>ê·¼ë³¸ ì›ì¸(Root Cause)</strong>ì„ íŒŒì•…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¨ìˆœíˆ ì¦ìƒë§Œ ë³´ê³  ìˆ˜ì •í•˜ë©´:

- ì„ì‹œë°©í¸ì— ê·¸ì³ ê°™ì€ ë¬¸ì œê°€ ì¬ë°œ
- ì˜ëª»ëœ ìˆ˜ì •ìœ¼ë¡œ ìƒˆë¡œìš´ ë²„ê·¸ ë„ì…
- ì‹œìŠ¤í…œ ì „ì²´ ì´í•´ ë¶€ì¡±

### í•´ê²°ì±… (Solution)

LLM(Large Language Model)ì„ í™œìš©í•˜ì—¬ ì—ëŸ¬ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³  ê·¼ë³¸ ì›ì¸ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.

#### ë¶„ì„ì— í•„ìš”í•œ ì •ë³´

1. <strong>ì—ëŸ¬ ë©”ì‹œì§€</strong>: ì§ì ‘ì ì¸ ì˜¤ë¥˜ ë‚´ìš©
2. <strong>ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤</strong>: í˜¸ì¶œ ê²½ë¡œ
3. <strong>ê´€ë ¨ ì½”ë“œ</strong>: ì—ëŸ¬ ë°œìƒ ì§€ì ì˜ ì½”ë“œ
4. <strong>ìµœê·¼ ë³€ê²½ì‚¬í•­</strong>: Git ì»¤ë°‹ íˆìŠ¤í† ë¦¬
5. <strong>ì‹œìŠ¤í…œ ìƒíƒœ</strong>: ë©”íŠ¸ë¦­, ë¡œê·¸

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### 1. LLM ê¸°ë°˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„ê¸°

```python
from openai import AsyncOpenAI
from anthropic import Anthropic
from typing import Dict, Any
import json

class RootCauseAnalyzer:
    def __init__(self, provider='openai'):
        """
        Args:
            provider: 'openai' ë˜ëŠ” 'anthropic'
        """
        if provider == 'openai':
            self.client = AsyncOpenAI()
            self.model = "gpt-4-turbo-preview"
        else:
            self.client = Anthropic()
            self.model = "claude-3-5-sonnet-20241022"

        self.provider = provider

    async def analyze(self, error_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì—ëŸ¬ ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ë¶„ì„

        Args:
            error_data: {
                'message': str,
                'stack_trace': str,
                'code_snippet': str,
                'recent_commits': List[str],
                'metrics': Dict
            }

        Returns:
            {
                'root_cause': str,
                'affected_files': List[str],
                'fix_strategy': str,
                'confidence': float  # 0ã€œ1
            }
        """

        prompt = self._build_analysis_prompt(error_data)

        if self.provider == 'openai':
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—ëŸ¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                                   "ê·¼ë³¸ ì›ì¸ì„ ì°¾ê³  ìˆ˜ì • ì „ëµì„ ì œì‹œí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,  # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ë‚®ì€ temperature
                response_format={"type": "json_object"}
            )

            analysis = json.loads(response.choices[0].message.content)

        else:  # Anthropic
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                temperature=0.1,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # JSON íŒŒì‹±
            analysis = json.loads(response.content[0].text)

        return analysis

    def _build_analysis_prompt(self, error_data: Dict[str, Any]) -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        return f"""
ë‹¤ìŒ ì—ëŸ¬ë¥¼ ë¶„ì„í•˜ì—¬ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”:

## ì—ëŸ¬ ë©”ì‹œì§€
{error_data.get('message', 'N/A')}

## ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤
```
{error_data.get('stack_trace', 'N/A')}
```

## ê´€ë ¨ ì½”ë“œ
```python
{error_data.get('code_snippet', 'N/A')}
```

## ìµœê·¼ ë³€ê²½ì‚¬í•­ (Git Commits)
{self._format_commits(error_data.get('recent_commits', []))}

## ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
{json.dumps(error_data.get('metrics', {}), indent=2)}

---

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”:

{{
  "root_cause": "ê·¼ë³¸ ì›ì¸ì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª…",
  "affected_files": ["ì˜í–¥ë°›ëŠ” íŒŒì¼ ê²½ë¡œë“¤"],
  "fix_strategy": "ìˆ˜ì • ì „ëµ (ë‹¨ê³„ë³„ë¡œ)",
  "confidence": 0.85,
  "additional_context": "ì¶”ê°€ ë§¥ë½ ì •ë³´"
}}
"""

    def _format_commits(self, commits: list) -> str:
        """ì»¤ë°‹ ëª©ë¡ì„ ì½ê¸° ì‰½ê²Œ í¬ë§·"""

        if not commits:
            return "ìµœê·¼ ë³€ê²½ì‚¬í•­ ì—†ìŒ"

        formatted = []
        for commit in commits:
            formatted.append(f"- {commit['hash'][:7]}: {commit['message']}")

        return "\n".join(formatted)

# ì‚¬ìš© ì˜ˆì‹œ
async def analyze_database_error():
    analyzer = RootCauseAnalyzer(provider='openai')

    error_data = {
        'message': 'psycopg2.OperationalError: connection pool exhausted',
        'stack_trace': '''
Traceback (most recent call last):
  File "app.py", line 42, in get_users
    conn = db_pool.getconn()
  File "psycopg2/pool.py", line 137, in getconn
    raise PoolError("connection pool exhausted")
''',
        'code_snippet': '''
async def get_users(request):
    conn = db_pool.getconn()  # ì—°ê²° íšë“
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM users")
        return cursor.fetchall()
    finally:
        pass  # BUG: connection not returned!
''',
        'recent_commits': [
            {
                'hash': 'a1b2c3d',
                'message': 'feat: add user list endpoint'
            }
        ],
        'metrics': {
            'active_connections': 20,
            'max_connections': 20,
            'requests_per_minute': 150
        }
    }

    analysis = await analyzer.analyze(error_data)

    print("ğŸ“Š ê·¼ë³¸ ì›ì¸ ë¶„ì„ ê²°ê³¼:")
    print(f"ê·¼ë³¸ ì›ì¸: {analysis['root_cause']}")
    print(f"ì˜í–¥ íŒŒì¼: {', '.join(analysis['affected_files'])}")
    print(f"ìˆ˜ì • ì „ëµ: {analysis['fix_strategy']}")
    print(f"ì‹ ë¢°ë„: {analysis['confidence']*100:.1f}%")

# ì‹¤í–‰
if __name__ == "__main__":
    import asyncio
    asyncio.run(analyze_database_error())
```

#### 2. ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ

ìœ„ ì½”ë“œ ì‹¤í–‰ ì‹œ LLMì´ ë°˜í™˜í•˜ëŠ” ë¶„ì„ ê²°ê³¼:

```json
{
  "root_cause": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ê³ ê°ˆë˜ì—ˆìŠµë‹ˆë‹¤. ì›ì¸ì€ `get_users()` í•¨ìˆ˜ì—ì„œ ì—°ê²°ì„ íšë“í•œ í›„ ë°˜í™˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. finally ë¸”ë¡ì— `db_pool.putconn(conn)` í˜¸ì¶œì´ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",

  "affected_files": [
    "app.py"
  ],

  "fix_strategy": "1. `get_users()` í•¨ìˆ˜ì˜ finally ë¸”ë¡ì— `db_pool.putconn(conn)` ì¶”ê°€\n2. ë” ë‚˜ì€ ë°©ë²•: ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš© (`with db_pool.getconn() as conn`)\n3. ì—°ê²° í’€ í¬ê¸°ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë©”íŠ¸ë¦­ ì¶”ê°€\n4. íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€",

  "confidence": 0.95,

  "additional_context": "ë©”íŠ¸ë¦­ì—ì„œ active_connectionsê°€ max_connectionsì™€ ë™ì¼í•˜ë¯€ë¡œ í’€ì´ ì™„ì „íˆ ê³ ê°ˆëœ ìƒíƒœì…ë‹ˆë‹¤. ìµœê·¼ ì»¤ë°‹ì—ì„œ ì¶”ê°€ëœ ì—”ë“œí¬ì¸íŠ¸ê°€ ë¬¸ì œì˜ ì›ì¸ì¼ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤."
}
```

### ì„¤ëª… (Explanation)

#### LLMì´ ê·¼ë³¸ ì›ì¸ ë¶„ì„ì— ìœ ìš©í•œ ì´ìœ 

1. <strong>ë§¥ë½ ì´í•´</strong>: ì—ëŸ¬ ë©”ì‹œì§€, ì½”ë“œ, ë³€ê²½ì‚¬í•­ì„ ì¢…í•© ë¶„ì„
2. <strong>íŒ¨í„´ ì¸ì‹</strong>: ìˆ˜ë°±ë§Œ ê°œ ì½”ë“œì—ì„œ í•™ìŠµí•œ ì¼ë°˜ì ì¸ ë²„ê·¸ íŒ¨í„´ ì¸ì‹
3. <strong>ì¶”ë¡  ëŠ¥ë ¥</strong>: ì§ì ‘ì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ì›ì¸ë„ ì¶”ë¡  ê°€ëŠ¥
4. <strong>ì„¤ëª… ìƒì„±</strong>: ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ì œê³µ

#### ì‹ ë¢°ë„ ì ìˆ˜ í™œìš©

```python
def decide_action_based_on_confidence(analysis):
    """ì‹ ë¢°ë„ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""

    confidence = analysis['confidence']

    if confidence >= 0.9:
        print("âœ… ë†’ì€ ì‹ ë¢°ë„: ìë™ ìˆ˜ì • ì§„í–‰")
        return 'auto_fix'

    elif confidence >= 0.7:
        print("âš ï¸ ì¤‘ê°„ ì‹ ë¢°ë„: ìˆ˜ì • ìƒì„± í›„ ë¦¬ë·° ìš”ì²­")
        return 'generate_and_review'

    else:
        print("âŒ ë‚®ì€ ì‹ ë¢°ë„: ì‚¬ëŒ ê°œì… í•„ìš”")
        return 'escalate_to_human'
```

### ë³€í˜• (Variations)

#### 1. ë©€í‹° ëª¨ë¸ ì•™ìƒë¸” ë¶„ì„

ì—¬ëŸ¬ LLMì˜ ë¶„ì„ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ í–¥ìƒ:

```python
class EnsembleRootCauseAnalyzer:
    def __init__(self):
        self.analyzers = [
            RootCauseAnalyzer(provider='openai'),
            RootCauseAnalyzer(provider='anthropic'),
        ]

    async def analyze_with_ensemble(self, error_data):
        """ì—¬ëŸ¬ ëª¨ë¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©"""

        # ë³‘ë ¬ë¡œ ë¶„ì„ ì‹¤í–‰
        analyses = await asyncio.gather(*[
            analyzer.analyze(error_data)
            for analyzer in self.analyzers
        ])

        # í•©ì˜ ë¶„ì„ (ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ê·¼ë³¸ ì›ì¸)
        root_causes = [a['root_cause'] for a in analyses]

        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = sum(a['confidence'] for a in analyses) / len(analyses)

        return {
            'consensus_root_cause': self._find_consensus(root_causes),
            'all_analyses': analyses,
            'avg_confidence': avg_confidence
        }

    def _find_consensus(self, root_causes):
        """ê°€ì¥ ì¼ê´€ëœ ê·¼ë³¸ ì›ì¸ ì°¾ê¸°"""
        # ì‹¤ì œ êµ¬í˜„: ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ë¹„êµ
        return root_causes[0]  # ë‹¨ìˆœí™”
```

#### 2. ê³¼ê±° ì‚¬ë¡€ ê¸°ë°˜ ë¶„ì„ (RAG)

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

class RAGRootCauseAnalyzer:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            collection_name="past_errors",
            embedding_function=self.embeddings
        )

    async def analyze_with_history(self, error_data):
        """ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¸ì¡°í•˜ì—¬ ë¶„ì„"""

        # 1. ìœ ì‚¬í•œ ê³¼ê±° ì—ëŸ¬ ê²€ìƒ‰
        similar_cases = self.vector_store.similarity_search(
            query=error_data['message'],
            k=3
        )

        # 2. ê³¼ê±° ì‚¬ë¡€ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨
        enhanced_prompt = f"""
ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€:
{self._format_similar_cases(similar_cases)}

í˜„ì¬ ì—ëŸ¬:
{error_data['message']}

ê³¼ê±° ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ ê·¼ë³¸ ì›ì¸ì„ ë¶„ì„í•˜ì„¸ìš”.
"""

        # 3. LLM ë¶„ì„
        analysis = await self.client.generate(enhanced_prompt)

        return analysis

    def save_successful_fix(self, error_data, fix_data):
        """ì„±ê³µí•œ ìˆ˜ì • ì‚¬ë¡€ ì €ì¥ (í•™ìŠµ)"""

        self.vector_store.add_texts(
            texts=[error_data['message']],
            metadatas=[{
                'root_cause': fix_data['root_cause'],
                'solution': fix_data['code'],
                'timestamp': datetime.now().isoformat()
            }]
        )
```

---

## Recipe 13.4: Fix Generation ìë™í™”

### ë¬¸ì œ (Problem)

ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í–ˆë‹¤ë©´, ì´ì œ ì‹¤ì œ <strong>ìˆ˜ì • ì½”ë“œ</strong>ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë„ì „ ê³¼ì œ:

- ì •í™•í•œ ìˆ˜ì • ì½”ë“œ ìƒì„±
- ê¸°ì¡´ ì½”ë“œ ìŠ¤íƒ€ì¼ ìœ ì§€
- ë¶€ì‘ìš© ì—†ëŠ” ìˆ˜ì •
- í…ŒìŠ¤íŠ¸ í†µê³¼ ë³´ì¥

### í•´ê²°ì±… (Solution)

ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ë¹„êµí•©ë‹ˆë‹¤:

1. <strong>Multi-Agent ë°©ì‹</strong>: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥ (Plan â†’ Code â†’ Review â†’ Test)
2. <strong>Agentless ë°©ì‹</strong>: ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ì§ì ‘ ìˆ˜ì • (ë” ë†’ì€ ì„±ê³µë¥ !)

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### 1. Agentless ë°©ì‹ (ì¶”ì²œ)

SWE-benchì—ì„œ 50.8% ì„±ê³µë¥ ë¡œ Multi-Agent(33.6%)ë³´ë‹¤ ìš°ìˆ˜:

```python
from openai import AsyncOpenAI
from typing import Dict, Any

class AgentlessFixGenerator:
    def __init__(self):
        self.client = AsyncOpenAI()
        self.model = "gpt-4-turbo-preview"

    async def generate_fix(self, error_context: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ìˆ˜ì • ì½”ë“œ ìƒì„±

        Args:
            error_context: {
                'error': str,           # ì—ëŸ¬ ë©”ì‹œì§€
                'root_cause': str,      # ê·¼ë³¸ ì›ì¸ ë¶„ì„ ê²°ê³¼
                'code': str,            # ì›ë³¸ ì½”ë“œ
                'file_path': str,       # íŒŒì¼ ê²½ë¡œ
                'tests': str            # ê´€ë ¨ í…ŒìŠ¤íŠ¸
            }

        Returns:
            {
                'fixed_code': str,      # ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œ
                'explanation': str,     # ìˆ˜ì • ì„¤ëª…
                'diff': str            # ë³€ê²½ì‚¬í•­ diff
            }
        """

        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ë‹¤ìŒ ì—ëŸ¬ë¥¼ ìˆ˜ì •í•˜ëŠ” ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

## ì—ëŸ¬ ì •ë³´
{error_context['error']}

## ê·¼ë³¸ ì›ì¸
{error_context['root_cause']}

## ì›ë³¸ ì½”ë“œ ({error_context['file_path']})
```python
{error_context['code']}
```

## ê´€ë ¨ í…ŒìŠ¤íŠ¸
```python
{error_context['tests']}
```

---

<strong>ìš”êµ¬ì‚¬í•­</strong>:
1. ëª¨ë“  ê¸°ì¡´ í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•´ì•¼ í•¨
2. ìƒˆë¡œìš´ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
3. ì½”ë“œ ìŠ¤íƒ€ì¼ì„ ì›ë³¸ê³¼ ì¼ê´€ë˜ê²Œ ìœ ì§€
4. ì£¼ì„ìœ¼ë¡œ ìˆ˜ì • ì‚¬í•­ ì„¤ëª… ì¶”ê°€

<strong>ì¶œë ¥ í˜•ì‹</strong> (JSON):
{{
  "fixed_code": "ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œ",
  "explanation": "ìˆ˜ì • ì‚¬í•­ ì„¤ëª…",
  "changes": ["ë³€ê²½ì‚¬í•­ 1", "ë³€ê²½ì‚¬í•­ 2"]
}}
"""

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë²„ê·¸ ìˆ˜ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                               "í•­ìƒ ì•ˆì „í•˜ê³  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.2,  # ì¼ê´€ì„± ìš°ì„ 
            response_format={"type": "json_object"}
        )

        import json
        fix_data = json.loads(response.choices[0].message.content)

        # Diff ìƒì„±
        fix_data['diff'] = self._generate_diff(
            error_context['code'],
            fix_data['fixed_code']
        )

        return fix_data

    def _generate_diff(self, original: str, fixed: str) -> str:
        """ë³€ê²½ì‚¬í•­ diff ìƒì„±"""

        import difflib

        diff = difflib.unified_diff(
            original.splitlines(keepends=True),
            fixed.splitlines(keepends=True),
            lineterm='',
            fromfile='original',
            tofile='fixed'
        )

        return ''.join(diff)

# ì‚¬ìš© ì˜ˆì‹œ
async def fix_database_connection_bug():
    generator = AgentlessFixGenerator()

    error_context = {
        'error': 'psycopg2.OperationalError: connection pool exhausted',
        'root_cause': 'ì—°ê²° íšë“ í›„ ë°˜í™˜í•˜ì§€ ì•Šì•„ í’€ì´ ê³ ê°ˆë¨',
        'code': '''
async def get_users(request):
    conn = db_pool.getconn()
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM users")
        return cursor.fetchall()
    finally:
        pass  # BUG: connection not returned!
''',
        'file_path': 'app.py',
        'tests': '''
def test_get_users():
    users = get_users(mock_request)
    assert len(users) > 0
'''
    }

    fix = await generator.generate_fix(error_context)

    print("ğŸ”§ ìƒì„±ëœ ìˆ˜ì • ì½”ë“œ:")
    print(fix['fixed_code'])
    print("\nğŸ“ ì„¤ëª…:")
    print(fix['explanation'])
    print("\nğŸ“Š ë³€ê²½ì‚¬í•­:")
    print(fix['diff'])

if __name__ == "__main__":
    import asyncio
    asyncio.run(fix_database_connection_bug())
```

#### 2. Multi-Agent ë°©ì‹ (LangGraph)

ë³µì¡í•œ í”„ë¡œì íŠ¸ë‚˜ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œëŠ” ì—­í•  ë¶„ë¦¬ê°€ ìœ ìš©:

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

class FixGenerationState(TypedDict):
    error: str
    root_cause: str
    code: str
    plan: str
    fixed_code: str
    review_comments: str
    approved: bool
    attempts: Annotated[int, operator.add]

class MultiAgentFixGenerator:
    def __init__(self):
        self.workflow = StateGraph(FixGenerationState)
        self.setup_workflow()

    def setup_workflow(self):
        """ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""

        # ë…¸ë“œ ì¶”ê°€
        self.workflow.add_node("planner", self.plan_fix)
        self.workflow.add_node("coder", self.generate_code)
        self.workflow.add_node("reviewer", self.review_code)

        # í”Œë¡œìš° ì •ì˜
        self.workflow.set_entry_point("planner")
        self.workflow.add_edge("planner", "coder")
        self.workflow.add_edge("coder", "reviewer")

        # ì¡°ê±´ë¶€ ì—£ì§€: ë¦¬ë·° í†µê³¼ ì‹œ ì¢…ë£Œ, ì‹¤íŒ¨ ì‹œ ì¬ì‘ì„±
        self.workflow.add_conditional_edges(
            "reviewer",
            self.should_retry,
            {
                "approve": END,
                "revise": "coder",
                "give_up": END
            }
        )

        self.app = self.workflow.compile()

    async def plan_fix(self, state: FixGenerationState) -> dict:
        """1ë‹¨ê³„: ìˆ˜ì • ê³„íš ìˆ˜ë¦½"""

        plan = await llm_call(f"""
ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•œ ìˆ˜ì • ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”:

ì—ëŸ¬: {state['error']}
ê·¼ë³¸ ì›ì¸: {state['root_cause']}

ë‹¨ê³„ë³„ ìˆ˜ì • ê³„íšì„ ì‘ì„±í•˜ì„¸ìš”.
""")

        print("ğŸ“‹ ìˆ˜ì • ê³„íš ìˆ˜ë¦½ ì™„ë£Œ")
        return {"plan": plan}

    async def generate_code(self, state: FixGenerationState) -> dict:
        """2ë‹¨ê³„: ì½”ë“œ ìƒì„±"""

        # ë¦¬ë·° í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ë°˜ì˜
        feedback = state.get('review_comments', '')

        fixed_code = await llm_call(f"""
ë‹¤ìŒ ê³„íšì„ ì½”ë“œë¡œ êµ¬í˜„í•˜ì„¸ìš”:

ê³„íš: {state['plan']}
ì›ë³¸ ì½”ë“œ: {state['code']}

{f'ì´ì „ ë¦¬ë·° í”¼ë“œë°±: {feedback}' if feedback else ''}

ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
""")

        print("ğŸ’» ì½”ë“œ ìƒì„± ì™„ë£Œ")
        return {"fixed_code": fixed_code, "attempts": 1}

    async def review_code(self, state: FixGenerationState) -> dict:
        """3ë‹¨ê³„: ì½”ë“œ ë¦¬ë·°"""

        review = await llm_call(f"""
ë‹¤ìŒ ì½”ë“œë¥¼ ë¦¬ë·°í•˜ì„¸ìš”:

ì›ë³¸: {state['code']}
ìˆ˜ì •ë³¸: {state['fixed_code']}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€:
1. ë²„ê·¸ê°€ ìˆ˜ì •ë˜ì—ˆëŠ”ê°€?
2. ìƒˆë¡œìš´ ë²„ê·¸ê°€ ì—†ëŠ”ê°€?
3. ì½”ë“œ í’ˆì§ˆì´ ìœ ì§€ë˜ëŠ”ê°€?

ìŠ¹ì¸í•˜ë ¤ë©´ "LGTM"ì„, ìˆ˜ì •ì´ í•„ìš”í•˜ë©´ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.
""")

        approved = "LGTM" in review

        print(f"ğŸ‘€ ë¦¬ë·° {'ìŠ¹ì¸' if approved else 'ê±°ë¶€'}")

        return {
            "review_comments": review,
            "approved": approved
        }

    def should_retry(self, state: FixGenerationState) -> str:
        """ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •"""

        if state['approved']:
            return "approve"
        elif state['attempts'] < 3:
            print("ğŸ”„ ì¬ì‘ì„± ì‹œë„")
            return "revise"
        else:
            print("âŒ 3íšŒ ì‹œë„ ì‹¤íŒ¨, í¬ê¸°")
            return "give_up"

    async def generate(self, error, root_cause, code):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""

        result = await self.app.ainvoke({
            "error": error,
            "root_cause": root_cause,
            "code": code,
            "attempts": 0,
            "approved": False
        })

        return result

# LLM í˜¸ì¶œ í—¬í¼ (ì‹¤ì œ êµ¬í˜„)
async def llm_call(prompt: str) -> str:
    from openai import AsyncOpenAI
    client = AsyncOpenAI()

    response = await client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )

    return response.choices[0].message.content
```

### ì„¤ëª… (Explanation)

#### Agentless vs Multi-Agent ë¹„êµ

| í•­ëª© | Agentless | Multi-Agent |
|------|-----------|-------------|
| <strong>ì„±ê³µë¥ </strong> | 50.8% (SWE-bench) | 33.6% (SWE-bench) |
| <strong>ì†ë„</strong> | ë¹ ë¦„ (1íšŒ í˜¸ì¶œ) | ëŠë¦¼ (3ã€œ5íšŒ í˜¸ì¶œ) |
| <strong>ë¹„ìš©</strong> | ë‚®ìŒ | ë†’ìŒ |
| <strong>ë³µì¡ë„</strong> | ë‚®ìŒ | ë†’ìŒ |
| <strong>ì ìš© ì‹œê¸°</strong> | ë‹¨ìˆœã€œì¤‘ê°„ ë³µì¡ë„ ë²„ê·¸ | ëŒ€ê·œëª¨ ì•„í‚¤í…ì²˜ ë³€ê²½ |

#### SWE-bench 2025ë…„ ë¦¬ë”ë³´ë“œ

| ìˆœìœ„ | ì‹œìŠ¤í…œ | ì„±ê³µë¥  | ì ‘ê·¼ ë°©ì‹ |
|------|--------|--------|-----------|
| 1ìœ„ | <strong>TRAE</strong> | 70.4% | o1 + Claude 3.7 + Gemini 2.5 Pro ì•™ìƒë¸” |
| 2ìœ„ | <strong>Mini-SWE-agent</strong> | 65% | 100ì¤„ Python (ì´ˆê²½ëŸ‰) |
| 3ìœ„ | <strong>AgentScope</strong> | 63.4% | Qwen2.5 + Claude 3.5 Sonnet |
| 4ìœ„ | Agentless | 50.8% | ë‹¨ì¼ LLM |
| 5ìœ„ | SWE-Agent | 33.6% | ë©€í‹° ì—ì´ì „íŠ¸ |

<strong>í•µì‹¬ ì¸ì‚¬ì´íŠ¸</strong>:
- <strong>ì•™ìƒë¸” > ë‹¨ì¼ ëª¨ë¸</strong>: TRAEëŠ” 3ê°œ ìµœê³  ëª¨ë¸ ì¡°í•©
- <strong>ë‹¨ìˆœí•¨ > ë³µì¡í•¨</strong>: Mini-SWE-agentëŠ” 100ì¤„ë¡œ 65% (SWE-Agentì˜ 2ë°°)
- <strong>Agentless ìš°ìˆ˜</strong>: ì—ì´ì „íŠ¸ ì—†ëŠ” ì ‘ê·¼ì´ ì˜¤íˆë ¤ íš¨ê³¼ì 

### ë³€í˜• (Variations)

#### 1. ì•™ìƒë¸” Fix Generation (TRAE ë°©ì‹)

```python
class EnsembleFixGenerator:
    def __init__(self):
        self.generators = [
            AgentlessFixGenerator(model="gpt-4-turbo"),
            AgentlessFixGenerator(model="claude-3-5-sonnet"),
            AgentlessFixGenerator(model="gemini-2.5-pro")
        ]

    async def generate_with_ensemble(self, error_context):
        """ì—¬ëŸ¬ ëª¨ë¸ì˜ ìˆ˜ì •ì•ˆì„ ìƒì„±í•˜ê³  ìµœì  ì„ íƒ"""

        # ë³‘ë ¬ë¡œ ìˆ˜ì • ìƒì„±
        fixes = await asyncio.gather(*[
            gen.generate_fix(error_context)
            for gen in self.generators
        ])

        # ê° ìˆ˜ì •ì•ˆì„ í…ŒìŠ¤íŠ¸
        test_results = await asyncio.gather(*[
            test_fix(fix['fixed_code'], error_context['tests'])
            for fix in fixes
        ])

        # í…ŒìŠ¤íŠ¸ í†µê³¼í•œ ìˆ˜ì •ì•ˆ ì¤‘ ê°€ì¥ ê°„ê²°í•œ ê²ƒ ì„ íƒ
        passing_fixes = [
            fix for fix, result in zip(fixes, test_results)
            if result['all_passed']
        ]

        if passing_fixes:
            # ì½”ë“œ ê¸¸ì´ê°€ ì§§ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ë‹¨ìˆœí•¨ ìš°ì„ )
            best_fix = min(passing_fixes, key=lambda f: len(f['fixed_code']))
            return best_fix

        return None  # ëª¨ë“  ìˆ˜ì •ì•ˆ ì‹¤íŒ¨

async def test_fix(code, tests):
    """ìˆ˜ì • ì½”ë“œ í…ŒìŠ¤íŠ¸"""
    # ì‹¤ì œ êµ¬í˜„: pytest ì‹¤í–‰
    return {'all_passed': True}
```

#### 2. ì ì§„ì  ìˆ˜ì • (Incremental Fix)

```python
class IncrementalFixGenerator:
    async def generate_minimal_fix(self, error_context):
        """ìµœì†Œí•œì˜ ë³€ê²½ìœ¼ë¡œ ìˆ˜ì •"""

        prompt = f"""
ë‹¤ìŒ ì—ëŸ¬ë¥¼ ìˆ˜ì •í•˜ë˜, <strong>ìµœì†Œí•œì˜ ì½”ë“œë§Œ ë³€ê²½</strong>í•˜ì„¸ìš”:

ì—ëŸ¬: {error_context['error']}
ì½”ë“œ: {error_context['code']}

ì¶œë ¥ í˜•ì‹:
{{
  "lines_to_change": {{
    "42": "new content for line 42",
    "45": "new content for line 45"
  }},
  "explanation": "ì„¤ëª…"
}}
"""

        fix = await llm_call(prompt)

        # ë¼ì¸ ë‹¨ìœ„ë¡œ ìˆ˜ì • ì ìš©
        return self._apply_line_changes(
            error_context['code'],
            fix['lines_to_change']
        )
```

---

## Recipe 13.5: Testing & Learning ì‚¬ì´í´

### ë¬¸ì œ (Problem)

ìˆ˜ì • ì½”ë“œë¥¼ ìƒì„±í–ˆë‹¤ë©´, ë°°í¬ ì „ì— <strong>ì² ì €í•œ ê²€ì¦</strong>ì´ í•„ìš”í•©ë‹ˆë‹¤:

- ìˆ˜ì •ì´ ì‹¤ì œë¡œ ë²„ê·¸ë¥¼ í•´ê²°í•˜ëŠ”ê°€?
- ìƒˆë¡œìš´ ë²„ê·¸ë¥¼ ë„ì…í•˜ì§€ ì•ŠëŠ”ê°€?
- ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ëŠ”ê°€?
- ì‹¤íŒ¨ ì‹œ ì–´ë–»ê²Œ ìì²´ ìˆ˜ì •í•  ê²ƒì¸ê°€?

### í•´ê²°ì±… (Solution)

<strong>Self-Correction Loop</strong>ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:

1. ìˆ˜ì • ì½”ë“œ í…ŒìŠ¤íŠ¸
2. ì‹¤íŒ¨ ì‹œ ì›ì¸ ë¶„ì„ (Reflection)
3. ìì²´ ìˆ˜ì • (Self-Correction)
4. ìµœëŒ€ 3íšŒ ì¬ì‹œë„
5. ì„±ê³µ ì‹œ í•™ìŠµ ë°ì´í„° ì €ì¥

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### 1. Self-Correction Loop êµ¬í˜„

```python
from typing import Dict, Any, List
import subprocess
import tempfile
import os

class SelfCorrectingTester:
    MAX_RETRIES = 3

    def __init__(self):
        self.client = AsyncOpenAI()

    async def validate_fix(
        self,
        original_code: str,
        fixed_code: str,
        test_suite: str,
        file_path: str
    ) -> Dict[str, Any]:
        """ìˆ˜ì • ì‚¬í•­ ê²€ì¦ (ìµœëŒ€ 3íšŒ ì¬ì‹œë„)

        Returns:
            {
                'success': bool,
                'final_code': str,
                'test_results': dict,
                'attempts': int,
                'reflections': List[str]
            }
        """

        current_code = fixed_code
        reflections = []

        for attempt in range(1, self.MAX_RETRIES + 1):
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë„ {attempt}/{self.MAX_RETRIES}")

            # 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            result = await self.run_tests(current_code, test_suite, file_path)

            if result['all_passed']:
                print(f"âœ… í…ŒìŠ¤íŠ¸ í†µê³¼! ({attempt}íšŒ ì‹œë„)")

                return {
                    'success': True,
                    'final_code': current_code,
                    'test_results': result,
                    'attempts': attempt,
                    'reflections': reflections
                }

            # 2. ì‹¤íŒ¨ ì‹œ ì›ì¸ ë¶„ì„ (Reflection)
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ì›ì¸ ë¶„ì„ ì¤‘...")
            reflection = await self.reflect_on_failure(
                code=current_code,
                failures=result['failures']
            )
            reflections.append(reflection)

            # 3. ìì²´ ìˆ˜ì • (Self-Correction)
            print(f"ğŸ”§ ìì²´ ìˆ˜ì • ì‹œë„ ì¤‘...")
            current_code = await self.apply_reflection(
                code=current_code,
                reflection=reflection
            )

        # 3íšŒ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
        print(f"âš ï¸ {self.MAX_RETRIES}íšŒ ì‹œë„ í›„ ì‹¤íŒ¨, ë¡¤ë°±")

        return {
            'success': False,
            'final_code': original_code,  # ì›ë³¸ìœ¼ë¡œ ë¡¤ë°±
            'test_results': result,
            'attempts': self.MAX_RETRIES,
            'reflections': reflections
        }

    async def run_tests(
        self,
        code: str,
        test_suite: str,
        file_path: str
    ) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰

        Returns:
            {
                'all_passed': bool,
                'passed': int,
                'failed': int,
                'failures': List[dict]
            }
        """

        # ì„ì‹œ íŒŒì¼ì— ì½”ë“œ ì‘ì„±
        with tempfile.TemporaryDirectory() as tmpdir:
            # ìˆ˜ì • ì½”ë“œ ì €ì¥
            code_file = os.path.join(tmpdir, os.path.basename(file_path))
            with open(code_file, 'w') as f:
                f.write(code)

            # í…ŒìŠ¤íŠ¸ ì½”ë“œ ì €ì¥
            test_file = os.path.join(tmpdir, 'test_fix.py')
            with open(test_file, 'w') as f:
                f.write(test_suite)

            # pytest ì‹¤í–‰
            result = subprocess.run(
                ['pytest', test_file, '-v', '--json-report', '--json-report-file=report.json'],
                cwd=tmpdir,
                capture_output=True,
                text=True
            )

            # ê²°ê³¼ íŒŒì‹±
            import json
            report_file = os.path.join(tmpdir, 'report.json')

            if os.path.exists(report_file):
                with open(report_file) as f:
                    report = json.load(f)

                failures = [
                    {
                        'test': test['nodeid'],
                        'error': test.get('call', {}).get('longrepr', ''),
                        'line': test.get('lineno')
                    }
                    for test in report.get('tests', [])
                    if test.get('outcome') == 'failed'
                ]

                return {
                    'all_passed': len(failures) == 0,
                    'passed': report['summary']['passed'],
                    'failed': report['summary'].get('failed', 0),
                    'failures': failures
                }

            # pytest-json-report ë¯¸ì„¤ì¹˜ ì‹œ fallback
            return {
                'all_passed': result.returncode == 0,
                'passed': 0 if result.returncode != 0 else 1,
                'failed': 1 if result.returncode != 0 else 0,
                'failures': [{'error': result.stdout + result.stderr}] if result.returncode != 0 else []
            }

    async def reflect_on_failure(self, code: str, failures: List[dict]) -> str:
        """ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ (Reflection)"""

        failures_text = "\n".join([
            f"í…ŒìŠ¤íŠ¸: {f['test']}\nì—ëŸ¬: {f['error']}"
            for f in failures
        ])

        prompt = f"""
ë‹¤ìŒ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:

<strong>ìˆ˜ì • ì½”ë“œ:</strong>
```python
{code}
```

<strong>ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:</strong>
```
{failures_text}
```

ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ ë¶„ì„í•˜ê³ , ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
{{
  "failure_reason": "ì‹¤íŒ¨ ì›ì¸",
  "fix_approach": "ìˆ˜ì • ë°©ë²•",
  "specific_changes": ["êµ¬ì²´ì  ë³€ê²½ì‚¬í•­ 1", "ë³€ê²½ì‚¬í•­ 2"]
}}
"""

        response = await self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )

        import json
        return json.loads(response.choices[0].message.content)

    async def apply_reflection(self, code: str, reflection: dict) -> str:
        """Reflection ê²°ê³¼ë¥¼ ì½”ë“œì— ì ìš©"""

        prompt = f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”:

<strong>í˜„ì¬ ì½”ë“œ:</strong>
```python
{code}
```

<strong>ë¶„ì„ ê²°ê³¼:</strong>
ì‹¤íŒ¨ ì›ì¸: {reflection['failure_reason']}
ìˆ˜ì • ë°©ë²•: {reflection['fix_approach']}
êµ¬ì²´ì  ë³€ê²½ì‚¬í•­:
{chr(10).join(f'- {c}' for c in reflection['specific_changes'])}

ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
"""

        response = await self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )

        return response.choices[0].message.content

# ì‚¬ìš© ì˜ˆì‹œ
async def test_self_correction():
    tester = SelfCorrectingTester()

    original_code = '''
def divide(a, b):
    return a / b
'''

    # ë²„ê·¸ê°€ ìˆëŠ” ìˆ˜ì • (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ì²˜ë¦¬ ì•ˆ í•¨)
    buggy_fix = '''
def divide(a, b):
    if b == 0:
        return 0  # ì˜ëª»ëœ ìˆ˜ì •!
    return a / b
'''

    test_suite = '''
def test_divide():
    assert divide(10, 2) == 5
    assert divide(10, 0) == None  # Noneì„ ê¸°ëŒ€í•˜ì§€ë§Œ 0 ë°˜í™˜
'''

    result = await tester.validate_fix(
        original_code=original_code,
        fixed_code=buggy_fix,
        test_suite=test_suite,
        file_path='math_utils.py'
    )

    if result['success']:
        print(f"âœ… ìµœì¢… ì½”ë“œ:\n{result['final_code']}")
    else:
        print(f"âŒ ìˆ˜ì • ì‹¤íŒ¨, ë¡¤ë°±ë¨")

    print(f"ì‹œë„ íšŸìˆ˜: {result['attempts']}")
    print(f"Reflection ë¡œê·¸: {result['reflections']}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_self_correction())
```

#### 2. í•™ìŠµ ì‹œìŠ¤í…œ (Continuous Learning)

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from datetime import datetime

class ContinuousLearningSystem:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            collection_name="self_healing_knowledge",
            embedding_function=self.embeddings,
            persist_directory="./chroma_db"
        )
        self.fix_history = []

    async def learn_from_fix(self, fix_data: Dict[str, Any], outcome: Dict[str, Any]):
        """ì„±ê³µí•œ ìˆ˜ì •ìœ¼ë¡œë¶€í„° í•™ìŠµ

        Args:
            fix_data: {
                'error_pattern': str,
                'root_cause': str,
                'code': str,
                'fix': str
            }
            outcome: {
                'success': bool,
                'test_results': dict,
                'attempts': int
            }
        """

        if not outcome['success']:
            print("âš ï¸ ì‹¤íŒ¨í•œ ìˆ˜ì •ì€ í•™ìŠµí•˜ì§€ ì•ŠìŒ")
            return

        # 1. ì„ë² ë”© ìƒì„± ë° ì €ì¥
        document = f"""
ì—ëŸ¬ íŒ¨í„´: {fix_data['error_pattern']}
ê·¼ë³¸ ì›ì¸: {fix_data['root_cause']}
ì›ë³¸ ì½”ë“œ:
{fix_data['code']}

ìˆ˜ì • ì½”ë“œ:
{fix_data['fix']}

ì„±ê³µ ì—¬ë¶€: {outcome['success']}
ì‹œë„ íšŸìˆ˜: {outcome['attempts']}
"""

        metadata = {
            'error_pattern': fix_data['error_pattern'],
            'root_cause': fix_data['root_cause'],
            'timestamp': datetime.now().isoformat(),
            'attempts': outcome['attempts'],
            'success_rate': 1.0 if outcome['success'] else 0.0
        }

        self.vector_store.add_texts(
            texts=[document],
            metadatas=[metadata]
        )

        # 2. ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
        self.fix_history.append({
            **fix_data,
            **outcome,
            'timestamp': datetime.now()
        })

        print(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: {len(self.fix_history)}ê°œ ì‚¬ë¡€ ì¶•ì ")

        # 3. íŒ¨í„´ ë¶„ì„
        await self.analyze_patterns()

    async def analyze_patterns(self):
        """ë°˜ë³µ íŒ¨í„´ ì‹ë³„"""

        from collections import Counter

        # ë™ì¼í•œ ì—ëŸ¬ íŒ¨í„´ ë¹ˆë„
        error_counts = Counter([
            fix['error_pattern']
            for fix in self.fix_history
        ])

        # 3íšŒ ì´ìƒ ë°œìƒí•œ íŒ¨í„´ì€ ë£°ë¡œ ì €ì¥
        for pattern, count in error_counts.items():
            if count >= 3:
                print(f"ğŸ” ë°˜ë³µ íŒ¨í„´ ë°œê²¬: {pattern} ({count}íšŒ)")
                await self.create_rule_from_pattern(pattern)

    async def create_rule_from_pattern(self, pattern: str):
        """ë°˜ë³µ íŒ¨í„´ì„ ë£°ë¡œ ìƒì„±"""

        # í•´ë‹¹ íŒ¨í„´ì˜ ëª¨ë“  ìˆ˜ì • ì‚¬ë¡€ ê²€ìƒ‰
        similar_cases = self.vector_store.similarity_search(
            query=pattern,
            k=5
        )

        # LLMìœ¼ë¡œ ì¼ë°˜í™”ëœ ë£° ìƒì„±
        prompt = f"""
ë‹¤ìŒ ìˆ˜ì • ì‚¬ë¡€ë“¤ì—ì„œ ì¼ë°˜í™”ëœ ë£°ì„ ì¶”ì¶œí•˜ì„¸ìš”:

{chr(10).join([case.page_content for case in similar_cases])}

ì¶œë ¥ í˜•ì‹:
{{
  "rule_name": "ë£° ì´ë¦„",
  "condition": "ì ìš© ì¡°ê±´",
  "action": "ìˆ˜ì • ë°©ë²•"
}}
"""

        # ë£° ì €ì¥ (ê°„ì†Œí™”)
        print(f"ğŸ“œ ìƒˆ ë£° ìƒì„±: {pattern}")

    async def apply_learned_knowledge(self, new_error: str) -> Dict[str, Any]:
        """í•™ìŠµí•œ ì§€ì‹ ì ìš©

        Returns:
            ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì†”ë£¨ì…˜ ë°˜í™˜
        """

        # ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        similar_cases = self.vector_store.similarity_search(
            query=new_error,
            k=1,
            filter={'success_rate': 1.0}  # ì„±ê³µí•œ ì‚¬ë¡€ë§Œ
        )

        if similar_cases and similar_cases[0].metadata.get('similarity', 0) > 0.9:
            print("ğŸ’¡ ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ ë°œê²¬! ì¬ì‚¬ìš©")

            return {
                'found': True,
                'solution': similar_cases[0].page_content,
                'metadata': similar_cases[0].metadata
            }

        print("ğŸ†• ìƒˆë¡œìš´ ë¬¸ì œ, LLMìœ¼ë¡œ ìƒì„± í•„ìš”")
        return {'found': False}

# í†µí•© ì˜ˆì‹œ
async def self_healing_with_learning():
    tester = SelfCorrectingTester()
    learner = ContinuousLearningSystem()

    # 1. ê³¼ê±° ì‚¬ë¡€ ê²€ìƒ‰
    past_solution = await learner.apply_learned_knowledge(
        "psycopg2.OperationalError: connection pool exhausted"
    )

    if past_solution['found']:
        print("âœ… ê³¼ê±° ì†”ë£¨ì…˜ ì¬ì‚¬ìš©")
        return past_solution

    # 2. ìƒˆë¡œìš´ ìˆ˜ì • ìƒì„±
    fix_data = {
        'error_pattern': 'connection pool exhausted',
        'root_cause': 'ì—°ê²° ë°˜í™˜ ëˆ„ë½',
        'code': 'original code',
        'fix': 'fixed code'
    }

    # 3. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
    outcome = await tester.validate_fix(
        original_code=fix_data['code'],
        fixed_code=fix_data['fix'],
        test_suite='test code',
        file_path='app.py'
    )

    # 4. í•™ìŠµ
    await learner.learn_from_fix(fix_data, outcome)

    return outcome
```

### ì„¤ëª… (Explanation)

#### Self-Correction Loopì˜ ì‘ë™ ì›ë¦¬

```mermaid
graph TD
    A[ìˆ˜ì • ì½”ë“œ ìƒì„±] --> B[í…ŒìŠ¤íŠ¸ ì‹¤í–‰]
    B --> C{í†µê³¼?}
    C -->|ì„±ê³µ| D[í•™ìŠµ ë°ì´í„° ì €ì¥]
    D --> E[ë°°í¬]
    C -->|ì‹¤íŒ¨| F[Reflection<br/>ì‹¤íŒ¨ ì›ì¸ ë¶„ì„]
    F --> G[Self-Correction<br/>ìì²´ ìˆ˜ì •]
    G --> H{ì‹œë„ íšŸìˆ˜ < 3?}
    H -->|Yes| B
    H -->|No| I[ë¡¤ë°±]
```

#### í•™ìŠµì˜ íš¨ê³¼

<strong>1ì°¨ ìˆ˜ì • ì‹œ</strong>:
- LLMì´ ì²˜ìŒë¶€í„° ì½”ë“œ ìƒì„±
- ì‹œê°„: í‰ê·  30ì´ˆ
- ì„±ê³µë¥ : 70%

<strong>í•™ìŠµ í›„ (ìœ ì‚¬ ì‚¬ë¡€ 100ê°œ ì¶•ì )</strong>:
- ê³¼ê±° ì‚¬ë¡€ ì¬ì‚¬ìš©
- ì‹œê°„: í‰ê·  5ì´ˆ (6ë°° ë¹ ë¦„)
- ì„±ê³µë¥ : 95% (í•™ìŠµ íš¨ê³¼)

### ë³€í˜• (Variations)

#### 1. A/B í…ŒìŠ¤íŒ…

```python
class ABTestingValidator:
    async def validate_with_ab_test(self, original_code, fixed_code):
        """A/B í…ŒìŠ¤íŠ¸ë¡œ ìˆ˜ì • íš¨ê³¼ ê²€ì¦"""

        # 1. ì¼ë¶€ íŠ¸ë˜í”½ë§Œ ìƒˆ ì½”ë“œë¡œ ë¼ìš°íŒ…
        await deploy_canary(fixed_code, percentage=5)

        # 2. ë©”íŠ¸ë¦­ ë¹„êµ (30ë¶„ ë™ì•ˆ)
        await asyncio.sleep(1800)

        original_metrics = await get_metrics(version='original')
        fixed_metrics = await get_metrics(version='fixed')

        # 3. í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        improvement = (fixed_metrics['error_rate'] - original_metrics['error_rate']) / original_metrics['error_rate']

        if improvement < -0.1:  # 10% ì´ìƒ ê°œì„ 
            print("âœ… ìˆ˜ì • íš¨ê³¼ ê²€ì¦, ì „ì²´ ë°°í¬")
            await deploy_fully(fixed_code)
        else:
            print("âŒ íš¨ê³¼ ì—†ìŒ, ë¡¤ë°±")
            await rollback()
```

#### 2. Mutation Testing

```python
class MutationTester:
    async def test_with_mutations(self, fixed_code, test_suite):
        """ë³€í˜• í…ŒìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê²€ì¦"""

        mutations = self.generate_mutations(fixed_code)

        killed_mutants = 0
        for mutant in mutations:
            result = await run_tests(mutant, test_suite)

            if not result['all_passed']:
                killed_mutants += 1  # í…ŒìŠ¤íŠ¸ê°€ ë³€í˜•ì„ ì¡ì•„ëƒ„

        mutation_score = killed_mutants / len(mutations)

        if mutation_score < 0.8:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± ({mutation_score*100:.0f}%)")
            return False

        return True

    def generate_mutations(self, code):
        """ì½”ë“œ ë³€í˜• ìƒì„±"""
        # ì˜ˆ: + â†’ -, == â†’ !=, True â†’ False
        return [
            code.replace('+', '-'),
            code.replace('==', '!='),
            code.replace('True', 'False')
        ]
```

---

## Recipe 13.6: LangGraph í†µí•©

### ë¬¸ì œ (Problem)

ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ë‹¨ê³„ë¥¼ í†µí•©í•˜ì—¬ <strong>ì™„ì „í•œ Self-Healing ì‹œìŠ¤í…œ</strong>ì„ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤:

1. Error Detection
2. Root Cause Analysis
3. Fix Generation
4. Testing & Self-Correction
5. Learning & Deployment

ê° ë‹¨ê³„ë¥¼ ì–´ë–»ê²Œ ì—°ê²°í•˜ê³ , ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ëŠ” ì–´ë–»ê²Œ ì²˜ë¦¬í•  ê²ƒì¸ê°€?

### í•´ê²°ì±… (Solution)

LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ <strong>ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„</strong>ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

### ì½”ë“œ/ì˜ˆì‹œ (Code)

#### ì™„ì „í•œ Self-Healing ì‹œìŠ¤í…œ (LangGraph)

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator
from openai import AsyncOpenAI
import asyncio

# 1. ìƒíƒœ ì •ì˜
class SelfHealingState(TypedDict):
    # ì…ë ¥
    codebase_path: str

    # Error Detection
    error: str
    error_severity: str

    # Root Cause Analysis
    root_cause: str
    affected_files: list

    # Fix Generation
    original_code: str
    fixed_code: str

    # Testing
    test_results: dict
    reflections: list

    # Learning
    learned: bool

    # ì œì–´
    attempts: Annotated[int, operator.add]
    success: bool

# 2. Self-Healing ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class CompleteSelfHealingSystem:
    def __init__(self):
        self.client = AsyncOpenAI()
        self.workflow = StateGraph(SelfHealingState)
        self.setup_workflow()

        # í•™ìŠµ ì‹œìŠ¤í…œ
        self.learner = ContinuousLearningSystem()

    def setup_workflow(self):
        """ì „ì²´ ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""

        # ë…¸ë“œ ì¶”ê°€
        self.workflow.add_node("detect", self.detect_error)
        self.workflow.add_node("analyze", self.analyze_root_cause)
        self.workflow.add_node("generate", self.generate_fix)
        self.workflow.add_node("test", self.test_fix)
        self.workflow.add_node("learn", self.learn_from_fix)
        self.workflow.add_node("deploy", self.deploy_fix)

        # í”Œë¡œìš° ì •ì˜
        self.workflow.set_entry_point("detect")

        # detect â†’ analyze (ì—ëŸ¬ê°€ ìˆì„ ë•Œë§Œ)
        self.workflow.add_conditional_edges(
            "detect",
            lambda state: "analyze" if state.get('error') else "end",
            {
                "analyze": "analyze",
                "end": END
            }
        )

        self.workflow.add_edge("analyze", "generate")
        self.workflow.add_edge("generate", "test")

        # test â†’ ì¡°ê±´ë¶€ ë¶„ê¸°
        self.workflow.add_conditional_edges(
            "test",
            self.should_retry,
            {
                "retry": "generate",     # ì¬ì‹œë„
                "success": "learn",      # ì„±ê³µ
                "rollback": END          # ì‹¤íŒ¨
            }
        )

        self.workflow.add_edge("learn", "deploy")
        self.workflow.add_edge("deploy", END)

        self.app = self.workflow.compile()

    async def detect_error(self, state: SelfHealingState) -> dict:
        """1ë‹¨ê³„: ì—ëŸ¬ ê°ì§€"""

        print("ğŸ” ì—ëŸ¬ ê°ì§€ ì¤‘...")

        # ì‹¤ì œ êµ¬í˜„: Prometheus, ë¡œê·¸, CodeQL í†µí•©
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜

        # ê³¼ê±° í•™ìŠµ ë°ì´í„° í™•ì¸
        past_solution = await self.learner.apply_learned_knowledge(
            "connection pool exhausted"
        )

        if past_solution['found']:
            print("ğŸ’¡ ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ ë°œê²¬, ë¹ ë¥¸ ê²½ë¡œ ì‚¬ìš©")
            return {
                'error': None,  # ì´ë¯¸ í•´ê²°ë¨
                'success': True
            }

        error = "psycopg2.OperationalError: connection pool exhausted"

        return {
            'error': error,
            'error_severity': 'high'
        }

    async def analyze_root_cause(self, state: SelfHealingState) -> dict:
        """2ë‹¨ê³„: ê·¼ë³¸ ì›ì¸ ë¶„ì„"""

        print("ğŸ”¬ ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì¤‘...")

        analyzer = RootCauseAnalyzer(provider='openai')

        error_data = {
            'message': state['error'],
            'stack_trace': 'Traceback...',
            'code_snippet': 'def get_users():\n    conn = db_pool.getconn()\n    ...',
            'recent_commits': [],
            'metrics': {}
        }

        analysis = await analyzer.analyze(error_data)

        return {
            'root_cause': analysis['root_cause'],
            'affected_files': analysis['affected_files']
        }

    async def generate_fix(self, state: SelfHealingState) -> dict:
        """3ë‹¨ê³„: íŒ¨ì¹˜ ìƒì„±"""

        print("ğŸ”§ íŒ¨ì¹˜ ìƒì„± ì¤‘...")

        generator = AgentlessFixGenerator()

        error_context = {
            'error': state['error'],
            'root_cause': state['root_cause'],
            'code': state.get('original_code', 'original code'),
            'file_path': state['affected_files'][0] if state['affected_files'] else 'app.py',
            'tests': 'test suite'
        }

        fix = await generator.generate_fix(error_context)

        return {
            'original_code': error_context['code'],
            'fixed_code': fix['fixed_code'],
            'attempts': 1
        }

    async def test_fix(self, state: SelfHealingState) -> dict:
        """4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë° Self-Correction"""

        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¤‘... (ì‹œë„ {state['attempts']}/{SelfCorrectingTester.MAX_RETRIES})")

        tester = SelfCorrectingTester()

        result = await tester.validate_fix(
            original_code=state['original_code'],
            fixed_code=state['fixed_code'],
            test_suite='test suite',
            file_path='app.py'
        )

        return {
            'test_results': result['test_results'],
            'reflections': result.get('reflections', []),
            'success': result['success'],
            'fixed_code': result['final_code']  # Self-Correction ì ìš©ëœ ì½”ë“œ
        }

    def should_retry(self, state: SelfHealingState) -> str:
        """ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •"""

        if state['success']:
            return "success"
        elif state['attempts'] < SelfCorrectingTester.MAX_RETRIES:
            print("ğŸ”„ ì¬ì‹œë„")
            return "retry"
        else:
            print("âŒ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼, ë¡¤ë°±")
            return "rollback"

    async def learn_from_fix(self, state: SelfHealingState) -> dict:
        """5ë‹¨ê³„: í•™ìŠµ"""

        print("ğŸ“š í•™ìŠµ ì¤‘...")

        fix_data = {
            'error_pattern': state['error'],
            'root_cause': state['root_cause'],
            'code': state['original_code'],
            'fix': state['fixed_code']
        }

        outcome = {
            'success': state['success'],
            'test_results': state['test_results'],
            'attempts': state['attempts']
        }

        await self.learner.learn_from_fix(fix_data, outcome)

        return {'learned': True}

    async def deploy_fix(self, state: SelfHealingState) -> dict:
        """6ë‹¨ê³„: ë°°í¬"""

        print("ğŸš€ ë°°í¬ ì¤‘...")

        # Git ì»¤ë°‹
        commit_msg = f"""
ğŸ¤– Self-healing fix: {state['error']}

Root cause: {state['root_cause']}
Attempts: {state['attempts']}

Auto-generated by Self-Healing AI Agent
"""

        # ì‹¤ì œ êµ¬í˜„: Git API, GitHub PR ìƒì„±
        print(f"âœ… ë°°í¬ ì™„ë£Œ: {state['affected_files']}")

        # ìŠ¬ë™ ì•Œë¦¼
        await self.notify_team(state)

        return {'success': True}

    async def notify_team(self, state: SelfHealingState):
        """íŒ€ ì•Œë¦¼"""

        # ì‹¤ì œ êµ¬í˜„: Slack API
        print(f"""
ğŸ“¢ Self-Healing ì•Œë¦¼

ì—ëŸ¬: {state['error']}
ê·¼ë³¸ ì›ì¸: {state['root_cause']}
ì‹œë„ íšŸìˆ˜: {state['attempts']}
ìƒíƒœ: {'âœ… ì„±ê³µ' if state['success'] else 'âŒ ì‹¤íŒ¨'}
""")

    async def run_continuous_monitoring(self):
        """24/7 ììœ¨ ëª¨ë‹ˆí„°ë§"""

        print("ğŸ¤– Self-Healing ì‹œìŠ¤í…œ ì‹œì‘ (Ctrl+Cë¡œ ì¤‘ë‹¨)")

        while True:
            try:
                result = await self.app.ainvoke({
                    'codebase_path': '/path/to/codebase',
                    'attempts': 0,
                    'success': False,
                    'reflections': []
                })

                if result.get('success'):
                    print(f"âœ… ìë™ ìˆ˜ì • ì™„ë£Œ: {result.get('error', 'Unknown')}")
                elif result.get('error') is None:
                    print("âœ¨ ì—ëŸ¬ ì—†ìŒ")
                else:
                    print(f"âŒ ìˆ˜ì • ì‹¤íŒ¨, ì‚¬ëŒ ê°œì… í•„ìš”")

                # 1ë¶„ ëŒ€ê¸°
                await asyncio.sleep(60)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Self-Healing ì‹œìŠ¤í…œ ì¢…ë£Œ")
                break
            except Exception as e:
                print(f"âš ï¸ ì‹œìŠ¤í…œ ì—ëŸ¬: {e}")
                await asyncio.sleep(60)

# ì‹¤í–‰ ì˜ˆì‹œ
async def main():
    system = CompleteSelfHealingSystem()

    # ë‹¨ì¼ ì‹¤í–‰
    result = await system.app.ainvoke({
        'codebase_path': '/path/to/codebase',
        'attempts': 0,
        'success': False,
        'reflections': []
    })

    print(f"\nìµœì¢… ê²°ê³¼: {result}")

    # ë˜ëŠ” 24/7 ëª¨ë‹ˆí„°ë§
    # await system.run_continuous_monitoring()

if __name__ == "__main__":
    asyncio.run(main())
```

### ì„¤ëª… (Explanation)

#### ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TD
    A[detect<br/>ì—ëŸ¬ ê°ì§€] --> B{ì—ëŸ¬ ìˆìŒ?}
    B -->|Yes| C[analyze<br/>ê·¼ë³¸ ì›ì¸ ë¶„ì„]
    B -->|No| Z[END]

    C --> D[generate<br/>íŒ¨ì¹˜ ìƒì„±]
    D --> E[test<br/>í…ŒìŠ¤íŠ¸]

    E --> F{ê²°ê³¼?}
    F -->|ì„±ê³µ| G[learn<br/>í•™ìŠµ]
    F -->|ì‹¤íŒ¨ & attempts < 3| D
    F -->|ì‹¤íŒ¨ & attempts >= 3| Z

    G --> H[deploy<br/>ë°°í¬]
    H --> Z
```

#### LangGraphì˜ ì¥ì 

1. <strong>ìƒíƒœ ê´€ë¦¬</strong>: ê° ë‹¨ê³„ì˜ ê²°ê³¼ê°€ Stateì— ìë™ ì €ì¥
2. <strong>ì¡°ê±´ë¶€ ë¶„ê¸°</strong>: í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ë¡œ
3. <strong>ì¬ì‹œë„ ë¡œì§</strong>: ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì´ì „ ë‹¨ê³„ë¡œ
4. <strong>ì‹œê°í™”</strong>: ê·¸ë˜í”„ í˜•íƒœë¡œ í”Œë¡œìš° ì´í•´ ì‰¬ì›€

### ë³€í˜• (Variations)

#### 1. GitHub Actions í†µí•©

```yaml
# .github/workflows/self-healing.yml
name: Self-Healing AI Agent

on:
  schedule:
    - cron: '0 */6 * * *'  # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
  workflow_dispatch:

jobs:
  self-healing:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          pip install langgraph openai anthropic

      - name: Run Self-Healing System
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python self_healing_system.py

      - name: Create Pull Request if Fix Generated
        if: success()
        uses: peter-evans/create-pull-request@v5
        with:
          title: 'ğŸ¤– Self-Healing Fix'
          body: |
            ìë™ ìƒì„±ëœ ìˆ˜ì •ì‚¬í•­ì…ë‹ˆë‹¤.

            ìƒì„¸ ë‚´ìš©ì€ ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.
          branch: auto-fix/${{ github.run_number }}
          labels: auto-fix, self-healing
```

#### 2. Slack í†µí•©

```python
import os
from slack_sdk.webhook import WebhookClient

class SlackNotifier:
    def __init__(self):
        self.webhook = WebhookClient(os.getenv('SLACK_WEBHOOK_URL'))

    async def notify_fix(self, state):
        """ìˆ˜ì • ì™„ë£Œ ì•Œë¦¼"""

        self.webhook.send(
            text=f"ğŸ¤– Self-Healing ìˆ˜ì • ì™„ë£Œ",
            blocks=[
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ¤– Self-Healing Fix Deployed"
                    }
                },
                {
                    "type": "section",
                    "fields": [
                        {
                            "type": "mrkdwn",
                            "text": f"*ì—ëŸ¬:*\n{state['error']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*ê·¼ë³¸ ì›ì¸:*\n{state['root_cause']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*ì‹œë„ íšŸìˆ˜:*\n{state['attempts']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*ìƒíƒœ:*\n{'âœ… ì„±ê³µ' if state['success'] else 'âŒ ì‹¤íŒ¨'}"
                        }
                    ]
                }
            ]
        )
```

---

## ì‹¤ì „ ì‚¬ë¡€ ì—°êµ¬

### Netflix: Chaos Engineeringê³¼ Self-Healing

#### ë°°ê²½

- <strong>270M+ ê¸€ë¡œë²Œ ì‚¬ìš©ì</strong>
- <strong>99.99% ê°€ë™ë¥ </strong> (ì—°ê°„ ë‹¤ìš´íƒ€ì„ < 1ì‹œê°„)
- <strong>AWS ì „ì²´ íŠ¸ë˜í”½ì˜ 37%</strong>

#### ìê°€ ì¹˜ìœ  ë©”ì»¤ë‹ˆì¦˜

##### 1. Auto-Scaling

```python
class NetflixAutoScaler:
    async def heal_capacity_issues(self):
        """ìš©ëŸ‰ ë¬¸ì œ ìë™ ë³µêµ¬"""

        while True:
            metrics = await cloudwatch.get_metrics()

            if metrics['cpu_usage'] > 80:
                # ì¸ìŠ¤í„´ìŠ¤ ìë™ ì¶”ê°€
                new_instances = await ec2.scale_out(count=10)
                await load_balancer.register_targets(new_instances)

                print("ğŸ“ˆ Auto-Scaling: +10 ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€")

            if metrics['cpu_usage'] < 20:
                # ë¶ˆí•„ìš”í•œ ì¸ìŠ¤í„´ìŠ¤ ì œê±°
                await ec2.scale_in(count=5)

                print("ğŸ“‰ Auto-Scaling: -5 ì¸ìŠ¤í„´ìŠ¤ ì œê±°")

            await asyncio.sleep(60)
```

##### 2. Chaos Monkey

```python
class ChaosMonkey:
    """ë¬´ì‘ìœ„ ì¥ì•  ì£¼ì…ìœ¼ë¡œ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸"""

    async def inject_failures(self):
        while True:
            # ë¬´ì‘ìœ„ ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ
            random_instance = random.choice(await ec2.list_instances())
            await ec2.terminate(random_instance)

            print(f"ğŸ’¥ Chaos: {random_instance} ì¢…ë£Œ")

            # ìê°€ ì¹˜ìœ  ë©”ì»¤ë‹ˆì¦˜ì´ ìë™ ë³µêµ¬í•˜ëŠ”ì§€ ê²€ì¦
            await self.verify_recovery()

            await asyncio.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤

    async def verify_recovery(self):
        """ë³µêµ¬ ê²€ì¦"""

        await asyncio.sleep(60)  # 1ë¶„ ëŒ€ê¸°

        health = await check_system_health()

        if health['status'] != 'healthy':
            raise AssertionError("Self-healing ì‹¤íŒ¨!")

        print("âœ… Self-Healing ê²€ì¦ í†µê³¼")
```

#### ì„±ê³¼

- <strong>AWS AZ ì¥ì•  ì‹œ</strong>: 30ì´ˆ ë‚´ ìë™ ë³µêµ¬
- <strong>ì „ì²´ ë¦¬ì „ ì¥ì•  ì‹œ</strong>: 5ë¶„ ë‚´ ë‹¤ë¥¸ ë¦¬ì „ìœ¼ë¡œ íŠ¸ë˜í”½ ì „í™˜
- <strong>ê°œë³„ ì„œë¹„ìŠ¤ ì¥ì• </strong>: ì‚¬ìš©ì ì˜í–¥ 0% (ì¦‰ì‹œ ë³µêµ¬)

### GitHub: Prototype AI Agent

#### í•µì‹¬ ê¸°ëŠ¥

1. <strong>ì½”ë“œë² ì´ìŠ¤ ìŠ¤ìº”</strong>: CodeQLë¡œ ì „ì²´ ì €ì¥ì†Œ ë¶„ì„
2. <strong>ìë™ ìˆ˜ì •</strong>: ì·¨ì•½ì , ë³µì¡ë„ ë¬¸ì œ ìë™ ìˆ˜ì •
3. <strong>PR ìƒì„±</strong>: ìˆ˜ì • ì‚¬í•­ì„ Pull Requestë¡œ ì œì¶œ

#### ì‹¤ì œ ì„±ê³¼

- <strong>í•˜ë£¨ 4ì²œë§Œ ê°œ ì‘ì—…</strong> ì²˜ë¦¬
- <strong>í‰ê·  ìˆ˜ì • ì‹œê°„</strong>: 15ë¶„ (ì‚¬ëŒ: 2-3ì‹œê°„)
- <strong>ì •í™•ë„</strong>: 85% (ì‚¬ëŒ ë¦¬ë·° í›„ ë¨¸ì§€ìœ¨)

### Google DeepMind: CodeMender

#### Gemini Deep Think ëª¨ë¸

- <strong>6ê°œì›”ê°„ 72ê°œ ë³´ì•ˆ íŒ¨ì¹˜</strong> ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬
- <strong>í‰ê·  ìˆ˜ì • ì‹œê°„</strong>: 20ë¶„
- <strong>ì»¤ë®¤ë‹ˆí‹° ìˆ˜ìš©ë¥ </strong>: 94% (68/72 PR ë¨¸ì§€)

---

## í•œê³„ì™€ í•´ê²°ì±…

### 1. ì •í™•ë„ ë¬¸ì œ

<strong>ë¬¸ì œ</strong>: 15% ì˜¤íƒì§€(False Positive), 5% ë¯¸íƒì§€(False Negative)

<strong>í•´ê²°ì±…</strong>:

```python
async def human_in_the_loop_validation(fix):
    """ì‹ ë¢°ë„ ê¸°ë°˜ ê²€ì¦"""

    if fix.confidence < 0.9:
        # ì‹ ë¢°ë„ ë‚®ì€ ìˆ˜ì •ì€ ì‚¬ëŒ ìŠ¹ì¸ í•„ìš”
        await request_human_approval(fix)
    else:
        # ì‹ ë¢°ë„ ë†’ì€ ìˆ˜ì •ì€ ìë™ ë°°í¬
        await auto_deploy(fix)
```

### 2. ë³µì¡í•œ ë²„ê·¸ ì²˜ë¦¬ ì‹¤íŒ¨

<strong>ë¬¸ì œ</strong>: ë©€í‹° ìŠ¤ë ˆë“œ ê²½ìŸ ì¡°ê±´, ê°„í—ì  ë²„ê·¸ëŠ” AIê°€ íŒŒì•… ì–´ë ¤ì›€

<strong>í•´ê²°ì±…</strong>:

```python
async def escalate_to_expert(issue):
    """ë³µì¡í•œ ë¬¸ì œëŠ” ì „ë¬¸ê°€ì—ê²Œ ì—ìŠ¤ì»¬ë ˆì´ì…˜"""

    if issue.complexity_score > 0.8:
        await notify_expert_team(issue)
        return "ESCALATED"

    return await self.auto_fix(issue)
```

### 3. ë³´ì•ˆ ë¦¬ìŠ¤í¬

<strong>ë¬¸ì œ</strong>: í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ê³µê²© ê°€ëŠ¥

<strong>í•´ê²°ì±…</strong>:

```python
def sanitize_input(error_msg):
    """ì…ë ¥ ê²€ì¦"""

    dangerous_keywords = ['DROP', 'DELETE', 'EXECUTE']
    for keyword in dangerous_keywords:
        if keyword in error_msg.upper():
            raise SecurityException(f"ìœ„í—˜í•œ í‚¤ì›Œë“œ: {keyword}")

    return error_msg
```

---

## Best Practices ìš”ì•½

### 1. ì ì§„ì  ë¡¤ì•„ì›ƒ (Canary Deployment)

```python
# 5% â†’ 50% â†’ 100% ë‹¨ê³„ì  ë°°í¬
await deploy_to_percentage(new_fix, percentage=5)
await monitor_for_duration(minutes=30)

if await check_error_rate() < 0.1:
    await deploy_to_percentage(new_fix, percentage=50)
```

### 2. ê´€ì°° ê°€ëŠ¥ì„± (Observability)

- <strong>í¬ê´„ì  ë¡œê¹…</strong>: ëª¨ë“  ë‹¨ê³„ ê¸°ë¡
- <strong>ì„±ëŠ¥ ë©”íŠ¸ë¦­</strong>: Prometheusë¡œ ìˆ˜ì§‘
- <strong>ì¶”ì </strong>: OpenTelemetry
- <strong>ì•Œë¦¼</strong>: Slack, PagerDuty
- <strong>ëŒ€ì‹œë³´ë“œ</strong>: Grafana

### 3. Human-in-the-Loop

- ì‹ ë¢°ë„ 0.9 ì´ìƒ: ìë™ ë°°í¬
- ì‹ ë¢°ë„ 0.7ã€œ0.9: ë¹„ë™ê¸° ë¦¬ë·°
- ì‹ ë¢°ë„ 0.7 ë¯¸ë§Œ: í•„ìˆ˜ ìŠ¹ì¸

### 4. ì§€ì†ì  í•™ìŠµ

- ì„±ê³µí•œ ìˆ˜ì • ì‚¬ë¡€ ì €ì¥
- ìœ ì‚¬ íŒ¨í„´ ì¬ì‚¬ìš©
- ë°˜ë³µ íŒ¨í„´ì„ ë£°ë¡œ ìƒì„±

---

## ì‹œì‘í•˜ê¸° ë¡œë“œë§µ

### 1ì£¼ì°¨: ê¸°ì´ˆ í•™ìŠµ

```bash
# LangGraph ì„¤ì¹˜
pip install langgraph langchain-openai

# ì˜ˆì œ ì‹¤í–‰
python examples/self_healing_demo.py
```

### 2ì£¼ì°¨: ì†Œê·œëª¨ í”„ë¡œì íŠ¸ ì ìš©

- ë‹¨ì¼ ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§
- ê°„ë‹¨í•œ ì—ëŸ¬ ìë™ ìˆ˜ì • (ì˜ˆ: í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½)

### 3ì£¼ì°¨: í”„ë¡œë•ì…˜ íŒŒì¼ëŸ¿

- Canary ë°°í¬ (5% â†’ 50% â†’ 100%)
- Human-in-the-Loop ê²€ì¦
- ì„±ê³¼ ì¸¡ì • (MTTR, ì„±ê³µë¥ )

### 1ê°œì›” í›„: ì „ë©´ ë„ì… ê²°ì •

---

## ì—°ìŠµ ë¬¸ì œ

### Exercise 1: ê°„ë‹¨í•œ Self-Healing ì‹œìŠ¤í…œ

ë‹¤ìŒ ë²„ê·¸ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”:

```python
# ë²„ê·¸: ZeroDivisionError
def calculate_average(numbers):
    return sum(numbers) / len(numbers)  # len(numbers)ê°€ 0ì´ë©´ ì—ëŸ¬!

# ëª©í‘œ: ìë™ìœ¼ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ ì¶”ê°€
```

### Exercise 2: í•™ìŠµ ì‹œìŠ¤í…œ

3ê°œ ì´ìƒì˜ ìˆ˜ì • ì‚¬ë¡€ë¥¼ í•™ìŠµí•˜ê³ , ìœ ì‚¬ ì‚¬ë¡€ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ê³¼ê±° ì†”ë£¨ì…˜ì„ ì ìš©í•˜ì„¸ìš”.

### Exercise 3: LangGraph ì›Œí¬í”Œë¡œìš°

Error Detection â†’ Root Cause Analysis â†’ Fix Generation 3ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°ë¥¼ LangGraphë¡œ êµ¬í˜„í•˜ì„¸ìš”.

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com)

### ë²¤ì¹˜ë§ˆí¬

- [SWE-bench ë¦¬ë”ë³´ë“œ](https://www.swebench.com/)
- [Meta AutoPatchBench](https://engineering.fb.com/2025/04/29/ai-research/autopatchbench-benchmark-ai-powered-security-fixes/)

### ì‹¤ì „ ì‚¬ë¡€

- [GitHub AI Agent](https://www.infoq.com/news/2025/06/github-ai-agent-bugfixing/)
- [Google CodeMender](https://www.artificialintelligence-news.com/news/google-new-ai-agent-rewrites-code-automate-vulnerability-fixes/)
- [Netflix Chaos Engineering](https://lobste.rs/s/yulcql/how_we_built_self_healing_system_survive)

### í•™ìŠµ ìë£Œ

- [Self-Healing ML Framework (NeurIPS 2024)](https://arxiv.org/abs/2411.00186)
- [LangGraph Self-Healing Tutorial](https://krishankantsinghal.medium.com/from-prompt-to-program-building-a-self-healing-ai-coder-with-langgraph-16f7767a6100)

---

## ë§ˆì¹˜ë©°

ìê°€ ì¹˜ìœ  AI ì‹œìŠ¤í…œì€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì˜ íŒ¨ëŸ¬ë‹¤ì„ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.

<strong>í•µì‹¬ ìš”ì•½</strong>:

- <strong>5ë‹¨ê³„ ì‚¬ì´í´</strong>: Detect â†’ Analyze â†’ Generate â†’ Test â†’ Learn
- <strong>Agentless > Multi-Agent</strong>: ë‹¨ìˆœí•¨ì´ ì´ê¸´ë‹¤ (50.8% vs 33.6%)
- <strong>ì§€ì†ì  í•™ìŠµ</strong>: ê³¼ê±° ì‚¬ë¡€ ì¬ì‚¬ìš©ìœ¼ë¡œ 6ë°° ë¹ ë¥¸ ìˆ˜ì •
- <strong>ì‹¤ì „ ê²€ì¦</strong>: GitHub, Google, Netflixê°€ í”„ë¡œë•ì…˜ ë°°í¬

<strong>ë‹¤ìŒ ë‹¨ê³„</strong>:

ì´ì œ ì—¬ëŸ¬ë¶„ì˜ ì‹œìŠ¤í…œì— ìê°€ ì¹˜ìœ  ë©”ì»¤ë‹ˆì¦˜ì„ ì¶”ê°€í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì‚¬ëŒì„ ê¹¨ìš°ì§€ ë§ê³ , AI ì—ì´ì „íŠ¸ê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ë„ë¡ í•˜ì„¸ìš”.

<strong>ë¯¸ë˜ëŠ” ììœ¨ì ì´ê³ , ì ì‘ì ì´ë©°, ìê°€ ì¹˜ìœ í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.</strong>

---

**ë‹¤ìŒ ì±•í„° ì˜ˆê³ **: Chapter 14ì—ì„œëŠ” AI ì—ì´ì „íŠ¸ì˜ ë³´ì•ˆê³¼ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ì„ ë‹¤ë£¹ë‹ˆë‹¤.
