# Chapter 13: Self-Healing AI ã‚·ã‚¹ãƒ†ãƒ 

> ã€Œã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯è‡ªå·±ä¿®å¾©ã§ããªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã€ â€” Netflix Engineering Team

## æ¦‚è¦

ã“ã®ç« ã§ã¯ã€Self-Healing AI Systems(è‡ªå·±ä¿®å¾©AIã‚·ã‚¹ãƒ†ãƒ )ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚GitHubã€Google DeepMindã€NetflixãŒå®Ÿæˆ¦é…å‚™ã—ãŸã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ†æã—ã€LangGraphã‚’æ´»ç”¨ã—ãŸå®Ÿè·µçš„ãªå®Ÿè£…æ–¹æ³•ã‚’ç¿’å¾—ã—ã¾ã™ã€‚

### ã“ã®ç« ã§å­¦ã¶ã“ã¨

- Self-Healing AI ã‚·ã‚¹ãƒ†ãƒ ã®5æ®µéšã‚µã‚¤ã‚¯ãƒ«ã®ç†è§£
- Error Detectionã‹ã‚‰å­¦ç¿’ã¾ã§ã®å…¨ä½“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…
- LangGraphã«ã‚ˆã‚‹è‡ªå¾‹å¾©æ—§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰
- å®Ÿæˆ¦äº‹ä¾‹åˆ†æ(GitHubã€Googleã€Netflix)
- é™ç•Œã¨è§£æ±ºç­–ã®ç†è§£

### å¿…è¦ãªäº‹å‰çŸ¥è­˜

- Pythonã®åŸºæœ¬æ–‡æ³•
- LLM APIä½¿ç”¨çµŒé¨“(OpenAIã€Anthropicãªã©)
- GitãŠã‚ˆã³GitHubã®åŸºæœ¬çŸ¥è­˜
- åŸºæœ¬çš„ãªDevOpsã®æ¦‚å¿µ

---

## Recipe 13.1: Self-Healingã®æ¦‚å¿µç†è§£

### å•é¡Œ(Problem)

å¾“æ¥ã®ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã¯ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã™ã‚‹ã¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«é€šçŸ¥ã‚’é€ã‚Šã€äººãŒæ‰‹å‹•ã§å•é¡Œã‚’åˆ†æã—ã¦ä¿®æ­£ã—ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯:

- <strong>å¹³å‡å¾©æ—§æ™‚é–“(MTTR)</strong>ãŒæ•°æ™‚é–“ã‹ã‚‰æ•°æ—¥
- å¤œé–“ãƒ»é€±æœ«ã®éšœå®³æ™‚ã«å¯¾å¿œé…å»¶
- åŒã˜å•é¡Œã®å†ç™ºã«æ¯å›æ‰‹å‹•å¯¾å¿œ
- äººçš„ãƒªã‚½ãƒ¼ã‚¹ã¸ã®ä¾å­˜ã§æ‹¡å¼µæ€§ä¸è¶³

### è§£æ±ºç­–(Solution)

è‡ªå·±ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ ã¯**æ¤œå‡º â†’ åˆ†æ â†’ ä¿®æ­£ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤**ã‚’å®Œå…¨ã«è‡ªå¾‹çš„ã«å®Ÿè¡Œã—ã¾ã™ã€‚

#### 5æ®µéšã‚µã‚¤ã‚¯ãƒ«

```mermaid
graph TD
    A[1. Error Detection<br/>ã‚¨ãƒ©ãƒ¼æ¤œå‡º] --> B[2. Root Cause Analysis<br/>æ ¹æœ¬åŸå› åˆ†æ]
    B --> C[3. Fix Generation<br/>ãƒ‘ãƒƒãƒç”Ÿæˆ]
    C --> D[4. Testing<br/>ãƒ†ã‚¹ãƒˆ]
    D --> E{é€šé?}
    E -->|å¤±æ•—| F[Self-Correction<br/>è‡ªå·±ä¿®æ­£]
    F --> D
    E -->|æˆåŠŸ| G[5. Learning & Deployment<br/>å­¦ç¿’ã¨ãƒ‡ãƒ—ãƒ­ã‚¤]
    E -->|3å›å¤±æ•—| H[Rollback<br/>ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯]
```

å„æ®µéšã®å½¹å‰²:

1. <strong>Error Detection</strong>: ç•°å¸¸å…†å€™ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œå‡º
2. <strong>Root Cause Analysis</strong>: ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ã‚’LLMã§åˆ†æ
3. <strong>Fix Generation</strong>: è‡ªå‹•çš„ã«ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
4. <strong>Testing</strong>: ä¿®æ­£å†…å®¹ã‚’æ¤œè¨¼ã—ã€å¤±æ•—æ™‚ã«è‡ªå·±ä¿®æ­£
5. <strong>Learning & Deployment</strong>: æˆåŠŸã—ãŸä¿®æ­£ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### å¾“æ¥ã®æ–¹å¼ vs Self-Healingã®æ¯”è¼ƒ

```python
# âŒ å¾“æ¥ã®ç›£è¦–: æ¤œå‡ºã®ã¿ã§æ‰‹å‹•ä¿®æ­£
def traditional_monitoring():
    if error_detected():
        send_alert_to_engineer()  # äººãŒèµ·ãã¦æ‰‹å‹•ä¿®æ­£
        wait_for_fix()            # ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ç™ºç”Ÿ
        # MTTR: æ•°æ™‚é–“ã€œæ•°æ—¥

# âœ… Self-Healing: æ¤œå‡º â†’ åˆ†æ â†’ ä¿®æ­£ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤(è‡ªå‹•)
async def self_healing_monitor():
    while True:
        if error := detect_anomaly():
            # 1. æ ¹æœ¬åŸå› åˆ†æ
            root_cause = await analyze_error(error)

            # 2. ãƒ‘ãƒƒãƒç”Ÿæˆ
            fix = await generate_patch(root_cause)

            # 3. ãƒ†ã‚¹ãƒˆ
            if await test_fix(fix):
                # 4. ãƒ‡ãƒ—ãƒ­ã‚¤
                await deploy(fix)

                # 5. å­¦ç¿’
                await learn_from_fix(fix)
            else:
                # å¤±æ•—æ™‚ã«åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦è¡Œ
                await retry_with_different_approach()

        await asyncio.sleep(60)  # 1åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
```

### èª¬æ˜(Explanation)

#### ãªãœä»ŠSelf-Healingã‚·ã‚¹ãƒ†ãƒ ãªã®ã‹?

<strong>å¸‚å ´è¦æ¨¡</strong>:
- AIå¸‚å ´: 2030å¹´ã¾ã§ã«$826.70Bäºˆæƒ³
- AIOpsãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : 2023å¹´$11.7B â†’ 2028å¹´$32.4B(3å€æˆé•·)

<strong>æ¡ç”¨çŠ¶æ³</strong>(2025å¹´åŸºæº–):
- <strong>GitHub</strong>: 1æ—¥4åƒä¸‡å€‹ã®ã‚¿ã‚¹ã‚¯ã§è‡ªå·±ä¿®å¾©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é‹ç”¨
- <strong>Google DeepMind</strong>: CodeMenderãŒ6ãƒ¶æœˆé–“ã§72å€‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒã‚’è‡ªå‹•è²¢çŒ®
- <strong>Netflix</strong>: 270Mãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦99.99%ã®ç¨¼åƒç‡ã‚’ç¶­æŒ
- <strong>Meta</strong>: AutoPatchBenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ¨™æº–åŒ–ã‚’ä¸»å°

#### Self-Healingã®ä¸»ãªåˆ©ç‚¹

| é …ç›® | å¾“æ¥ã®æ–¹å¼ | Self-Healing |
|------|------------|--------------|
| MTTR | æ•°æ™‚é–“ã€œæ•°æ—¥ | <strong>æ•°åˆ†ä»¥å†…</strong> |
| é‹ç”¨æ™‚é–“ | å–¶æ¥­æ™‚é–“ã®ã¿ | <strong>24/7è‡ªå¾‹é‹ç”¨</strong> |
| å†ç™ºå¯¾å¿œ | æ¯å›æ‰‹å‹•ä¿®æ­£ | <strong>å³åº§ã«è‡ªå‹•è§£æ±º</strong> |
| æ‹¡å¼µæ€§ | äººçš„ãƒªã‚½ãƒ¼ã‚¹ä¾å­˜ | <strong>ç„¡é™ã«æ‹¡å¼µå¯èƒ½</strong> |

### å¤‰å½¢(Variations)

#### 1. éƒ¨åˆ†çš„è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ (Human-in-the-Loop)

å®Œå…¨è‡ªå¾‹ãŒè² æ‹…ãªå ´åˆã¯ã€ä¿¡é ¼åº¦ã«åŸºã¥ã„ã¦äººé–“ã®æ¤œè¨¼ã‚’è¿½åŠ :

```python
async def hybrid_self_healing(error):
    fix = await generate_fix(error)

    if fix.confidence >= 0.9:
        # é«˜ä¿¡é ¼åº¦: è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤
        await auto_deploy(fix)
    elif fix.confidence >= 0.7:
        # ä¸­é–“ä¿¡é ¼åº¦: éåŒæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        await request_human_review(fix)
    else:
        # ä½ä¿¡é ¼åº¦: å¿…é ˆæ‰¿èª
        await block_until_approved(fix)
```

#### 2. ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–Self-Healing

ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿ã«é©ç”¨:

- <strong>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒ</strong>: Google CodeMenderæ–¹å¼
- <strong>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–</strong>: Netflix Auto-Scaling
- <strong>ãƒ†ã‚¹ãƒˆä¿®æ­£</strong>: GitHub CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

---

## Recipe 13.2: Error Detectionå®Ÿè£…

### å•é¡Œ(Problem)

Self-Healingã®æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ã‚¨ãƒ©ãƒ¼ã‚’æ­£ç¢ºã«æ¤œå‡ºã™ã‚‹ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ãªèª²é¡ŒãŒã‚ã‚Šã¾ã™:

- æ­£å¸¸å‹•ä½œã¨ç•°å¸¸å…†å€™ã‚’ã©ã†åŒºåˆ¥ã™ã‚‹ã‹?
- æ–­ç¶šçš„ã«ç™ºç”Ÿã™ã‚‹ã‚¨ãƒ©ãƒ¼ã‚’ã©ã†æ•æ‰ã™ã‚‹ã‹?
- èª¤æ¤œçŸ¥(False Positive)ã‚’ã©ã†æ¸›ã‚‰ã™ã‹?

### è§£æ±ºç­–(Solution)

3ã¤ã®æ–¹æ³•è«–ã‚’çµ„ã¿åˆã‚ã›ã¾ã™:

1. <strong>ç•°å¸¸æ¤œå‡º(Anomaly Detection)</strong>: æ©Ÿæ¢°å­¦ç¿’ã§æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
2. <strong>ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç›£è¦–</strong>: Prometheusã€Datadogãªã©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
3. <strong>ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æ</strong>: CodeQLã§é™çš„ã‚³ãƒ¼ãƒ‰åˆ†æ

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### 1. ç•°å¸¸æ¤œå‡º(Isolation Forest)

```python
from sklearn.ensemble import IsolationForest
import numpy as np

class AnomalyDetector:
    def __init__(self, contamination=0.1):
        """
        contamination: ç•°å¸¸å€¤ã®å‰²åˆ(0.1 = 10%)
        """
        self.model = IsolationForest(
            contamination=contamination,
            random_state=42
        )
        self.is_trained = False

    def train(self, normal_metrics):
        """æ­£å¸¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å­¦ç¿’

        Args:
            normal_metrics: shape (n_samples, n_features)
                ä¾‹: [[cpu, memory, latency], ...]
        """
        self.model.fit(normal_metrics)
        self.is_trained = True

    def detect(self, current_metrics):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ

        Returns:
            True: ç•°å¸¸æ¤œå‡º
            False: æ­£å¸¸
        """
        if not self.is_trained:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        prediction = self.model.predict([current_metrics])
        return prediction[0] == -1  # -1 = ç•°å¸¸ã€1 = æ­£å¸¸

# ä½¿ç”¨ä¾‹
detector = AnomalyDetector()

# 1é€±é–“ã®æ­£å¸¸ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
normal_data = [
    [20.5, 512, 0.15],  # [cpu%, memory_mb, latency_sec]
    [22.1, 530, 0.18],
    # ... æ•°åƒå€‹ã®ã‚µãƒ³ãƒ—ãƒ«
]
detector.train(normal_data)

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º
current = [85.3, 1024, 2.5]  # CPUæ€¥å¢—ã€ãƒ¡ãƒ¢ãƒªå¢—åŠ ã€é…å»¶å¢—åŠ 
if detector.detect(current):
    print("âš ï¸ ç•°å¸¸æ¤œå‡º! Self-Healingé–‹å§‹")
```

#### 2. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç›£è¦–(Prometheus)

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
import random

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
error_counter = Counter(
    'app_errors_total',
    'Total number of errors',
    ['error_type']
)

response_time = Histogram(
    'http_response_time_seconds',
    'HTTP response time in seconds',
    ['endpoint']
)

active_connections = Gauge(
    'active_connections',
    'Number of active connections'
)

# FastAPI/Flaskä¾‹
from fastapi import FastAPI, Request
import asyncio

app = FastAPI()

@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    """å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç›£è¦–"""

    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šå¢—åŠ 
    active_connections.inc()

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“æ¸¬å®š
    start = time.time()

    try:
        response = await call_next(request)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“è¨˜éŒ²
        duration = time.time() - start
        response_time.labels(endpoint=request.url.path).observe(duration)

        return response

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆ
        error_counter.labels(error_type=type(e).__name__).inc()
        raise

    finally:
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šæ¸›å°‘
        active_connections.dec()

@app.get("/api/users")
async def get_users():
    # æ„å›³çš„ã«é…å»¶ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    if random.random() < 0.1:  # 10%ã®ç¢ºç‡ã§é…ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        await asyncio.sleep(2)

    if random.random() < 0.05:  # 5%ã®ç¢ºç‡ã§ã‚¨ãƒ©ãƒ¼
        raise ValueError("Database connection failed")

    return {"users": []}

# Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒ¼ãƒãƒ¼èµ·å‹•(ãƒãƒ¼ãƒˆ8000)
if __name__ == "__main__":
    start_http_server(8000)
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)
```

#### 3. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æ(CodeQL)

```ql
// CodeQLã‚¯ã‚¨ãƒª: SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§æ¤œå‡º
import python

from StringLiteral sql, Call query_call, StringFormatting fmt
where
  // execute()é–¢æ•°å‘¼ã³å‡ºã—ã‚’æ¤œç´¢
  query_call.getFunc().getName() = "execute" and

  // æœ€åˆã®å¼•æ•°ãŒSQLæ–‡å­—åˆ—
  sql.getParentNode*() = query_call.getArg(0) and

  // æ–‡å­—åˆ—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½¿ç”¨(è„†å¼±æ€§!)
  fmt.getASubExpression*() = sql

select query_call,
  "SQL injection vulnerability detected: unsanitized user input in query"
```

Pythonã‚³ãƒ¼ãƒ‰ä¾‹(è„†å¼±ãªã‚³ãƒ¼ãƒ‰):

```python
# âŒ è„†å¼±ãªã‚³ãƒ¼ãƒ‰(CodeQLãŒæ¤œå‡º)
def get_user(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"  # å±é™º!
    cursor.execute(query)
    return cursor.fetchone()

# âœ… å®‰å…¨ãªã‚³ãƒ¼ãƒ‰
def get_user_safe(user_id):
    query = "SELECT * FROM users WHERE id = %s"  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒª
    cursor.execute(query, (user_id,))
    return cursor.fetchone()
```

#### 4. çµ±åˆã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 

```python
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ErrorEvent:
    timestamp: datetime
    source: str  # 'anomaly', 'runtime', 'static'
    severity: str  # 'low', 'medium', 'high', 'critical'
    message: str
    metadata: Dict

class IntegratedErrorDetector:
    def __init__(self):
        self.anomaly_detector = AnomalyDetector()
        self.error_history: List[ErrorEvent] = []

    async def monitor(self):
        """3ã¤ã®æ–¹æ³•è«–ã‚’çµ±åˆã—ãŸç›£è¦–"""

        while True:
            errors = []

            # 1. ç•°å¸¸æ¤œå‡º
            current_metrics = await self.get_current_metrics()
            if self.anomaly_detector.detect(current_metrics):
                errors.append(ErrorEvent(
                    timestamp=datetime.now(),
                    source='anomaly',
                    severity='high',
                    message='Anomaly detected in system metrics',
                    metadata={'metrics': current_metrics}
                ))

            # 2. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç›£è¦–
            prometheus_alerts = await self.check_prometheus_alerts()
            for alert in prometheus_alerts:
                errors.append(ErrorEvent(
                    timestamp=datetime.now(),
                    source='runtime',
                    severity=alert['severity'],
                    message=alert['summary'],
                    metadata=alert
                ))

            # 3. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æ(å®šæœŸçš„ã«å®Ÿè¡Œ)
            if datetime.now().hour == 2:  # æ¯æ—¥åˆå‰2æ™‚
                codeql_results = await self.run_codeql_scan()
                for issue in codeql_results:
                    errors.append(ErrorEvent(
                        timestamp=datetime.now(),
                        source='static',
                        severity='critical',
                        message=f'Security vulnerability: {issue["type"]}',
                        metadata=issue
                    ))

            # ã‚¨ãƒ©ãƒ¼ç™ºè¦‹æ™‚ã«Self-Healingã‚’ãƒˆãƒªã‚¬ãƒ¼
            if errors:
                await self.trigger_self_healing(errors)

            await asyncio.sleep(60)  # 1åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯

    async def get_current_metrics(self) -> List[float]:
        """ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        # å®Ÿè£…ä¾‹: Prometheus APIå‘¼ã³å‡ºã—
        return [45.2, 768, 0.25]  # [cpu%, memory_mb, latency_sec]

    async def check_prometheus_alerts(self) -> List[Dict]:
        """Prometheusã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª"""
        # å®Ÿè£…ä¾‹: Prometheus Alertmanager API
        return []

    async def run_codeql_scan(self) -> List[Dict]:
        """CodeQLã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ"""
        # å®Ÿè£…ä¾‹: CodeQL CLIå‘¼ã³å‡ºã—
        return []

    async def trigger_self_healing(self, errors: List[ErrorEvent]):
        """Self-Healingãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹"""
        print(f"ğŸš¨ {len(errors)}å€‹ã®ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã€Self-Healingé–‹å§‹")
        for error in errors:
            print(f"  - [{error.severity}] {error.message}")
        # æ¬¡ã®ãƒ¬ã‚·ãƒ”ã§å®Ÿè£…
```

### èª¬æ˜(Explanation)

#### å„æ–¹æ³•è«–ã®é•·æ‰€ã¨çŸ­æ‰€

| æ–¹æ³• | é•·æ‰€ | çŸ­æ‰€ | é©ç”¨æ™‚æœŸ |
|------|------|------|----------|
| <strong>ç•°å¸¸æ¤œå‡º</strong> | æœªçŸ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ | èª¤æ¤œçŸ¥ã®å¯èƒ½æ€§ | ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ |
| <strong>ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç›£è¦–</strong> | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€æ­£ç¢º | ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©ãŒå¿…è¦ | æ—¢çŸ¥ã®å•é¡Œæ¤œå‡º |
| <strong>ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æ</strong> | ãƒ‡ãƒ—ãƒ­ã‚¤å‰ã«ç™ºè¦‹ | é…ã„ã€é™çš„åˆ†æã®é™ç•Œ | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰å“è³ª |

#### èª¤æ¤œçŸ¥ã‚’æ¸›ã‚‰ã™

```python
class SmartAlertingSystem:
    def __init__(self, threshold=3):
        self.threshold = threshold  # 3å›é€£ç¶šç™ºç”Ÿæ™‚ã®ã¿ã‚¢ãƒ©ãƒ¼ãƒˆ
        self.error_counts = {}

    async def should_alert(self, error_signature: str) -> bool:
        """é€£ç¶šç™ºç”Ÿå›æ•°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ãƒ¼ãƒˆ"""

        self.error_counts[error_signature] = \
            self.error_counts.get(error_signature, 0) + 1

        if self.error_counts[error_signature] >= self.threshold:
            # ã‚¢ãƒ©ãƒ¼ãƒˆå¾Œã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒªã‚»ãƒƒãƒˆ
            self.error_counts[error_signature] = 0
            return True

        return False
```

### å¤‰å½¢(Variations)

#### 1. ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–ç›£è¦–

```python
# AWS CloudWatchçµ±åˆ
import boto3

cloudwatch = boto3.client('cloudwatch')

def check_cloudwatch_alarms():
    response = cloudwatch.describe_alarms(
        StateValue='ALARM'
    )

    return response['MetricAlarms']

# Datadogçµ±åˆ
from datadog import api, initialize

initialize(api_key='YOUR_API_KEY', app_key='YOUR_APP_KEY')

def check_datadog_monitors():
    monitors = api.Monitor.get_all(
        group_states='alert'
    )

    return monitors
```

#### 2. ãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ©ãƒ¼æ¤œå‡º

```python
import re
from collections import defaultdict

class LogBasedDetector:
    ERROR_PATTERNS = [
        r'ERROR',
        r'FATAL',
        r'Exception',
        r'Traceback',
        r'ConnectionRefusedError'
    ]

    def __init__(self, log_file: str):
        self.log_file = log_file
        self.error_counts = defaultdict(int)

    async def monitor_logs(self):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–"""

        with open(self.log_file, 'r') as f:
            # ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ã«ç§»å‹•
            f.seek(0, 2)

            while True:
                line = f.readline()

                if not line:
                    await asyncio.sleep(0.1)
                    continue

                # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
                for pattern in self.ERROR_PATTERNS:
                    if re.search(pattern, line):
                        self.error_counts[pattern] += 1

                        if self.error_counts[pattern] >= 5:
                            yield ErrorEvent(
                                timestamp=datetime.now(),
                                source='logs',
                                severity='high',
                                message=f'Pattern {pattern} detected 5+ times',
                                metadata={'line': line}
                            )
```

---

## Recipe 13.3: Root Cause Analysis

### å•é¡Œ(Problem)

ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã—ãŸã‚‰ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯<strong>æ ¹æœ¬åŸå› (Root Cause)</strong>ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ã§ã™ã€‚å˜ã«ç—‡çŠ¶ã ã‘ã‚’è¦‹ã¦ä¿®æ­£ã™ã‚‹ã¨:

- å¿œæ€¥å‡¦ç½®ã«çµ‚ã‚ã‚ŠåŒã˜å•é¡ŒãŒå†ç™º
- èª¤ã£ãŸä¿®æ­£ã§æ–°ã—ã„ãƒã‚°ã‚’å°å…¥
- ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ç†è§£ä¸è¶³

### è§£æ±ºç­–(Solution)

LLM(Large Language Model)ã‚’æ´»ç”¨ã—ã¦ã‚¨ãƒ©ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã—ã€æ ¹æœ¬åŸå› ã‚’æ¨è«–ã—ã¾ã™ã€‚

#### åˆ†æã«å¿…è¦ãªæƒ…å ±

1. <strong>ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</strong>: ç›´æ¥çš„ãªã‚¨ãƒ©ãƒ¼å†…å®¹
2. <strong>ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹</strong>: å‘¼ã³å‡ºã—çµŒè·¯
3. <strong>é–¢é€£ã‚³ãƒ¼ãƒ‰</strong>: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿåœ°ç‚¹ã®ã‚³ãƒ¼ãƒ‰
4. <strong>æœ€è¿‘ã®å¤‰æ›´</strong>: Gitã‚³ãƒŸãƒƒãƒˆå±¥æ­´
5. <strong>ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹</strong>: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒ­ã‚°

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### 1. LLMãƒ™ãƒ¼ã‚¹ã®æ ¹æœ¬åŸå› åˆ†æå™¨

```python
from openai import AsyncOpenAI
from anthropic import Anthropic
from typing import Dict, Any
import json

class RootCauseAnalyzer:
    def __init__(self, provider='openai'):
        """
        Args:
            provider: 'openai' ã¾ãŸã¯ 'anthropic'
        """
        if provider == 'openai':
            self.client = AsyncOpenAI()
            self.model = "gpt-4-turbo-preview"
        else:
            self.client = Anthropic()
            self.model = "claude-3-5-sonnet-20241022"

        self.provider = provider

    async def analyze(self, error_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’LLMã§åˆ†æ

        Args:
            error_data: {
                'message': str,
                'stack_trace': str,
                'code_snippet': str,
                'recent_commits': List[str],
                'metrics': Dict
            }

        Returns:
            {
                'root_cause': str,
                'affected_files': List[str],
                'fix_strategy': str,
                'confidence': float  # 0ã€œ1
            }
        """

        prompt = self._build_analysis_prompt(error_data)

        if self.provider == 'openai':
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ©ãƒ¼åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚"
                                   "æ ¹æœ¬åŸå› ã‚’è¦‹ã¤ã‘ã€ä¿®æ­£æˆ¦ç•¥ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,  # ä¸€è²«æ€§ã®ã‚ã‚‹åˆ†æã®ãŸã‚ä½ã„temperature
                response_format={"type": "json_object"}
            )

            analysis = json.loads(response.choices[0].message.content)

        else:  # Anthropic
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                temperature=0.1,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # JSONãƒ‘ãƒ¼ã‚¹
            analysis = json.loads(response.content[0].text)

        return analysis

    def _build_analysis_prompt(self, error_data: Dict[str, Any]) -> str:
        """åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹æˆ"""

        return f"""
æ¬¡ã®ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æã—ã¦æ ¹æœ¬åŸå› ã‚’æŠŠæ¡ã—ã¦ãã ã•ã„:

## ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
{error_data.get('message', 'N/A')}

## ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹
```
{error_data.get('stack_trace', 'N/A')}
```

## é–¢é€£ã‚³ãƒ¼ãƒ‰
```python
{error_data.get('code_snippet', 'N/A')}
```

## æœ€è¿‘ã®å¤‰æ›´(Git Commits)
{self._format_commits(error_data.get('recent_commits', []))}

## ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
{json.dumps(error_data.get('metrics', {}), indent=2)}

---

æ¬¡ã®JSONå½¢å¼ã§åˆ†æçµæœã‚’æä¾›ã—ã¦ãã ã•ã„:

{{
  "root_cause": "æ ¹æœ¬åŸå› ã®æ˜ç¢ºãªèª¬æ˜",
  "affected_files": ["å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"],
  "fix_strategy": "ä¿®æ­£æˆ¦ç•¥(æ®µéšçš„ã«)",
  "confidence": 0.85,
  "additional_context": "è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±"
}}
"""

    def _format_commits(self, commits: list) -> str:
        """ã‚³ãƒŸãƒƒãƒˆãƒªã‚¹ãƒˆã‚’èª­ã¿ã‚„ã™ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

        if not commits:
            return "æœ€è¿‘ã®å¤‰æ›´ãªã—"

        formatted = []
        for commit in commits:
            formatted.append(f"- {commit['hash'][:7]}: {commit['message']}")

        return "\n".join(formatted)

# ä½¿ç”¨ä¾‹
async def analyze_database_error():
    analyzer = RootCauseAnalyzer(provider='openai')

    error_data = {
        'message': 'psycopg2.OperationalError: connection pool exhausted',
        'stack_trace': '''
Traceback (most recent call last):
  File "app.py", line 42, in get_users
    conn = db_pool.getconn()
  File "psycopg2/pool.py", line 137, in getconn
    raise PoolError("connection pool exhausted")
''',
        'code_snippet': '''
async def get_users(request):
    conn = db_pool.getconn()  # æ¥ç¶šå–å¾—
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM users")
        return cursor.fetchall()
    finally:
        pass  # BUG: connection not returned!
''',
        'recent_commits': [
            {
                'hash': 'a1b2c3d',
                'message': 'feat: add user list endpoint'
            }
        ],
        'metrics': {
            'active_connections': 20,
            'max_connections': 20,
            'requests_per_minute': 150
        }
    }

    analysis = await analyzer.analyze(error_data)

    print("ğŸ“Š æ ¹æœ¬åŸå› åˆ†æçµæœ:")
    print(f"æ ¹æœ¬åŸå› : {analysis['root_cause']}")
    print(f"å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(analysis['affected_files'])}")
    print(f"ä¿®æ­£æˆ¦ç•¥: {analysis['fix_strategy']}")
    print(f"ä¿¡é ¼åº¦: {analysis['confidence']*100:.1f}%")

# å®Ÿè¡Œ
if __name__ == "__main__":
    import asyncio
    asyncio.run(analyze_database_error())
```

#### 2. å®Ÿéš›ã®åˆ†æçµæœä¾‹

ä¸Šè¨˜ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã«LLMãŒè¿”ã™åˆ†æçµæœ:

```json
{
  "root_cause": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ãŒæ¯æ¸‡ã—ã¾ã—ãŸã€‚åŸå› ã¯`get_users()`é–¢æ•°ã§æ¥ç¶šã‚’å–å¾—ã—ãŸå¾Œã€è¿”å´ã—ã¦ã„ãªã„ãŸã‚ã§ã™ã€‚finallyãƒ–ãƒ­ãƒƒã‚¯ã«`db_pool.putconn(conn)`å‘¼ã³å‡ºã—ãŒæ¬ è½ã—ã¦ã„ã¾ã™ã€‚",

  "affected_files": [
    "app.py"
  ],

  "fix_strategy": "1. `get_users()`é–¢æ•°ã®finallyãƒ–ãƒ­ãƒƒã‚¯ã«`db_pool.putconn(conn)`ã‚’è¿½åŠ \n2. ã‚ˆã‚Šè‰¯ã„æ–¹æ³•: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½¿ç”¨(`with db_pool.getconn() as conn`)\n3. æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚’ç›£è¦–ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ \n4. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã§ç„¡é™å¾…æ©Ÿã‚’é˜²æ­¢",

  "confidence": 0.95,

  "additional_context": "ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§active_connectionsãŒmax_connectionsã¨åŒã˜ãŸã‚ã€ãƒ—ãƒ¼ãƒ«ãŒå®Œå…¨ã«æ¯æ¸‡ã—ãŸçŠ¶æ…‹ã§ã™ã€‚æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆã§è¿½åŠ ã•ã‚ŒãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå•é¡Œã®åŸå› ã§ã‚ã‚‹å¯èƒ½æ€§ãŒéå¸¸ã«é«˜ã„ã§ã™ã€‚"
}
```

### èª¬æ˜(Explanation)

#### LLMãŒæ ¹æœ¬åŸå› åˆ†æã«æœ‰ç”¨ãªç†ç”±

1. <strong>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£</strong>: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚³ãƒ¼ãƒ‰ã€å¤‰æ›´å±¥æ­´ã‚’ç·åˆåˆ†æ
2. <strong>ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜</strong>: æ•°ç™¾ä¸‡ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å­¦ç¿’ã—ãŸä¸€èˆ¬çš„ãªãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èªè­˜
3. <strong>æ¨è«–èƒ½åŠ›</strong>: ç›´æ¥çš„ã«ç¾ã‚Œãªã„åŸå› ã‚‚æ¨è«–å¯èƒ½
4. <strong>èª¬æ˜ç”Ÿæˆ</strong>: äººãŒç†è§£ã—ã‚„ã™ã„èª¬æ˜ã‚’æä¾›

#### ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®æ´»ç”¨

```python
def decide_action_based_on_confidence(analysis):
    """ä¿¡é ¼åº¦ã«å¿œã˜ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ±ºå®š"""

    confidence = analysis['confidence']

    if confidence >= 0.9:
        print("âœ… é«˜ä¿¡é ¼åº¦: è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ")
        return 'auto_fix'

    elif confidence >= 0.7:
        print("âš ï¸ ä¸­é–“ä¿¡é ¼åº¦: ä¿®æ­£ç”Ÿæˆå¾Œãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼")
        return 'generate_and_review'

    else:
        print("âŒ ä½ä¿¡é ¼åº¦: äººé–“ã®ä»‹å…¥ãŒå¿…è¦")
        return 'escalate_to_human'
```

### å¤‰å½¢(Variations)

#### 1. ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†æ

è¤‡æ•°ã®LLMã®åˆ†æã‚’æ¯”è¼ƒã—ã¦ç²¾åº¦å‘ä¸Š:

```python
class EnsembleRootCauseAnalyzer:
    def __init__(self):
        self.analyzers = [
            RootCauseAnalyzer(provider='openai'),
            RootCauseAnalyzer(provider='anthropic'),
        ]

    async def analyze_with_ensemble(self, error_data):
        """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®åˆ†æçµæœã‚’çµ±åˆ"""

        # ä¸¦åˆ—ã§åˆ†æå®Ÿè¡Œ
        analyses = await asyncio.gather(*[
            analyzer.analyze(error_data)
            for analyzer in self.analyzers
        ])

        # åˆæ„åˆ†æ(æœ€ã‚‚å¤šãè¨€åŠã•ã‚ŒãŸæ ¹æœ¬åŸå› )
        root_causes = [a['root_cause'] for a in analyses]

        # å¹³å‡ä¿¡é ¼åº¦
        avg_confidence = sum(a['confidence'] for a in analyses) / len(analyses)

        return {
            'consensus_root_cause': self._find_consensus(root_causes),
            'all_analyses': analyses,
            'avg_confidence': avg_confidence
        }

    def _find_consensus(self, root_causes):
        """æœ€ã‚‚ä¸€è²«æ€§ã®ã‚ã‚‹æ ¹æœ¬åŸå› ã‚’è¦‹ã¤ã‘ã‚‹"""
        # å®Ÿè£…ä¾‹: åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦æ¯”è¼ƒ
        return root_causes[0]  # ç°¡ç•¥åŒ–
```

#### 2. éå»äº‹ä¾‹ãƒ™ãƒ¼ã‚¹ã®åˆ†æ(RAG)

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

class RAGRootCauseAnalyzer:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            collection_name="past_errors",
            embedding_function=self.embeddings
        )

    async def analyze_with_history(self, error_data):
        """éå»ã®é¡ä¼¼äº‹ä¾‹ã‚’å‚ç…§ã—ã¦åˆ†æ"""

        # 1. é¡ä¼¼ã—ãŸéå»ã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œç´¢
        similar_cases = self.vector_store.similarity_search(
            query=error_data['message'],
            k=3
        )

        # 2. éå»äº‹ä¾‹ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã‚ã‚‹
        enhanced_prompt = f"""
éå»ã®é¡ä¼¼äº‹ä¾‹:
{self._format_similar_cases(similar_cases)}

ç¾åœ¨ã®ã‚¨ãƒ©ãƒ¼:
{error_data['message']}

éå»äº‹ä¾‹ã‚’å‚è€ƒã«æ ¹æœ¬åŸå› ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
"""

        # 3. LLMåˆ†æ
        analysis = await self.client.generate(enhanced_prompt)

        return analysis

    def save_successful_fix(self, error_data, fix_data):
        """æˆåŠŸã—ãŸä¿®æ­£äº‹ä¾‹ã‚’ä¿å­˜(å­¦ç¿’)"""

        self.vector_store.add_texts(
            texts=[error_data['message']],
            metadatas=[{
                'root_cause': fix_data['root_cause'],
                'solution': fix_data['code'],
                'timestamp': datetime.now().isoformat()
            }]
        )
```

---

## Recipe 13.4: Fix Generationè‡ªå‹•åŒ–

### å•é¡Œ(Problem)

æ ¹æœ¬åŸå› ã‚’æŠŠæ¡ã—ãŸã‚‰ã€æ¬¡ã¯å®Ÿéš›ã®<strong>ä¿®æ­£ã‚³ãƒ¼ãƒ‰</strong>ã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚èª²é¡Œ:

- æ­£ç¢ºãªä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
- æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ç¶­æŒ
- å‰¯ä½œç”¨ã®ãªã„ä¿®æ­£
- ãƒ†ã‚¹ãƒˆé€šéã®ä¿è¨¼

### è§£æ±ºç­–(Solution)

2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¯”è¼ƒã—ã¾ã™:

1. <strong>Multi-Agentæ–¹å¼</strong>: è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”åŠ›(Plan â†’ Code â†’ Review â†’ Test)
2. <strong>Agentlessæ–¹å¼</strong>: å˜ä¸€LLMå‘¼ã³å‡ºã—ã§ç›´æ¥ä¿®æ­£(ã‚ˆã‚Šé«˜ã„æˆåŠŸç‡!)

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### 1. Agentlessæ–¹å¼(æ¨å¥¨)

SWE-benchã§50.8%ã®æˆåŠŸç‡ã§Multi-Agent(33.6%)ã‚ˆã‚Šå„ªç§€:

```python
from openai import AsyncOpenAI
from typing import Dict, Any

class AgentlessFixGenerator:
    def __init__(self):
        self.client = AsyncOpenAI()
        self.model = "gpt-4-turbo-preview"

    async def generate_fix(self, error_context: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€LLMå‘¼ã³å‡ºã—ã§ä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ

        Args:
            error_context: {
                'error': str,           # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                'root_cause': str,      # æ ¹æœ¬åŸå› åˆ†æçµæœ
                'code': str,            # å…ƒã®ã‚³ãƒ¼ãƒ‰
                'file_path': str,       # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                'tests': str            # é–¢é€£ãƒ†ã‚¹ãƒˆ
            }

        Returns:
            {
                'fixed_code': str,      # ä¿®æ­£ã•ã‚ŒãŸå…¨ä½“ã‚³ãƒ¼ãƒ‰
                'explanation': str,     # ä¿®æ­£èª¬æ˜
                'diff': str            # å¤‰æ›´å†…å®¹ã®diff
            }
        """

        prompt = f"""
ã‚ãªãŸã¯å°‚é–€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚æ¬¡ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## ã‚¨ãƒ©ãƒ¼æƒ…å ±
{error_context['error']}

## æ ¹æœ¬åŸå› 
{error_context['root_cause']}

## å…ƒã®ã‚³ãƒ¼ãƒ‰({error_context['file_path']})
```python
{error_context['code']}
```

## é–¢é€£ãƒ†ã‚¹ãƒˆ
```python
{error_context['tests']}
```

---

<strong>è¦ä»¶</strong>:
1. ã™ã¹ã¦ã®æ—¢å­˜ãƒ†ã‚¹ãƒˆãŒé€šéã™ã‚‹ã“ã¨
2. æ–°ã—ã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨
3. ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å…ƒã¨ä¸€è²«ã—ã¦ç¶­æŒ
4. ã‚³ãƒ¡ãƒ³ãƒˆã§ä¿®æ­£å†…å®¹ã‚’èª¬æ˜è¿½åŠ 

<strong>å‡ºåŠ›å½¢å¼</strong>(JSON):
{{
  "fixed_code": "ä¿®æ­£ã•ã‚ŒãŸå…¨ä½“ã‚³ãƒ¼ãƒ‰",
  "explanation": "ä¿®æ­£å†…å®¹ã®èª¬æ˜",
  "changes": ["å¤‰æ›´å†…å®¹1", "å¤‰æ›´å†…å®¹2"]
}}
"""

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ãƒã‚°ä¿®æ­£ã®å°‚é–€å®¶ã§ã™ã€‚"
                               "å¸¸ã«å®‰å…¨ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã¾ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.2,  # ä¸€è²«æ€§å„ªå…ˆ
            response_format={"type": "json_object"}
        )

        import json
        fix_data = json.loads(response.choices[0].message.content)

        # Diffç”Ÿæˆ
        fix_data['diff'] = self._generate_diff(
            error_context['code'],
            fix_data['fixed_code']
        )

        return fix_data

    def _generate_diff(self, original: str, fixed: str) -> str:
        """å¤‰æ›´å†…å®¹ã®diffç”Ÿæˆ"""

        import difflib

        diff = difflib.unified_diff(
            original.splitlines(keepends=True),
            fixed.splitlines(keepends=True),
            lineterm='',
            fromfile='original',
            tofile='fixed'
        )

        return ''.join(diff)

# ä½¿ç”¨ä¾‹
async def fix_database_connection_bug():
    generator = AgentlessFixGenerator()

    error_context = {
        'error': 'psycopg2.OperationalError: connection pool exhausted',
        'root_cause': 'æ¥ç¶šå–å¾—å¾Œã«è¿”å´ã›ãšãƒ—ãƒ¼ãƒ«ãŒæ¯æ¸‡',
        'code': '''
async def get_users(request):
    conn = db_pool.getconn()
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM users")
        return cursor.fetchall()
    finally:
        pass  # BUG: connection not returned!
''',
        'file_path': 'app.py',
        'tests': '''
def test_get_users():
    users = get_users(mock_request)
    assert len(users) > 0
'''
    }

    fix = await generator.generate_fix(error_context)

    print("ğŸ”§ ç”Ÿæˆã•ã‚ŒãŸä¿®æ­£ã‚³ãƒ¼ãƒ‰:")
    print(fix['fixed_code'])
    print("\nğŸ“ èª¬æ˜:")
    print(fix['explanation'])
    print("\nğŸ“Š å¤‰æ›´å†…å®¹:")
    print(fix['diff'])

if __name__ == "__main__":
    import asyncio
    asyncio.run(fix_database_connection_bug())
```

#### 2. Multi-Agentæ–¹å¼(LangGraph)

è¤‡é›‘ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºç’°å¢ƒã§ã¯å½¹å‰²åˆ†é›¢ãŒæœ‰ç”¨:

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

class FixGenerationState(TypedDict):
    error: str
    root_cause: str
    code: str
    plan: str
    fixed_code: str
    review_comments: str
    approved: bool
    attempts: Annotated[int, operator.add]

class MultiAgentFixGenerator:
    def __init__(self):
        self.workflow = StateGraph(FixGenerationState)
        self.setup_workflow()

    def setup_workflow(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹æˆ"""

        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        self.workflow.add_node("planner", self.plan_fix)
        self.workflow.add_node("coder", self.generate_code)
        self.workflow.add_node("reviewer", self.review_code)

        # ãƒ•ãƒ­ãƒ¼å®šç¾©
        self.workflow.set_entry_point("planner")
        self.workflow.add_edge("planner", "coder")
        self.workflow.add_edge("coder", "reviewer")

        # æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸: ãƒ¬ãƒ“ãƒ¥ãƒ¼é€šéæ™‚çµ‚äº†ã€å¤±æ•—æ™‚å†ä½œæˆ
        self.workflow.add_conditional_edges(
            "reviewer",
            self.should_retry,
            {
                "approve": END,
                "revise": "coder",
                "give_up": END
            }
        )

        self.app = self.workflow.compile()

    async def plan_fix(self, state: FixGenerationState) -> dict:
        """1æ®µéš: ä¿®æ­£è¨ˆç”»ç­–å®š"""

        plan = await llm_call(f"""
æ¬¡ã®å•é¡Œã«å¯¾ã™ã‚‹ä¿®æ­£è¨ˆç”»ã‚’ç­–å®šã—ã¦ãã ã•ã„:

ã‚¨ãƒ©ãƒ¼: {state['error']}
æ ¹æœ¬åŸå› : {state['root_cause']}

æ®µéšçš„ãªä¿®æ­£è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
""")

        print("ğŸ“‹ ä¿®æ­£è¨ˆç”»ç­–å®šå®Œäº†")
        return {"plan": plan}

    async def generate_code(self, state: FixGenerationState) -> dict:
        """2æ®µéš: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""

        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã‚Œã°åæ˜ 
        feedback = state.get('review_comments', '')

        fixed_code = await llm_call(f"""
æ¬¡ã®è¨ˆç”»ã‚’ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã—ã¦ãã ã•ã„:

è¨ˆç”»: {state['plan']}
å…ƒã®ã‚³ãƒ¼ãƒ‰: {state['code']}

{f'å‰å›ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {feedback}' if feedback else ''}

ä¿®æ­£ã•ã‚ŒãŸå…¨ä½“ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
""")

        print("ğŸ’» ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†")
        return {"fixed_code": fixed_code, "attempts": 1}

    async def review_code(self, state: FixGenerationState) -> dict:
        """3æ®µéš: ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼"""

        review = await llm_call(f"""
æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:

å…ƒ: {state['code']}
ä¿®æ­£ç‰ˆ: {state['fixed_code']}

æ¬¡ã®åŸºæº–ã§è©•ä¾¡:
1. ãƒã‚°ãŒä¿®æ­£ã•ã‚Œã¦ã„ã‚‹ã‹?
2. æ–°ã—ã„ãƒã‚°ãŒãªã„ã‹?
3. ã‚³ãƒ¼ãƒ‰å“è³ªãŒç¶­æŒã•ã‚Œã¦ã„ã‚‹ã‹?

æ‰¿èªã™ã‚‹ã«ã¯ã€ŒLGTMã€ã‚’ã€ä¿®æ­£ãŒå¿…è¦ãªã‚‰å…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãã ã•ã„ã€‚
""")

        approved = "LGTM" in review

        print(f"ğŸ‘€ ãƒ¬ãƒ“ãƒ¥ãƒ¼ {'æ‰¿èª' if approved else 'å´ä¸‹'}")

        return {
            "review_comments": review,
            "approved": approved
        }

    def should_retry(self, state: FixGenerationState) -> str:
        """å†è©¦è¡Œã®åˆ¤å®š"""

        if state['approved']:
            return "approve"
        elif state['attempts'] < 3:
            print("ğŸ”„ å†ä½œæˆè©¦è¡Œ")
            return "revise"
        else:
            print("âŒ 3å›è©¦è¡Œå¤±æ•—ã€è«¦ã‚ã‚‹")
            return "give_up"

    async def generate(self, error, root_cause, code):
        """å…¨ä½“ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ"""

        result = await self.app.ainvoke({
            "error": error,
            "root_cause": root_cause,
            "code": code,
            "attempts": 0,
            "approved": False
        })

        return result

# LLMå‘¼ã³å‡ºã—ãƒ˜ãƒ«ãƒ‘ãƒ¼(å®Ÿè£…ä¾‹)
async def llm_call(prompt: str) -> str:
    from openai import AsyncOpenAI
    client = AsyncOpenAI()

    response = await client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )

    return response.choices[0].message.content
```

### èª¬æ˜(Explanation)

#### Agentless vs Multi-Agentã®æ¯”è¼ƒ

| é …ç›® | Agentless | Multi-Agent |
|------|-----------|-------------|
| <strong>æˆåŠŸç‡</strong> | 50.8% (SWE-bench) | 33.6% (SWE-bench) |
| <strong>é€Ÿåº¦</strong> | é€Ÿã„(1å›å‘¼ã³å‡ºã—) | é…ã„(3ã€œ5å›å‘¼ã³å‡ºã—) |
| <strong>ã‚³ã‚¹ãƒˆ</strong> | ä½ã„ | é«˜ã„ |
| <strong>è¤‡é›‘åº¦</strong> | ä½ã„ | é«˜ã„ |
| <strong>é©ç”¨æ™‚æœŸ</strong> | å˜ç´”ã€œä¸­ç¨‹åº¦ã®è¤‡é›‘åº¦ãƒã‚° | å¤§è¦æ¨¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´ |

#### SWE-bench 2025å¹´ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰

| é †ä½ | ã‚·ã‚¹ãƒ†ãƒ  | æˆåŠŸç‡ | ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ |
|------|--------|--------|-----------|
| 1ä½ | <strong>TRAE</strong> | 70.4% | o1 + Claude 3.7 + Gemini 2.5 Proã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« |
| 2ä½ | <strong>Mini-SWE-agent</strong> | 65% | 100è¡ŒPython(è¶…è»½é‡) |
| 3ä½ | <strong>AgentScope</strong> | 63.4% | Qwen2.5 + Claude 3.5 Sonnet |
| 4ä½ | Agentless | 50.8% | å˜ä¸€LLM |
| 5ä½ | SWE-Agent | 33.6% | ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ |

<strong>æ ¸å¿ƒçš„ãªæ´å¯Ÿ</strong>:
- <strong>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« > å˜ä¸€ãƒ¢ãƒ‡ãƒ«</strong>: TRAEã¯3ã¤ã®æœ€é«˜ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›
- <strong>ã‚·ãƒ³ãƒ—ãƒ« > è¤‡é›‘</strong>: Mini-SWE-agentã¯100è¡Œã§65%(SWE-Agentã®2å€)
- <strong>AgentlessãŒå„ªç§€</strong>: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãªã—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚€ã—ã‚åŠ¹æœçš„

### å¤‰å½¢(Variations)

#### 1. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«Fix Generation(TRAEæ–¹å¼)

```python
class EnsembleFixGenerator:
    def __init__(self):
        self.generators = [
            AgentlessFixGenerator(model="gpt-4-turbo"),
            AgentlessFixGenerator(model="claude-3-5-sonnet"),
            AgentlessFixGenerator(model="gemini-2.5-pro")
        ]

    async def generate_with_ensemble(self, error_context):
        """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¿®æ­£æ¡ˆã‚’ç”Ÿæˆã—æœ€é©ãªã‚‚ã®ã‚’é¸æŠ"""

        # ä¸¦åˆ—ã§ä¿®æ­£ç”Ÿæˆ
        fixes = await asyncio.gather(*[
            gen.generate_fix(error_context)
            for gen in self.generators
        ])

        # å„ä¿®æ­£æ¡ˆã‚’ãƒ†ã‚¹ãƒˆ
        test_results = await asyncio.gather(*[
            test_fix(fix['fixed_code'], error_context['tests'])
            for fix in fixes
        ])

        # ãƒ†ã‚¹ãƒˆé€šéã—ãŸä¿®æ­£æ¡ˆã®ä¸­ã§æœ€ã‚‚ç°¡æ½”ãªã‚‚ã®ã‚’é¸æŠ
        passing_fixes = [
            fix for fix, result in zip(fixes, test_results)
            if result['all_passed']
        ]

        if passing_fixes:
            # ã‚³ãƒ¼ãƒ‰é•·ãŒçŸ­ã„é †ã«ã‚½ãƒ¼ãƒˆ(ã‚·ãƒ³ãƒ—ãƒ«å„ªå…ˆ)
            best_fix = min(passing_fixes, key=lambda f: len(f['fixed_code']))
            return best_fix

        return None  # å…¨ã¦ã®ä¿®æ­£æ¡ˆãŒå¤±æ•—

async def test_fix(code, tests):
    """ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
    # å®Ÿè£…ä¾‹: pytestå®Ÿè¡Œ
    return {'all_passed': True}
```

#### 2. æ®µéšçš„ä¿®æ­£(Incremental Fix)

```python
class IncrementalFixGenerator:
    async def generate_minimal_fix(self, error_context):
        """æœ€å°é™ã®å¤‰æ›´ã§ä¿®æ­£"""

        prompt = f"""
æ¬¡ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¾ã™ãŒã€<strong>æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ã®ã¿å¤‰æ›´</strong>ã—ã¦ãã ã•ã„:

ã‚¨ãƒ©ãƒ¼: {error_context['error']}
ã‚³ãƒ¼ãƒ‰: {error_context['code']}

å‡ºåŠ›å½¢å¼:
{{
  "lines_to_change": {{
    "42": "new content for line 42",
    "45": "new content for line 45"
  }},
  "explanation": "èª¬æ˜"
}}
"""

        fix = await llm_call(prompt)

        # è¡Œå˜ä½ã§ä¿®æ­£é©ç”¨
        return self._apply_line_changes(
            error_context['code'],
            fix['lines_to_change']
        )
```

---

## Recipe 13.5: Testing & Learningã‚µã‚¤ã‚¯ãƒ«

### å•é¡Œ(Problem)

ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ãŸã‚‰ã€ãƒ‡ãƒ—ãƒ­ã‚¤å‰ã«<strong>å¾¹åº•çš„ãªæ¤œè¨¼</strong>ãŒå¿…è¦ã§ã™:

- ä¿®æ­£ãŒå®Ÿéš›ã«ãƒã‚°ã‚’è§£æ±ºã—ã¦ã„ã‚‹ã‹?
- æ–°ã—ã„ãƒã‚°ã‚’å°å…¥ã—ã¦ã„ãªã„ã‹?
- ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒé€šéã™ã‚‹ã‹?
- å¤±æ•—æ™‚ã«ã©ã†è‡ªå·±ä¿®æ­£ã™ã‚‹ã‹?

### è§£æ±ºç­–(Solution)

<strong>Self-Correction Loop</strong>ã‚’å®Ÿè£…ã—ã¾ã™:

1. ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
2. å¤±æ•—æ™‚ã®åŸå› åˆ†æ(Reflection)
3. è‡ªå·±ä¿®æ­£(Self-Correction)
4. æœ€å¤§3å›å†è©¦è¡Œ
5. æˆåŠŸæ™‚ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### 1. Self-Correction Loopå®Ÿè£…

```python
from typing import Dict, Any, List
import subprocess
import tempfile
import os

class SelfCorrectingTester:
    MAX_RETRIES = 3

    def __init__(self):
        self.client = AsyncOpenAI()

    async def validate_fix(
        self,
        original_code: str,
        fixed_code: str,
        test_suite: str,
        file_path: str
    ) -> Dict[str, Any]:
        """ä¿®æ­£å†…å®¹ã®æ¤œè¨¼(æœ€å¤§3å›å†è©¦è¡Œ)

        Returns:
            {
                'success': bool,
                'final_code': str,
                'test_results': dict,
                'attempts': int,
                'reflections': List[str]
            }
        """

        current_code = fixed_code
        reflections = []

        for attempt in range(1, self.MAX_RETRIES + 1):
            print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆè©¦è¡Œ {attempt}/{self.MAX_RETRIES}")

            # 1. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            result = await self.run_tests(current_code, test_suite, file_path)

            if result['all_passed']:
                print(f"âœ… ãƒ†ã‚¹ãƒˆé€šé! ({attempt}å›è©¦è¡Œ)")

                return {
                    'success': True,
                    'final_code': current_code,
                    'test_results': result,
                    'attempts': attempt,
                    'reflections': reflections
                }

            # 2. å¤±æ•—æ™‚ã®åŸå› åˆ†æ(Reflection)
            print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—ã€åŸå› åˆ†æä¸­...")
            reflection = await self.reflect_on_failure(
                code=current_code,
                failures=result['failures']
            )
            reflections.append(reflection)

            # 3. è‡ªå·±ä¿®æ­£(Self-Correction)
            print(f"ğŸ”§ è‡ªå·±ä¿®æ­£è©¦è¡Œä¸­...")
            current_code = await self.apply_reflection(
                code=current_code,
                reflection=reflection
            )

        # 3å›å¤±æ•—æ™‚ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print(f"âš ï¸ {self.MAX_RETRIES}å›è©¦è¡Œå¾Œå¤±æ•—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯")

        return {
            'success': False,
            'final_code': original_code,  # å…ƒã«æˆ»ã™
            'test_results': result,
            'attempts': self.MAX_RETRIES,
            'reflections': reflections
        }

    async def run_tests(
        self,
        code: str,
        test_suite: str,
        file_path: str
    ) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

        Returns:
            {
                'all_passed': bool,
                'passed': int,
                'failed': int,
                'failures': List[dict]
            }
        """

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãè¾¼ã¿
        with tempfile.TemporaryDirectory() as tmpdir:
            # ä¿®æ­£ã‚³ãƒ¼ãƒ‰ä¿å­˜
            code_file = os.path.join(tmpdir, os.path.basename(file_path))
            with open(code_file, 'w') as f:
                f.write(code)

            # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ä¿å­˜
            test_file = os.path.join(tmpdir, 'test_fix.py')
            with open(test_file, 'w') as f:
                f.write(test_suite)

            # pytestå®Ÿè¡Œ
            result = subprocess.run(
                ['pytest', test_file, '-v', '--json-report', '--json-report-file=report.json'],
                cwd=tmpdir,
                capture_output=True,
                text=True
            )

            # çµæœãƒ‘ãƒ¼ã‚¹
            import json
            report_file = os.path.join(tmpdir, 'report.json')

            if os.path.exists(report_file):
                with open(report_file) as f:
                    report = json.load(f)

                failures = [
                    {
                        'test': test['nodeid'],
                        'error': test.get('call', {}).get('longrepr', ''),
                        'line': test.get('lineno')
                    }
                    for test in report.get('tests', [])
                    if test.get('outcome') == 'failed'
                ]

                return {
                    'all_passed': len(failures) == 0,
                    'passed': report['summary']['passed'],
                    'failed': report['summary'].get('failed', 0),
                    'failures': failures
                }

            # pytest-json-reportæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã®fallback
            return {
                'all_passed': result.returncode == 0,
                'passed': 0 if result.returncode != 0 else 1,
                'failed': 1 if result.returncode != 0 else 0,
                'failures': [{'error': result.stdout + result.stderr}] if result.returncode != 0 else []
            }

    async def reflect_on_failure(self, code: str, failures: List[dict]) -> str:
        """å¤±æ•—åŸå› åˆ†æ(Reflection)"""

        failures_text = "\n".join([
            f"ãƒ†ã‚¹ãƒˆ: {f['test']}\nã‚¨ãƒ©ãƒ¼: {f['error']}"
            for f in failures
        ])

        prompt = f"""
æ¬¡ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ:

<strong>ä¿®æ­£ã‚³ãƒ¼ãƒ‰:</strong>
```python
{code}
```

<strong>å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:</strong>
```
{failures_text}
```

ãªãœå¤±æ•—ã—ãŸã‹åˆ†æã—ã€ã©ã†ä¿®æ­£ã™ã¹ãã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼:
{{
  "failure_reason": "å¤±æ•—åŸå› ",
  "fix_approach": "ä¿®æ­£æ–¹æ³•",
  "specific_changes": ["å…·ä½“çš„å¤‰æ›´å†…å®¹1", "å¤‰æ›´å†…å®¹2"]
}}
"""

        response = await self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ãƒ†ã‚¹ãƒˆå¤±æ•—ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )

        import json
        return json.loads(response.choices[0].message.content)

    async def apply_reflection(self, code: str, reflection: dict) -> str:
        """Reflectionçµæœã‚’ã‚³ãƒ¼ãƒ‰ã«é©ç”¨"""

        prompt = f"""
æ¬¡ã®åˆ†æçµæœã«åŸºã¥ã„ã¦ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„:

<strong>ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰:</strong>
```python
{code}
```

<strong>åˆ†æçµæœ:</strong>
å¤±æ•—åŸå› : {reflection['failure_reason']}
ä¿®æ­£æ–¹æ³•: {reflection['fix_approach']}
å…·ä½“çš„å¤‰æ›´å†…å®¹:
{chr(10).join(f'- {c}' for c in reflection['specific_changes'])}

ä¿®æ­£ã•ã‚ŒãŸå…¨ä½“ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

        response = await self.client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )

        return response.choices[0].message.content

# ä½¿ç”¨ä¾‹
async def test_self_correction():
    tester = SelfCorrectingTester()

    original_code = '''
def divide(a, b):
    return a / b
'''

    # ãƒã‚°ã®ã‚ã‚‹ä¿®æ­£(0é™¤ç®—å‡¦ç†ãªã—)
    buggy_fix = '''
def divide(a, b):
    if b == 0:
        return 0  # èª¤ã£ãŸä¿®æ­£!
    return a / b
'''

    test_suite = '''
def test_divide():
    assert divide(10, 2) == 5
    assert divide(10, 0) == None  # Noneã‚’æœŸå¾…ã™ã‚‹ãŒ0ã‚’è¿”ã™
'''

    result = await tester.validate_fix(
        original_code=original_code,
        fixed_code=buggy_fix,
        test_suite=test_suite,
        file_path='math_utils.py'
    )

    if result['success']:
        print(f"âœ… æœ€çµ‚ã‚³ãƒ¼ãƒ‰:\n{result['final_code']}")
    else:
        print(f"âŒ ä¿®æ­£å¤±æ•—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¸ˆã¿")

    print(f"è©¦è¡Œå›æ•°: {result['attempts']}")
    print(f"Reflectionãƒ­ã‚°: {result['reflections']}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_self_correction())
```

#### 2. å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ (Continuous Learning)

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from datetime import datetime

class ContinuousLearningSystem:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            collection_name="self_healing_knowledge",
            embedding_function=self.embeddings,
            persist_directory="./chroma_db"
        )
        self.fix_history = []

    async def learn_from_fix(self, fix_data: Dict[str, Any], outcome: Dict[str, Any]):
        """æˆåŠŸã—ãŸä¿®æ­£ã‹ã‚‰å­¦ç¿’

        Args:
            fix_data: {
                'error_pattern': str,
                'root_cause': str,
                'code': str,
                'fix': str
            }
            outcome: {
                'success': bool,
                'test_results': dict,
                'attempts': int
            }
        """

        if not outcome['success']:
            print("âš ï¸ å¤±æ•—ã—ãŸä¿®æ­£ã¯å­¦ç¿’ã—ãªã„")
            return

        # 1. åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨ä¿å­˜
        document = f"""
ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³: {fix_data['error_pattern']}
æ ¹æœ¬åŸå› : {fix_data['root_cause']}
å…ƒã®ã‚³ãƒ¼ãƒ‰:
{fix_data['code']}

ä¿®æ­£ã‚³ãƒ¼ãƒ‰:
{fix_data['fix']}

æˆåŠŸ: {outcome['success']}
è©¦è¡Œå›æ•°: {outcome['attempts']}
"""

        metadata = {
            'error_pattern': fix_data['error_pattern'],
            'root_cause': fix_data['root_cause'],
            'timestamp': datetime.now().isoformat(),
            'attempts': outcome['attempts'],
            'success_rate': 1.0 if outcome['success'] else 0.0
        }

        self.vector_store.add_texts(
            texts=[document],
            metadatas=[metadata]
        )

        # 2. ãƒ¡ãƒ¢ãƒªã«ã‚‚ä¿å­˜
        self.fix_history.append({
            **fix_data,
            **outcome,
            'timestamp': datetime.now()
        })

        print(f"ğŸ“š å­¦ç¿’å®Œäº†: {len(self.fix_history)}å€‹ã®äº‹ä¾‹è“„ç©")

        # 3. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        await self.analyze_patterns()

    async def analyze_patterns(self):
        """ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥"""

        from collections import Counter

        # åŒã˜ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é »åº¦
        error_counts = Counter([
            fix['error_pattern']
            for fix in self.fix_history
        ])

        # 3å›ä»¥ä¸Šç™ºç”Ÿã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ä¿å­˜
        for pattern, count in error_counts.items():
            if count >= 3:
                print(f"ğŸ” ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹: {pattern} ({count}å›)")
                await self.create_rule_from_pattern(pattern)

    async def create_rule_from_pattern(self, pattern: str):
        """ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ç”Ÿæˆ"""

        # è©²å½“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å…¨ä¿®æ­£äº‹ä¾‹æ¤œç´¢
        similar_cases = self.vector_store.similarity_search(
            query=pattern,
            k=5
        )

        # LLMã§ä¸€èˆ¬åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«ç”Ÿæˆ
        prompt = f"""
æ¬¡ã®ä¿®æ­£äº‹ä¾‹ã‹ã‚‰ä¸€èˆ¬åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„:

{chr(10).join([case.page_content for case in similar_cases])}

å‡ºåŠ›å½¢å¼:
{{
  "rule_name": "ãƒ«ãƒ¼ãƒ«å",
  "condition": "é©ç”¨æ¡ä»¶",
  "action": "ä¿®æ­£æ–¹æ³•"
}}
"""

        # ãƒ«ãƒ¼ãƒ«ä¿å­˜(ç°¡ç•¥åŒ–)
        print(f"ğŸ“œ æ–°ãƒ«ãƒ¼ãƒ«ç”Ÿæˆ: {pattern}")

    async def apply_learned_knowledge(self, new_error: str) -> Dict[str, Any]:
        """å­¦ç¿’ã—ãŸçŸ¥è­˜ã‚’é©ç”¨

        Returns:
            éå»ã®é¡ä¼¼äº‹ä¾‹ãŒã‚ã‚Œã°ãã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿”ã™
        """

        # é¡ä¼¼äº‹ä¾‹æ¤œç´¢
        similar_cases = self.vector_store.similarity_search(
            query=new_error,
            k=1,
            filter={'success_rate': 1.0}  # æˆåŠŸã—ãŸäº‹ä¾‹ã®ã¿
        )

        if similar_cases and similar_cases[0].metadata.get('similarity', 0) > 0.9:
            print("ğŸ’¡ éå»ã®é¡ä¼¼äº‹ä¾‹ç™ºè¦‹! å†åˆ©ç”¨")

            return {
                'found': True,
                'solution': similar_cases[0].page_content,
                'metadata': similar_cases[0].metadata
            }

        print("ğŸ†• æ–°ã—ã„å•é¡Œã€LLMã§ç”ŸæˆãŒå¿…è¦")
        return {'found': False}

# çµ±åˆä¾‹
async def self_healing_with_learning():
    tester = SelfCorrectingTester()
    learner = ContinuousLearningSystem()

    # 1. éå»äº‹ä¾‹æ¤œç´¢
    past_solution = await learner.apply_learned_knowledge(
        "psycopg2.OperationalError: connection pool exhausted"
    )

    if past_solution['found']:
        print("âœ… éå»ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³å†åˆ©ç”¨")
        return past_solution

    # 2. æ–°ã—ã„ä¿®æ­£ç”Ÿæˆ
    fix_data = {
        'error_pattern': 'connection pool exhausted',
        'root_cause': 'æ¥ç¶šè¿”å´æ¼ã‚Œ',
        'code': 'original code',
        'fix': 'fixed code'
    }

    # 3. ãƒ†ã‚¹ãƒˆã¨æ¤œè¨¼
    outcome = await tester.validate_fix(
        original_code=fix_data['code'],
        fixed_code=fix_data['fix'],
        test_suite='test code',
        file_path='app.py'
    )

    # 4. å­¦ç¿’
    await learner.learn_from_fix(fix_data, outcome)

    return outcome
```

### èª¬æ˜(Explanation)

#### Self-Correction Loopã®å‹•ä½œåŸç†

```mermaid
graph TD
    A[ä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ] --> B[ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ]
    B --> C{é€šé?}
    C -->|æˆåŠŸ| D[å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜]
    D --> E[ãƒ‡ãƒ—ãƒ­ã‚¤]
    C -->|å¤±æ•—| F[Reflection<br/>å¤±æ•—åŸå› åˆ†æ]
    F --> G[Self-Correction<br/>è‡ªå·±ä¿®æ­£]
    G --> H{è©¦è¡Œå›æ•° < 3?}
    H -->|Yes| B
    H -->|No| I[ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯]
```

#### å­¦ç¿’ã®åŠ¹æœ

<strong>1å›ç›®ã®ä¿®æ­£æ™‚</strong>:
- LLMãŒæœ€åˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
- æ™‚é–“: å¹³å‡30ç§’
- æˆåŠŸç‡: 70%

<strong>å­¦ç¿’å¾Œ(é¡ä¼¼äº‹ä¾‹100å€‹è“„ç©)</strong>:
- éå»äº‹ä¾‹å†åˆ©ç”¨
- æ™‚é–“: å¹³å‡5ç§’(6å€é€Ÿã„)
- æˆåŠŸç‡: 95%(å­¦ç¿’åŠ¹æœ)

### å¤‰å½¢(Variations)

#### 1. A/Bãƒ†ã‚¹ãƒ†ã‚£ãƒ³ã‚°

```python
class ABTestingValidator:
    async def validate_with_ab_test(self, original_code, fixed_code):
        """A/Bãƒ†ã‚¹ãƒˆã§ä¿®æ­£åŠ¹æœã‚’æ¤œè¨¼"""

        # 1. ä¸€éƒ¨ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã¿æ–°ã‚³ãƒ¼ãƒ‰ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        await deploy_canary(fixed_code, percentage=5)

        # 2. ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒ(30åˆ†é–“)
        await asyncio.sleep(1800)

        original_metrics = await get_metrics(version='original')
        fixed_metrics = await get_metrics(version='fixed')

        # 3. çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼
        improvement = (fixed_metrics['error_rate'] - original_metrics['error_rate']) / original_metrics['error_rate']

        if improvement < -0.1:  # 10%ä»¥ä¸Šæ”¹å–„
            print("âœ… ä¿®æ­£åŠ¹æœæ¤œè¨¼ã€å…¨ä½“ãƒ‡ãƒ—ãƒ­ã‚¤")
            await deploy_fully(fixed_code)
        else:
            print("âŒ åŠ¹æœãªã—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            await rollback()
```

#### 2. Mutation Testing

```python
class MutationTester:
    async def test_with_mutations(self, fixed_code, test_suite):
        """å¤‰ç•°ãƒ†ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸æ¤œè¨¼"""

        mutations = self.generate_mutations(fixed_code)

        killed_mutants = 0
        for mutant in mutations:
            result = await run_tests(mutant, test_suite)

            if not result['all_passed']:
                killed_mutants += 1  # ãƒ†ã‚¹ãƒˆãŒå¤‰ç•°ã‚’æ¤œå‡º

        mutation_score = killed_mutants / len(mutations)

        if mutation_score < 0.8:
            print(f"âš ï¸ ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³({mutation_score*100:.0f}%)")
            return False

        return True

    def generate_mutations(self, code):
        """ã‚³ãƒ¼ãƒ‰å¤‰ç•°ç”Ÿæˆ"""
        # ä¾‹: + â†’ -, == â†’ !=, True â†’ False
        return [
            code.replace('+', '-'),
            code.replace('==', '!='),
            code.replace('True', 'False')
        ]
```

---

## Recipe 13.6: LangGraphçµ±åˆ

### å•é¡Œ(Problem)

ã“ã‚Œã¾ã§å­¦ã‚“ã ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ±åˆã—ã¦<strong>å®Œå…¨ãªSelf-Healingã‚·ã‚¹ãƒ†ãƒ </strong>ã‚’æ§‹ç¯‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

1. Error Detection
2. Root Cause Analysis
3. Fix Generation
4. Testing & Self-Correction
5. Learning & Deployment

å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã©ã†æ¥ç¶šã—ã€å¤±æ•—æ™‚ã®å†è©¦è¡Œã¯ã©ã†å‡¦ç†ã™ã‚‹ã‹?

### è§£æ±ºç­–(Solution)

LangGraphã‚’ä½¿ç”¨ã—ã¦å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’<strong>çŠ¶æ…‹ãƒ™ãƒ¼ã‚¹ã®ã‚°ãƒ©ãƒ•</strong>ã¨ã—ã¦æ§‹æˆã—ã¾ã™ã€‚

### ã‚³ãƒ¼ãƒ‰/ä¾‹(Code)

#### å®Œå…¨ãªSelf-Healingã‚·ã‚¹ãƒ†ãƒ (LangGraph)

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator
from openai import AsyncOpenAI
import asyncio

# 1. çŠ¶æ…‹å®šç¾©
class SelfHealingState(TypedDict):
    # å…¥åŠ›
    codebase_path: str

    # Error Detection
    error: str
    error_severity: str

    # Root Cause Analysis
    root_cause: str
    affected_files: list

    # Fix Generation
    original_code: str
    fixed_code: str

    # Testing
    test_results: dict
    reflections: list

    # Learning
    learned: bool

    # åˆ¶å¾¡
    attempts: Annotated[int, operator.add]
    success: bool

# 2. Self-Healingã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹
class CompleteSelfHealingSystem:
    def __init__(self):
        self.client = AsyncOpenAI()
        self.workflow = StateGraph(SelfHealingState)
        self.setup_workflow()

        # å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
        self.learner = ContinuousLearningSystem()

    def setup_workflow(self):
        """å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹æˆ"""

        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        self.workflow.add_node("detect", self.detect_error)
        self.workflow.add_node("analyze", self.analyze_root_cause)
        self.workflow.add_node("generate", self.generate_fix)
        self.workflow.add_node("test", self.test_fix)
        self.workflow.add_node("learn", self.learn_from_fix)
        self.workflow.add_node("deploy", self.deploy_fix)

        # ãƒ•ãƒ­ãƒ¼å®šç¾©
        self.workflow.set_entry_point("detect")

        # detect â†’ analyze(ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹æ™‚ã®ã¿)
        self.workflow.add_conditional_edges(
            "detect",
            lambda state: "analyze" if state.get('error') else "end",
            {
                "analyze": "analyze",
                "end": END
            }
        )

        self.workflow.add_edge("analyze", "generate")
        self.workflow.add_edge("generate", "test")

        # test â†’ æ¡ä»¶ä»˜ãåˆ†å²
        self.workflow.add_conditional_edges(
            "test",
            self.should_retry,
            {
                "retry": "generate",     # å†è©¦è¡Œ
                "success": "learn",      # æˆåŠŸ
                "rollback": END          # å¤±æ•—
            }
        )

        self.workflow.add_edge("learn", "deploy")
        self.workflow.add_edge("deploy", END)

        self.app = self.workflow.compile()

    async def detect_error(self, state: SelfHealingState) -> dict:
        """1æ®µéš: ã‚¨ãƒ©ãƒ¼æ¤œå‡º"""

        print("ğŸ” ã‚¨ãƒ©ãƒ¼æ¤œå‡ºä¸­...")

        # å®Ÿè£…ä¾‹: Prometheusã€ãƒ­ã‚°ã€CodeQLçµ±åˆ
        # ã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

        # éå»ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        past_solution = await self.learner.apply_learned_knowledge(
            "connection pool exhausted"
        )

        if past_solution['found']:
            print("ğŸ’¡ éå»ã®é¡ä¼¼äº‹ä¾‹ç™ºè¦‹ã€é«˜é€Ÿãƒ‘ã‚¹ä½¿ç”¨")
            return {
                'error': None,  # ã™ã§ã«è§£æ±ºæ¸ˆã¿
                'success': True
            }

        error = "psycopg2.OperationalError: connection pool exhausted"

        return {
            'error': error,
            'error_severity': 'high'
        }

    async def analyze_root_cause(self, state: SelfHealingState) -> dict:
        """2æ®µéš: æ ¹æœ¬åŸå› åˆ†æ"""

        print("ğŸ”¬ æ ¹æœ¬åŸå› åˆ†æä¸­...")

        analyzer = RootCauseAnalyzer(provider='openai')

        error_data = {
            'message': state['error'],
            'stack_trace': 'Traceback...',
            'code_snippet': 'def get_users():\n    conn = db_pool.getconn()\n    ...',
            'recent_commits': [],
            'metrics': {}
        }

        analysis = await analyzer.analyze(error_data)

        return {
            'root_cause': analysis['root_cause'],
            'affected_files': analysis['affected_files']
        }

    async def generate_fix(self, state: SelfHealingState) -> dict:
        """3æ®µéš: ãƒ‘ãƒƒãƒç”Ÿæˆ"""

        print("ğŸ”§ ãƒ‘ãƒƒãƒç”Ÿæˆä¸­...")

        generator = AgentlessFixGenerator()

        error_context = {
            'error': state['error'],
            'root_cause': state['root_cause'],
            'code': state.get('original_code', 'original code'),
            'file_path': state['affected_files'][0] if state['affected_files'] else 'app.py',
            'tests': 'test suite'
        }

        fix = await generator.generate_fix(error_context)

        return {
            'original_code': error_context['code'],
            'fixed_code': fix['fixed_code'],
            'attempts': 1
        }

    async def test_fix(self, state: SelfHealingState) -> dict:
        """4æ®µéš: ãƒ†ã‚¹ãƒˆã¨Self-Correction"""

        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆä¸­... (è©¦è¡Œ {state['attempts']}/{SelfCorrectingTester.MAX_RETRIES})")

        tester = SelfCorrectingTester()

        result = await tester.validate_fix(
            original_code=state['original_code'],
            fixed_code=state['fixed_code'],
            test_suite='test suite',
            file_path='app.py'
        )

        return {
            'test_results': result['test_results'],
            'reflections': result.get('reflections', []),
            'success': result['success'],
            'fixed_code': result['final_code']  # Self-Correctioné©ç”¨æ¸ˆã¿ã‚³ãƒ¼ãƒ‰
        }

    def should_retry(self, state: SelfHealingState) -> str:
        """å†è©¦è¡Œåˆ¤å®š"""

        if state['success']:
            return "success"
        elif state['attempts'] < SelfCorrectingTester.MAX_RETRIES:
            print("ğŸ”„ å†è©¦è¡Œ")
            return "retry"
        else:
            print("âŒ æœ€å¤§è©¦è¡Œå›æ•°è¶…éã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return "rollback"

    async def learn_from_fix(self, state: SelfHealingState) -> dict:
        """5æ®µéš: å­¦ç¿’"""

        print("ğŸ“š å­¦ç¿’ä¸­...")

        fix_data = {
            'error_pattern': state['error'],
            'root_cause': state['root_cause'],
            'code': state['original_code'],
            'fix': state['fixed_code']
        }

        outcome = {
            'success': state['success'],
            'test_results': state['test_results'],
            'attempts': state['attempts']
        }

        await self.learner.learn_from_fix(fix_data, outcome)

        return {'learned': True}

    async def deploy_fix(self, state: SelfHealingState) -> dict:
        """6æ®µéš: ãƒ‡ãƒ—ãƒ­ã‚¤"""

        print("ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­...")

        # Gitã‚³ãƒŸãƒƒãƒˆ
        commit_msg = f"""
ğŸ¤– Self-healing fix: {state['error']}

Root cause: {state['root_cause']}
Attempts: {state['attempts']}

Auto-generated by Self-Healing AI Agent
"""

        # å®Ÿè£…ä¾‹: Git APIã€GitHub PRä½œæˆ
        print(f"âœ… ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†: {state['affected_files']}")

        # Slacké€šçŸ¥
        await self.notify_team(state)

        return {'success': True}

    async def notify_team(self, state: SelfHealingState):
        """ãƒãƒ¼ãƒ é€šçŸ¥"""

        # å®Ÿè£…ä¾‹: Slack API
        print(f"""
ğŸ“¢ Self-Healingé€šçŸ¥

ã‚¨ãƒ©ãƒ¼: {state['error']}
æ ¹æœ¬åŸå› : {state['root_cause']}
è©¦è¡Œå›æ•°: {state['attempts']}
çŠ¶æ…‹: {'âœ… æˆåŠŸ' if state['success'] else 'âŒ å¤±æ•—'}
""")

    async def run_continuous_monitoring(self):
        """24/7è‡ªå¾‹ç›£è¦–"""

        print("ğŸ¤– Self-Healingã‚·ã‚¹ãƒ†ãƒ é–‹å§‹(Ctrl+Cã§åœæ­¢)")

        while True:
            try:
                result = await self.app.ainvoke({
                    'codebase_path': '/path/to/codebase',
                    'attempts': 0,
                    'success': False,
                    'reflections': []
                })

                if result.get('success'):
                    print(f"âœ… è‡ªå‹•ä¿®æ­£å®Œäº†: {result.get('error', 'Unknown')}")
                elif result.get('error') is None:
                    print("âœ¨ ã‚¨ãƒ©ãƒ¼ãªã—")
                else:
                    print(f"âŒ ä¿®æ­£å¤±æ•—ã€äººé–“ã®ä»‹å…¥ãŒå¿…è¦")

                # 1åˆ†å¾…æ©Ÿ
                await asyncio.sleep(60)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Self-Healingã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")
                break
            except Exception as e:
                print(f"âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(60)

# å®Ÿè¡Œä¾‹
async def main():
    system = CompleteSelfHealingSystem()

    # å˜ä¸€å®Ÿè¡Œ
    result = await system.app.ainvoke({
        'codebase_path': '/path/to/codebase',
        'attempts': 0,
        'success': False,
        'reflections': []
    })

    print(f"\næœ€çµ‚çµæœ: {result}")

    # ã¾ãŸã¯24/7ç›£è¦–
    # await system.run_continuous_monitoring()

if __name__ == "__main__":
    asyncio.run(main())
```

### èª¬æ˜(Explanation)

#### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ 

```mermaid
graph TD
    A[detect<br/>ã‚¨ãƒ©ãƒ¼æ¤œå‡º] --> B{ã‚¨ãƒ©ãƒ¼ã‚ã‚Š?}
    B -->|Yes| C[analyze<br/>æ ¹æœ¬åŸå› åˆ†æ]
    B -->|No| Z[END]

    C --> D[generate<br/>ãƒ‘ãƒƒãƒç”Ÿæˆ]
    D --> E[test<br/>ãƒ†ã‚¹ãƒˆ]

    E --> F{çµæœ?}
    F -->|æˆåŠŸ| G[learn<br/>å­¦ç¿’]
    F -->|å¤±æ•— & attempts < 3| D
    F -->|å¤±æ•— & attempts >= 3| Z

    G --> H[deploy<br/>ãƒ‡ãƒ—ãƒ­ã‚¤]
    H --> Z
```

#### LangGraphã®åˆ©ç‚¹

1. <strong>çŠ¶æ…‹ç®¡ç†</strong>: å„ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœãŒStateã«è‡ªå‹•ä¿å­˜
2. <strong>æ¡ä»¶ä»˜ãåˆ†å²</strong>: ãƒ†ã‚¹ãƒˆçµæœã«å¿œã˜ã¦ç•°ãªã‚‹ãƒ‘ã‚¹
3. <strong>å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯</strong>: å¤±æ•—æ™‚ã«è‡ªå‹•çš„ã«å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã«æˆ»ã‚‹
4. <strong>å¯è¦–åŒ–</strong>: ã‚°ãƒ©ãƒ•å½¢å¼ã§ãƒ•ãƒ­ãƒ¼ã‚’ç†è§£ã—ã‚„ã™ã„

### å¤‰å½¢(Variations)

#### 1. GitHub Actionsçµ±åˆ

```yaml
# .github/workflows/self-healing.yml
name: Self-Healing AI Agent

on:
  schedule:
    - cron: '0 */6 * * *'  # 6æ™‚é–“ã”ã¨ã«å®Ÿè¡Œ
  workflow_dispatch:

jobs:
  self-healing:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          pip install langgraph openai anthropic

      - name: Run Self-Healing System
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python self_healing_system.py

      - name: Create Pull Request if Fix Generated
        if: success()
        uses: peter-evans/create-pull-request@v5
        with:
          title: 'ğŸ¤– Self-Healing Fix'
          body: |
            è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸä¿®æ­£ã§ã™ã€‚

            è©³ç´°ã¯ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
          branch: auto-fix/${{ github.run_number }}
          labels: auto-fix, self-healing
```

#### 2. Slackçµ±åˆ

```python
import os
from slack_sdk.webhook import WebhookClient

class SlackNotifier:
    def __init__(self):
        self.webhook = WebhookClient(os.getenv('SLACK_WEBHOOK_URL'))

    async def notify_fix(self, state):
        """ä¿®æ­£å®Œäº†é€šçŸ¥"""

        self.webhook.send(
            text=f"ğŸ¤– Self-Healingä¿®æ­£å®Œäº†",
            blocks=[
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ¤– Self-Healing Fix Deployed"
                    }
                },
                {
                    "type": "section",
                    "fields": [
                        {
                            "type": "mrkdwn",
                            "text": f"*ã‚¨ãƒ©ãƒ¼:*\n{state['error']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*æ ¹æœ¬åŸå› :*\n{state['root_cause']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*è©¦è¡Œå›æ•°:*\n{state['attempts']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*çŠ¶æ…‹:*\n{'âœ… æˆåŠŸ' if state['success'] else 'âŒ å¤±æ•—'}"
                        }
                    ]
                }
            ]
        )
```

---

## å®Ÿæˆ¦äº‹ä¾‹ç ”ç©¶

### Netflix: Chaos Engineeringã¨Self-Healing

#### èƒŒæ™¯

- <strong>270M+ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼</strong>
- <strong>99.99%ç¨¼åƒç‡</strong>(å¹´é–“ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  < 1æ™‚é–“)
- <strong>AWSå…¨ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®37%</strong>

#### è‡ªå·±ä¿®å¾©ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

##### 1. Auto-Scaling

```python
class NetflixAutoScaler:
    async def heal_capacity_issues(self):
        """å®¹é‡å•é¡Œã®è‡ªå‹•å¾©æ—§"""

        while True:
            metrics = await cloudwatch.get_metrics()

            if metrics['cpu_usage'] > 80:
                # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è‡ªå‹•è¿½åŠ 
                new_instances = await ec2.scale_out(count=10)
                await load_balancer.register_targets(new_instances)

                print("ğŸ“ˆ Auto-Scaling: +10ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è¿½åŠ ")

            if metrics['cpu_usage'] < 20:
                # ä¸è¦ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å‰Šé™¤
                await ec2.scale_in(count=5)

                print("ğŸ“‰ Auto-Scaling: -5ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å‰Šé™¤")

            await asyncio.sleep(60)
```

##### 2. Chaos Monkey

```python
class ChaosMonkey:
    """ãƒ©ãƒ³ãƒ€ãƒ éšœå®³æ³¨å…¥ã§å¾©æ—§åŠ›ãƒ†ã‚¹ãƒˆ"""

    async def inject_failures(self):
        while True:
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹çµ‚äº†
            random_instance = random.choice(await ec2.list_instances())
            await ec2.terminate(random_instance)

            print(f"ğŸ’¥ Chaos: {random_instance} çµ‚äº†")

            # è‡ªå·±ä¿®å¾©ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒè‡ªå‹•å¾©æ—§ã™ã‚‹ã‹æ¤œè¨¼
            await self.verify_recovery()

            await asyncio.sleep(3600)  # 1æ™‚é–“ã”ã¨

    async def verify_recovery(self):
        """å¾©æ—§æ¤œè¨¼"""

        await asyncio.sleep(60)  # 1åˆ†å¾…æ©Ÿ

        health = await check_system_health()

        if health['status'] != 'healthy':
            raise AssertionError("Self-healingå¤±æ•—!")

        print("âœ… Self-Healingæ¤œè¨¼é€šé")
```

#### æˆæœ

- <strong>AWS AZéšœå®³æ™‚</strong>: 30ç§’ä»¥å†…ã«è‡ªå‹•å¾©æ—§
- <strong>å…¨ãƒªãƒ¼ã‚¸ãƒ§ãƒ³éšœå®³æ™‚</strong>: 5åˆ†ä»¥å†…ã«ä»–ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¸ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯è»¢æ›
- <strong>å€‹åˆ¥ã‚µãƒ¼ãƒ“ã‚¹éšœå®³</strong>: ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿0%(å³åº§ã«å¾©æ—§)

### GitHub: Prototype AI Agent

#### ä¸»ãªæ©Ÿèƒ½

1. <strong>ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ£ãƒ³</strong>: CodeQLã§å…¨ãƒªãƒã‚¸ãƒˆãƒªåˆ†æ
2. <strong>è‡ªå‹•ä¿®æ­£</strong>: è„†å¼±æ€§ã€è¤‡é›‘åº¦å•é¡Œã‚’è‡ªå‹•ä¿®æ­£
3. <strong>PRä½œæˆ</strong>: ä¿®æ­£å†…å®¹ã‚’Pull Requestã¨ã—ã¦æå‡º

#### å®Ÿéš›ã®æˆæœ

- <strong>1æ—¥4åƒä¸‡å€‹ã®ã‚¿ã‚¹ã‚¯</strong>å‡¦ç†
- <strong>å¹³å‡ä¿®æ­£æ™‚é–“</strong>: 15åˆ†(äººé–“: 2-3æ™‚é–“)
- <strong>ç²¾åº¦</strong>: 85%(äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼å¾Œã®ãƒãƒ¼ã‚¸ç‡)

### Google DeepMind: CodeMender

#### Gemini Deep Thinkãƒ¢ãƒ‡ãƒ«

- <strong>6ãƒ¶æœˆé–“ã§72å€‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒ</strong>ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã«è²¢çŒ®
- <strong>å¹³å‡ä¿®æ­£æ™‚é–“</strong>: 20åˆ†
- <strong>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å—å®¹ç‡</strong>: 94%(68/72 PRãƒãƒ¼ã‚¸)

---

## é™ç•Œã¨è§£æ±ºç­–

### 1. ç²¾åº¦å•é¡Œ

<strong>å•é¡Œ</strong>: 15%èª¤æ¤œçŸ¥(False Positive)ã€5%æœªæ¤œçŸ¥(False Negative)

<strong>è§£æ±ºç­–</strong>:

```python
async def human_in_the_loop_validation(fix):
    """ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼"""

    if fix.confidence < 0.9:
        # ä¿¡é ¼åº¦ãŒä½ã„ä¿®æ­£ã¯äººé–“ã®æ‰¿èªãŒå¿…è¦
        await request_human_approval(fix)
    else:
        # ä¿¡é ¼åº¦ãŒé«˜ã„ä¿®æ­£ã¯è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤
        await auto_deploy(fix)
```

### 2. è¤‡é›‘ãªãƒã‚°å‡¦ç†ã®å¤±æ•—

<strong>å•é¡Œ</strong>: ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ç«¶åˆçŠ¶æ…‹ã€æ–­ç¶šçš„ãƒã‚°ã¯AIãŒæŠŠæ¡å›°é›£

<strong>è§£æ±ºç­–</strong>:

```python
async def escalate_to_expert(issue):
    """è¤‡é›‘ãªå•é¡Œã¯å°‚é–€å®¶ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    if issue.complexity_score > 0.8:
        await notify_expert_team(issue)
        return "ESCALATED"

    return await self.auto_fix(issue)
```

### 3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯

<strong>å•é¡Œ</strong>: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã®å¯èƒ½æ€§

<strong>è§£æ±ºç­–</strong>:

```python
def sanitize_input(error_msg):
    """å…¥åŠ›æ¤œè¨¼"""

    dangerous_keywords = ['DROP', 'DELETE', 'EXECUTE']
    for keyword in dangerous_keywords:
        if keyword in error_msg.upper():
            raise SecurityException(f"å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")

    return error_msg
```

---

## Best Practicesè¦ç´„

### 1. æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ(Canary Deployment)

```python
# 5% â†’ 50% â†’ 100% æ®µéšçš„ãƒ‡ãƒ—ãƒ­ã‚¤
await deploy_to_percentage(new_fix, percentage=5)
await monitor_for_duration(minutes=30)

if await check_error_rate() < 0.1:
    await deploy_to_percentage(new_fix, percentage=50)
```

### 2. å¯è¦³æ¸¬æ€§(Observability)

- <strong>åŒ…æ‹¬çš„ãƒ­ã‚°è¨˜éŒ²</strong>: ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²
- <strong>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹</strong>: Prometheusã§åé›†
- <strong>ãƒˆãƒ¬ãƒ¼ã‚¹</strong>: OpenTelemetry
- <strong>ã‚¢ãƒ©ãƒ¼ãƒˆ</strong>: Slackã€PagerDuty
- <strong>ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</strong>: Grafana

### 3. Human-in-the-Loop

- ä¿¡é ¼åº¦0.9ä»¥ä¸Š: è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤
- ä¿¡é ¼åº¦0.7ã€œ0.9: éåŒæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼
- ä¿¡é ¼åº¦0.7æœªæº€: å¿…é ˆæ‰¿èª

### 4. ç¶™ç¶šçš„å­¦ç¿’

- æˆåŠŸã—ãŸä¿®æ­£äº‹ä¾‹ã‚’ä¿å­˜
- é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å†åˆ©ç”¨
- ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ«ãƒ¼ãƒ«åŒ–

---

## ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### 1é€±ç›®: åŸºç¤å­¦ç¿’

```bash
# LangGraphã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install langgraph langchain-openai

# ä¾‹å®Ÿè¡Œ
python examples/self_healing_demo.py
```

### 2é€±ç›®: å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé©ç”¨

- å˜ä¸€ã‚µãƒ¼ãƒ“ã‚¹ç›£è¦–
- ç°¡å˜ãªã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®æ­£(ä¾‹: ç’°å¢ƒå¤‰æ•°ã®æ¬ è½)

### 3é€±ç›®: ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆ

- Canaryãƒ‡ãƒ—ãƒ­ã‚¤(5% â†’ 50% â†’ 100%)
- Human-in-the-Loopæ¤œè¨¼
- æˆæœæ¸¬å®š(MTTRã€æˆåŠŸç‡)

### 1ãƒ¶æœˆå¾Œ: å…¨é¢å°å…¥æ±ºå®š

---

## ç·´ç¿’å•é¡Œ

### Exercise 1: ã‚·ãƒ³ãƒ—ãƒ«ãªSelf-Healingã‚·ã‚¹ãƒ†ãƒ 

æ¬¡ã®ãƒã‚°ã‚’è‡ªå‹•ä¿®æ­£ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„:

```python
# ãƒã‚°: ZeroDivisionError
def calculate_average(numbers):
    return sum(numbers) / len(numbers)  # len(numbers)ãŒ0ãªã‚‰ã‚¨ãƒ©ãƒ¼!

# ç›®æ¨™: è‡ªå‹•çš„ã«ç©ºãƒªã‚¹ãƒˆå‡¦ç†ã‚’è¿½åŠ 
```

### Exercise 2: å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

3ã¤ä»¥ä¸Šã®ä¿®æ­£äº‹ä¾‹ã‚’å­¦ç¿’ã—ã€é¡ä¼¼äº‹ä¾‹ç™ºç”Ÿæ™‚ã«è‡ªå‹•çš„ã«éå»ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã—ã¦ãã ã•ã„ã€‚

### Exercise 3: LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

Error Detection â†’ Root Cause Analysis â†’ Fix Generationã®3æ®µéšãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’LangGraphã§å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

---

## å‚è€ƒè³‡æ–™

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [LangGraphå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://langchain-ai.github.io/langgraph/)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com)

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

- [SWE-benchãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰](https://www.swebench.com/)
- [Meta AutoPatchBench](https://engineering.fb.com/2025/04/29/ai-research/autopatchbench-benchmark-ai-powered-security-fixes/)

### å®Ÿæˆ¦äº‹ä¾‹

- [GitHub AI Agent](https://www.infoq.com/news/2025/06/github-ai-agent-bugfixing/)
- [Google CodeMender](https://www.artificialintelligence-news.com/news/google-new-ai-agent-rewrites-code-automate-vulnerability-fixes/)
- [Netflix Chaos Engineering](https://lobste.rs/s/yulcql/how_we_built_self_healing_system_survive)

### å­¦ç¿’è³‡æ–™

- [Self-Healing ML Framework (NeurIPS 2024)](https://arxiv.org/abs/2411.00186)
- [LangGraph Self-Healing Tutorial](https://krishankantsinghal.medium.com/from-prompt-to-program-building-a-self-healing-ai-coder-with-langgraph-16f7767a6100)

---

## ãŠã‚ã‚Šã«

è‡ªå·±ä¿®å¾©AIã‚·ã‚¹ãƒ†ãƒ ã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æ ¹æœ¬çš„ã«å¤‰é©ã—ã¦ã„ã¾ã™ã€‚

<strong>è¦ç‚¹ã¾ã¨ã‚</strong>:

- <strong>5æ®µéšã‚µã‚¤ã‚¯ãƒ«</strong>: Detect â†’ Analyze â†’ Generate â†’ Test â†’ Learn
- <strong>Agentless > Multi-Agent</strong>: ã‚·ãƒ³ãƒ—ãƒ«ã•ãŒå‹ã¤(50.8% vs 33.6%)
- <strong>ç¶™ç¶šçš„å­¦ç¿’</strong>: éå»äº‹ä¾‹å†åˆ©ç”¨ã§6å€é€Ÿã„ä¿®æ­£
- <strong>å®Ÿæˆ¦æ¤œè¨¼</strong>: GitHubã€Googleã€NetflixãŒãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³é…å‚™

<strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>:

ã“ã‚Œã‹ã‚‰çš†ã•ã‚“ã®ã‚·ã‚¹ãƒ†ãƒ ã«è‡ªå·±ä¿®å¾©ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è¿½åŠ ã™ã‚‹ç•ªã§ã™ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚äººã‚’èµ·ã“ã•ãšã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå‹•çš„ã«ä¿®æ­£ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

<strong>æœªæ¥ã¯è‡ªå¾‹çš„ã§ã€é©å¿œçš„ã§ã€è‡ªå·±ä¿®å¾©ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚</strong>

---

**æ¬¡ç« äºˆå‘Š**: Chapter 14ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨å€«ç†çš„è€ƒæ…®äº‹é …ã‚’æ‰±ã„ã¾ã™ã€‚
