---
title: Google Gemini File Searchë¡œ RAG ì‹œìŠ¤í…œ 5ë¶„ ë§Œì— êµ¬ì¶•í•˜ê¸°
description: >-
  2025ë…„ 11ì›” ë°œí‘œëœ Gemini File Search Toolì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ RAG íŒŒì´í”„ë¼ì¸ ì—†ì´ ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„
  êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œ. ì™„ì „ ê´€ë¦¬í˜• RAGë¡œ ê°œë°œ ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ë‹¨ì¶•í•˜ì„¸ìš”.
pubDate: '2025-11-13'
heroImage: ../../../assets/blog/google-gemini-file-search-rag-tutorial-hero.webp
tags:
  - gemini
  - google-ai
  - rag
  - file-search
  - python
  - streamlit
relatedPosts:
  - slug: data-driven-pm-framework
    score: 0.94
    reason:
      ko: 'AI/ML, ì•„í‚¤í…ì²˜ ë¶„ì•¼ì—ì„œ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©° ë¹„ìŠ·í•œ ë‚œì´ë„ì…ë‹ˆë‹¤.'
      ja: AI/MLã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é‡ã§é¡ä¼¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã€åŒç¨‹åº¦ã®é›£æ˜“åº¦ã§ã™ã€‚
      en: 'Covers similar topics in AI/ML, architecture with comparable difficulty.'
      zh: åœ¨AI/MLã€æ¶æ„é¢†åŸŸæ¶µç›–ç±»ä¼¼ä¸»é¢˜ï¼Œéš¾åº¦ç›¸å½“ã€‚
  - slug: ai-agent-notion-mcp-automation
    score: 0.93
    reason:
      ko: 'ìë™í™”, AI/ML, ì•„í‚¤í…ì²˜ ë¶„ì•¼ì—ì„œ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©° ë¹„ìŠ·í•œ ë‚œì´ë„ì…ë‹ˆë‹¤.'
      ja: è‡ªå‹•åŒ–ã€AI/MLã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é‡ã§é¡ä¼¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã€åŒç¨‹åº¦ã®é›£æ˜“åº¦ã§ã™ã€‚
      en: >-
        Covers similar topics in automation, AI/ML, architecture with comparable
        difficulty.
      zh: åœ¨è‡ªåŠ¨åŒ–ã€AI/MLã€æ¶æ„é¢†åŸŸæ¶µç›–ç±»ä¼¼ä¸»é¢˜ï¼Œéš¾åº¦ç›¸å½“ã€‚
  - slug: ai-agent-persona-analysis
    score: 0.93
    reason:
      ko: 'AI/ML, ì•„í‚¤í…ì²˜ ë¶„ì•¼ì—ì„œ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©° ë¹„ìŠ·í•œ ë‚œì´ë„ì…ë‹ˆë‹¤.'
      ja: AI/MLã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é‡ã§é¡ä¼¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã€åŒç¨‹åº¦ã®é›£æ˜“åº¦ã§ã™ã€‚
      en: 'Covers similar topics in AI/ML, architecture with comparable difficulty.'
      zh: åœ¨AI/MLã€æ¶æ„é¢†åŸŸæ¶µç›–ç±»ä¼¼ä¸»é¢˜ï¼Œéš¾åº¦ç›¸å½“ã€‚
  - slug: claude-skills-implementation-guide
    score: 0.93
    reason:
      ko: 'ìë™í™”, AI/ML, ì•„í‚¤í…ì²˜ ë¶„ì•¼ì—ì„œ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©° ë¹„ìŠ·í•œ ë‚œì´ë„ì…ë‹ˆë‹¤.'
      ja: è‡ªå‹•åŒ–ã€AI/MLã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é‡ã§é¡ä¼¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã€åŒç¨‹åº¦ã®é›£æ˜“åº¦ã§ã™ã€‚
      en: >-
        Covers similar topics in automation, AI/ML, architecture with comparable
        difficulty.
      zh: åœ¨è‡ªåŠ¨åŒ–ã€AI/MLã€æ¶æ„é¢†åŸŸæ¶µç›–ç±»ä¼¼ä¸»é¢˜ï¼Œéš¾åº¦ç›¸å½“ã€‚
  - slug: jules-autocoding
    score: 0.93
    reason:
      ko: 'ìë™í™”, AI/ML, ì•„í‚¤í…ì²˜ ë¶„ì•¼ì—ì„œ ìœ ì‚¬í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©° ë¹„ìŠ·í•œ ë‚œì´ë„ì…ë‹ˆë‹¤.'
      ja: è‡ªå‹•åŒ–ã€AI/MLã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†é‡ã§é¡ä¼¼ã—ãŸãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã€åŒç¨‹åº¦ã®é›£æ˜“åº¦ã§ã™ã€‚
      en: >-
        Covers similar topics in automation, AI/ML, architecture with comparable
        difficulty.
      zh: åœ¨è‡ªåŠ¨åŒ–ã€AI/MLã€æ¶æ„é¢†åŸŸæ¶µç›–ç±»ä¼¼ä¸»é¢˜ï¼Œéš¾åº¦ç›¸å½“ã€‚
---

## ê°œìš”

2025ë…„ 11ì›” 7ì¼, Googleì€ ê°œë°œìë“¤ì´ ì˜¤ë«ë™ì•ˆ ê¸°ë‹¤ë ¤ì˜¨ í˜ì‹ ì ì¸ ê¸°ëŠ¥ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ë°”ë¡œ <strong>Gemini API File Search Tool</strong>ì…ë‹ˆë‹¤. ì´ê²ƒì€ ë‹¨ìˆœí•œ íŒŒì¼ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì•„ë‹™ë‹ˆë‹¤. ì™„ì „ ê´€ë¦¬í˜• RAG (Retrieval Augmented Generation) ì‹œìŠ¤í…œìœ¼ë¡œ, ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•ì˜ íŒë„ë¥¼ ì™„ì „íˆ ë°”ê¾¸ëŠ” ê²Œì„ ì²´ì¸ì €ì…ë‹ˆë‹¤.

### ì™œ í˜ì‹ ì ì¸ê°€?

ì „í†µì ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë³µì¡í•œ ì‘ì—…ë“¤ì´ í•„ìš”í–ˆìŠµë‹ˆë‹¤:

- ğŸ“„ <strong>ë¬¸ì„œ ì²­í‚¹ (Chunking)</strong>: ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• 
- ğŸ”¢ <strong>ì„ë² ë”© ìƒì„±</strong>: ê° ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
- ğŸ—„ï¸ <strong>ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬</strong>: Pinecone, Weaviate, Chroma ë“±ì˜ ì„¤ì • ë° ìš´ì˜
- ğŸ” <strong>ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ìµœì í™”</strong>: ìœ ì‚¬ë„ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ íŠœë‹
- ğŸ”„ <strong>ì§€ì†ì ì¸ ìœ ì§€ë³´ìˆ˜</strong>: ì¸í”„ë¼ ìŠ¤ì¼€ì¼ë§, ë¹„ìš© ê´€ë¦¬

<strong>File Search Toolì€ ì´ ëª¨ë“  ê³¼ì •ì„ ìë™í™”</strong>í•˜ì—¬, ê°œë°œìê°€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë°”ë¡œ ì§ˆë¬¸í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ë§ˆì¹˜ OpenAIì˜ Assistants APIê°€ í–ˆë˜ ê²ƒì²˜ëŸ¼, í•˜ì§€ë§Œ Googleì˜ ê°•ë ¥í•œ Gemini ëª¨ë¸ê³¼ í•¨ê»˜ ë§ì´ì£ .

## File Search Toolì´ë€?

### RAGì˜ ê¸°ë³¸ ê°œë…

RAG (Retrieval Augmented Generation)ëŠ” LLMì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ê¸°ìˆ ì…ë‹ˆë‹¤. LLMì€ í•™ìŠµ ë°ì´í„°ê¹Œì§€ë§Œ ì•Œê³  ìˆê³ , ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ê¸°ì—…ì˜ ë‚´ë¶€ ë¬¸ì„œëŠ” ì•Œì§€ ëª»í•©ë‹ˆë‹¤. RAGëŠ” ì´ ë¬¸ì œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í•´ê²°í•©ë‹ˆë‹¤:

```mermaid
graph LR
    A[ì‚¬ìš©ì ì§ˆë¬¸] --> B[ë¬¸ì„œ ê²€ìƒ‰]
    B --> C[ê´€ë ¨ ë¬¸ì„œ ì¡°ê°]
    C --> D[LLM + ë¬¸ì„œ]
    D --> E[ì •í™•í•œ ë‹µë³€]
```

### ê¸°ì¡´ ë°©ì‹ vs File Search Tool

<strong>ê¸°ì¡´ ë°©ì‹</strong> (ì§ì ‘ êµ¬ì¶•):
```python
# 1. ë¬¸ì„œ ë¡œë“œ
documents = load_documents("./docs")

# 2. ì²­í‚¹
chunks = text_splitter.split(documents)

# 3. ì„ë² ë”© ìƒì„±
embeddings = openai_embeddings.embed(chunks)

# 4. ë²¡í„° DB ì €ì¥
vector_db = Pinecone.from_documents(chunks, embeddings)

# 5. ê²€ìƒ‰ ë° ìƒì„±
relevant_docs = vector_db.similarity_search(query)
answer = llm.generate(query + relevant_docs)
```

<strong>File Search Tool</strong> (ì™„ì „ ê´€ë¦¬í˜•):
```python
# 1. Store ìƒì„±
store = client.file_search_stores.create(
    config={'display_name': 'My Knowledge Base'}
)

# 2. íŒŒì¼ ì—…ë¡œë“œ (ì²­í‚¹, ì„ë² ë”© ìë™)
operation = client.file_search_stores.upload_to_file_search_store(
    file='document.pdf',
    file_search_store_name=store.name
)

# 3. ì§ˆë¬¸í•˜ê¸° (ê²€ìƒ‰, ìƒì„± ìë™)
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store.name]
                )
            )
        ]
    )
)
```

ì°¨ì´ê°€ ë³´ì´ì‹œë‚˜ìš”? <strong>ì½”ë“œì˜ ì–‘ì´ 60% ì´ìƒ ì¤„ì–´ë“¤ì—ˆê³ , ë³µì¡í•œ ì„¤ì •ì´ ì™„ì „íˆ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤.</strong>

## ì‘ë™ ì›ë¦¬

File Search Toolì€ ì„¸ ê°€ì§€ ì£¼ìš” ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤:

```mermaid
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant API as Gemini API
    participant Store as File Search Store
    participant VDB as ë²¡í„° DB
    participant LLM as Gemini Model

    U->>API: íŒŒì¼ ì—…ë¡œë“œ
    API->>Store: íŒŒì¼ ì €ì¥
    Store->>Store: ìë™ ì²­í‚¹
    Store->>VDB: ì„ë² ë”© ìƒì„± ë° ì €ì¥

    U->>API: ì§ˆë¬¸ ì „ì†¡
    API->>VDB: ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
    VDB->>API: ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ë°˜í™˜
    API->>LLM: ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸
    LLM->>U: ë‹µë³€ ìƒì„±
```

### 1ë‹¨ê³„: ì¸ë±ì‹± (Indexing)

íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë‹¤ìŒì´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤:

- <strong>ìë™ ì²­í‚¹</strong>: ë¬¸ì„œë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•  (ê¸°ë³¸ 400 í† í°)
- <strong>ì„ë² ë”© ìƒì„±</strong>: ê° ì²­í¬ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
- <strong>ë²¡í„° ì €ì¥</strong>: Googleì˜ ê´€ë¦¬í˜• ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

### 2ë‹¨ê³„: ê²€ìƒ‰ (Retrieval)

ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ë©´:

- ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ë¬´ë£Œ!)
- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ ê²€ìƒ‰
- Top-K ê°œì˜ ë¬¸ì„œ ì¡°ê° ì„ íƒ

### 3ë‹¨ê³„: ìƒì„± (Generation)

Gemini ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±:

- ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
- ì›ë³¸ ì§ˆë¬¸ê³¼ ê²°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
- ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ë‹µë³€ ìƒì„±
- ì¸ìš© ì¶œì²˜ ì •ë³´ í¬í•¨

## ì£¼ìš” ê¸°ëŠ¥

### 1. ê´‘ë²”ìœ„í•œ íŒŒì¼ í˜•ì‹ ì§€ì›

File Search Toolì€ 300ê°œ ì´ìƒì˜ íŒŒì¼ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤:

<strong>ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ (100+ ì¢…ë¥˜)</strong>:
- PDF, DOCX, XLSX, PPTX
- JSON, XML, YAML
- SQL, SQLite ë°ì´í„°ë² ì´ìŠ¤

<strong>í…ìŠ¤íŠ¸ íŒŒì¼ (200+ ì¢…ë¥˜)</strong>:
- Markdown, HTML, CSV
- Python, JavaScript, Java, Go ë“± ëª¨ë“  ì£¼ìš” í”„ë¡œê·¸ë˜ë° ì–¸ì–´
- ë¡œê·¸ íŒŒì¼, ì„¤ì • íŒŒì¼

### 2. ì»¤ìŠ¤í…€ ì²­í‚¹ ì„¤ì •

ë¬¸ì„œ íŠ¹ì„±ì— ë§ê²Œ ì²­í‚¹ ì „ëµì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
config={
    'chunking_config': {
        'white_space_config': {
            'max_tokens_per_chunk': 400,  # ì²­í¬ë‹¹ ìµœëŒ€ í† í° ìˆ˜
            'max_overlap_tokens': 40       # ì²­í¬ ê°„ ì˜¤ë²„ë©
        }
    }
}
```

<strong>ì¶”ì²œ ì„¤ì •</strong>:
- <strong>FAQ ë¬¸ì„œ</strong>: 200 í† í° (ì§§ê³  ê°„ê²°í•œ ì •ë³´)
- <strong>ê¸°ìˆ  ë§¤ë‰´ì–¼</strong>: 400 í† í° (ê¸°ë³¸ ì„¤ì •, ê· í˜•)
- <strong>ì—°êµ¬ ë…¼ë¬¸</strong>: 600 í† í° (ê¸´ ë§¥ë½ í•„ìš”)

### 3. ë©”íƒ€ë°ì´í„° í•„í„°ë§

íŒŒì¼ ì—…ë¡œë“œ ì‹œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ê²€ìƒ‰ì„ ì •êµí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
custom_metadata=[
    {"key": "author", "string_value": "Robert Graves"},
    {"key": "department", "string_value": "Engineering"},
    {"key": "year", "numeric_value": 2025},
    {"key": "is_public", "boolean_value": True}
]
```

### 4. ì¸ìš© ì¶œì²˜ ì¶”ì 

ë‹µë³€ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì¶œì²˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
response = client.models.generate_content(...)

if hasattr(response, 'grounding_metadata'):
    for citation in response.grounding_metadata.citations:
        print(f"ì¶œì²˜: {citation.source}")
        print(f"ì¸ìš© í…ìŠ¤íŠ¸: {citation.text}")
```

### 5. ë¬´ë£Œ ì¿¼ë¦¬ ì„ë² ë”©

ì¼ë°˜ì ìœ¼ë¡œ ì„ë² ë”© ìƒì„±ì—ëŠ” ë¹„ìš©ì´ ë°œìƒí•˜ì§€ë§Œ, File Search Toolì€ <strong>ì¿¼ë¦¬ ì„ë² ë”©ì„ ë¬´ë£Œë¡œ ì œê³µ</strong>í•©ë‹ˆë‹¤. ì¸ë±ì‹± ì‹œì—ë§Œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤ ($0.15 / 1M í† í°).

## ì‹¤ìŠµ: Pythonìœ¼ë¡œ ì‹œì‘í•˜ê¸°

ì‹¤ì œë¡œ File Search Toolì„ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì€ ì œê°€ ì§ì ‘ í…ŒìŠ¤íŠ¸í•œ ì½”ë“œì…ë‹ˆë‹¤.

### í™˜ê²½ ì„¤ì •

<strong>uv ì‚¬ìš© (ê¶Œì¥)</strong>:

```bash
# uv ì„¤ì¹˜ (ì•„ì§ ì—†ë‹¤ë©´)
curl -LsSf https://astral.sh/uv/install.sh | sh

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir gemini-file-search-demo
cd gemini-file-search-demo

# Python ê°€ìƒí™˜ê²½ ìƒì„±
uv venv
source .venv/bin/activate  # Unix/macOS
# .venv\Scripts\activate  # Windows

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
uv pip install google-genai streamlit python-dotenv
```

<strong>ì „í†µì ì¸ pip ì‚¬ìš©</strong>:

```bash
# Python 3.9+ í•„ìš”
python --version

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install google-genai streamlit python-dotenv
```

### API í‚¤ ë°œê¸‰

1. [Google AI Studio](https://aistudio.google.com) ì ‘ì†
2. ì™¼ìª½ ë©”ë‰´ì—ì„œ "Get API key" ì„ íƒ
3. "Create API key" ë²„íŠ¼ í´ë¦­
4. API í‚¤ ë³µì‚¬

<strong>.env íŒŒì¼ ìƒì„±</strong>:

```bash
GEMINI_API_KEY=your-api-key-here
```

### ê¸°ë³¸ ì˜ˆì œ ì½”ë“œ

ì™„ì „íˆ ì‘ë™í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤:

```python
import os
import time
from google import genai
from google.genai import types
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = genai.Client()

# 1. File Search Store ìƒì„±
print("Store ìƒì„± ì¤‘...")
store = client.file_search_stores.create(
    config={'display_name': 'My First Knowledge Base'}
)
print(f"âœ“ Store ìƒì„± ì™„ë£Œ: {store.name}")

# 2. íŒŒì¼ ì—…ë¡œë“œ
print("\níŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
operation = client.file_search_stores.upload_to_file_search_store(
    file='document.pdf',  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½
    file_search_store_name=store.name,
    config={
        'display_name': 'Sample Document',
        'chunking_config': {
            'white_space_config': {
                'max_tokens_per_chunk': 400,
                'max_overlap_tokens': 40
            }
        }
    }
)

# 3. ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
while not operation.done:
    print("ì¸ë±ì‹± ì¤‘...")
    time.sleep(5)
    operation = client.operations.get(operation)

print("âœ“ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

# 4. ì§ˆë¬¸í•˜ê¸°
print("\nì§ˆë¬¸ ì²˜ë¦¬ ì¤‘...")
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ 3ê°€ì§€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.",
    config=types.GenerateContentConfig(
        tools=[
            types.Tool(
                file_search=types.FileSearch(
                    file_search_store_names=[store.name]
                )
            )
        ],
        temperature=0.2
    )
)

print("\n=== ë‹µë³€ ===")
print(response.text)

# 5. ì¸ìš© ì¶œì²˜ í™•ì¸
if hasattr(response, 'grounding_metadata'):
    print("\n=== ì¶œì²˜ ===")
    for idx, citation in enumerate(response.grounding_metadata.citations, 1):
        print(f"{idx}. {citation.source}")
```

## Streamlit ì›¹ ì•± ë°ëª¨

ì œê°€ ì‹¤ì œë¡œ êµ¬í˜„í•˜ê³  í…ŒìŠ¤íŠ¸í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. `uv run python -m streamlit run web_app.py` ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì›¹ ì•± êµ¬ì¡°

```python
import streamlit as st
from google import genai
from google.genai import types
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Gemini File Search",
    page_icon="ğŸ”",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "client" not in st.session_state:
    st.session_state.client = None
if "store" not in st.session_state:
    st.session_state.store = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_client(api_key):
    try:
        os.environ["GEMINI_API_KEY"] = api_key
        client = genai.Client()
        return client, None
    except Exception as e:
        return None, str(e)

# Store ìƒì„± í•¨ìˆ˜
def create_store(client, store_name):
    try:
        store = client.file_search_stores.create(
            config={"display_name": store_name}
        )
        return store, None
    except Exception as e:
        return None, str(e)

# íŒŒì¼ ì—…ë¡œë“œ í•¨ìˆ˜
def upload_file(client, file, store_name):
    try:
        import uuid

        # ì„ì‹œ íŒŒì¼ ìƒì„±
        file_ext = os.path.splitext(file.name)[1]
        temp_file = f"temp_{uuid.uuid4().hex}{file_ext}"

        with open(temp_file, "wb") as f:
            f.write(file.getbuffer())

        # ì—…ë¡œë“œ
        operation = client.file_search_stores.upload_to_file_search_store(
            file=temp_file,
            file_search_store_name=store_name,
            config={
                "display_name": file.name,
                "chunking_config": {
                    "white_space_config": {
                        "max_tokens_per_chunk": 400,
                        "max_overlap_tokens": 40
                    }
                }
            }
        )

        # ì™„ë£Œ ëŒ€ê¸°
        while not operation.done:
            time.sleep(2)
            operation = client.operations.get(operation)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_file):
            os.remove(temp_file)

        return True, None

    except Exception as e:
        return False, str(e)

# ì¿¼ë¦¬ í•¨ìˆ˜
def query_store(client, question, store_name):
    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=question,
            config=types.GenerateContentConfig(
                tools=[
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=[store_name]
                        )
                    )
                ],
                temperature=0.2
            )
        )

        # ì¸ìš© ì •ë³´ ì¶”ì¶œ
        citations = []
        if hasattr(response, "grounding_metadata") and response.grounding_metadata:
            if hasattr(response.grounding_metadata, "citations"):
                for citation in response.grounding_metadata.citations:
                    citations.append({
                        "source": getattr(citation, "source", "N/A"),
                        "text": getattr(citation, "text", "")[:100]
                    })

        return response.text, citations, None

    except Exception as e:
        return None, None, str(e)

# UI êµ¬ì„±
st.title("ğŸ” Gemini File Search")
st.markdown("Google Gemini APIì˜ File Search Toolì„ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” - ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    api_key = st.text_input(
        "Gemini API Key",
        type="password",
        value=os.getenv("GEMINI_API_KEY", ""),
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤"
    )

    if api_key and not st.session_state.client:
        client, error = initialize_client(api_key)
        if client:
            st.session_state.client = client
            st.success("âœ“ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {error}")

    st.divider()

    # Store ê´€ë¦¬
    if st.session_state.client:
        st.header("ğŸ“ Store ê´€ë¦¬")

        # ìƒˆ Store ìƒì„±
        new_store_name = st.text_input("Store ì´ë¦„", value="My Knowledge Base")
        if st.button("ìƒì„±"):
            with st.spinner("Store ìƒì„± ì¤‘..."):
                store, error = create_store(st.session_state.client, new_store_name)
                if store:
                    st.session_state.store = store
                    st.success(f"âœ“ Store ìƒì„±: {store.name}")
                    st.rerun()
                else:
                    st.error(f"ìƒì„± ì‹¤íŒ¨: {error}")

        # í˜„ì¬ Store
        if st.session_state.store:
            st.success(f"**í˜„ì¬ Store:** {st.session_state.store.display_name}")

# ë©”ì¸ ì˜ì—­
if not st.session_state.client:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    st.stop()

if not st.session_state.store:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ Storeë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”")
    st.stop()

# íƒ­ìœ¼ë¡œ ê¸°ëŠ¥ ë¶„ë¦¬
tab1, tab2 = st.tabs(["ğŸ’¬ ì§ˆì˜ì‘ë‹µ", "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ"])

# ì§ˆì˜ì‘ë‹µ íƒ­
with tab1:
    st.header("ì§ˆì˜ì‘ë‹µ")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬
    for chat in st.session_state.chat_history:
        with st.chat_message("user"):
            st.write(chat["question"])

        with st.chat_message("assistant"):
            st.write(chat["answer"])

            if chat.get("citations"):
                with st.expander("ğŸ“š ì¸ìš© ì¶œì²˜"):
                    for i, citation in enumerate(chat["citations"], 1):
                        st.markdown(f"**{i}. {citation['source']}**")
                        st.text(f"   {citation['text']}...")

    # ì§ˆë¬¸ ì…ë ¥
    question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

    if question:
        with st.chat_message("user"):
            st.write(question)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                answer, citations, error = query_store(
                    st.session_state.client,
                    question,
                    st.session_state.store.name
                )

                if answer:
                    st.write(answer)

                    if citations:
                        with st.expander("ğŸ“š ì¸ìš© ì¶œì²˜"):
                            for i, citation in enumerate(citations, 1):
                                st.markdown(f"**{i}. {citation['source']}**")
                                st.text(f"   {citation['text']}...")

                    # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                    st.session_state.chat_history.append({
                        "question": question,
                        "answer": answer,
                        "citations": citations
                    })
                else:
                    st.error(f"ì˜¤ë¥˜: {error}")

# íŒŒì¼ ì—…ë¡œë“œ íƒ­
with tab2:
    st.header("íŒŒì¼ ì—…ë¡œë“œ")

    uploaded_files = st.file_uploader(
        "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        accept_multiple_files=True,
        type=["pdf", "txt", "docx", "md", "csv"],
        help="PDF, TXT, DOCX, Markdown, CSV íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )

    if uploaded_files:
        if st.button("ì—…ë¡œë“œ ì‹œì‘", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, file in enumerate(uploaded_files):
                status_text.text(f"ì—…ë¡œë“œ ì¤‘: {file.name}")

                success, error = upload_file(
                    st.session_state.client,
                    file,
                    st.session_state.store.name
                )

                if success:
                    st.success(f"âœ“ {file.name}")
                else:
                    st.error(f"âœ— {file.name}: {error}")

                progress_bar.progress((i + 1) / len(uploaded_files))

            status_text.text("ì—…ë¡œë“œ ì™„ë£Œ!")
            time.sleep(1)
            st.rerun()
```

### ì‹¤í–‰ ë°©ë²•

```bash
# Streamlit ì‹¤í–‰
uv run python -m streamlit run web_app.py

# ë˜ëŠ” ì „í†µì ì¸ ë°©ì‹
streamlit run web_app.py
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8501`ë¡œ ì ‘ì†í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì¸í„°í˜ì´ìŠ¤ê°€ í‘œì‹œë©ë‹ˆë‹¤:

### ì‹¤ì œ êµ¬í˜„ í™”ë©´

<strong>1. ë©”ì¸ í™”ë©´ ë° Store ìƒì„±</strong>

![Gemini File Search ë©”ì¸ í™”ë©´](../../../assets/gemini-file-search/gemini-file-search-1.png)

ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ê³ , Storeë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Store ì´ë¦„ì„ ì…ë ¥í•˜ê³  "generation" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ìƒˆë¡œìš´ File Search Storeê°€ ìƒì„±ë©ë‹ˆë‹¤.

<strong>2. íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤</strong>

![íŒŒì¼ ì—…ë¡œë“œ í™”ë©´](../../../assets/gemini-file-search/gemini-file-search-2.png)

"File Upload" íƒ­ì—ì„œ ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDF, TXT, DOCX, Markdown, CSV ë“± ë‹¤ì–‘í•œ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.

<strong>3. ì§ˆì˜ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤</strong>

![ì§ˆì˜ì‘ë‹µ í™”ë©´](../../../assets/gemini-file-search/gemini-file-search-3.png)

"Q&A" íƒ­ì—ì„œ ì—…ë¡œë“œí•œ ë¬¸ì„œì— ëŒ€í•´ ìì—°ì–´ë¡œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ëŒ€í™”ê°€ ì§„í–‰ë˜ë©°, ì¸ìš© ì¶œì²˜ë„ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤.

<strong>4. Store ê´€ë¦¬ ë° íŒŒì¼ ëª©ë¡</strong>

![Store ê´€ë¦¬](../../../assets/gemini-file-search/gemini-file-search-4.png)

í˜„ì¬ ì„ íƒëœ Storeì˜ ì •ë³´ì™€ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<strong>5. ì§ˆì˜ì‘ë‹µ ê²°ê³¼ ì˜ˆì‹œ</strong>

![ì§ˆì˜ì‘ë‹µ ê²°ê³¼](../../../assets/gemini-file-search/gemini-file-search-5.png)

ì‹¤ì œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ í‘œì‹œë˜ë©°, ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ë¬¸ì„œ ì¶œì²˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- âœ… API í‚¤ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
- âœ… File Search Store ìƒì„± ë° ê´€ë¦¬
- âœ… íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì§€ì›)
- âœ… ëŒ€í™”í˜• ì§ˆì˜ì‘ë‹µ (ì±„íŒ… ì¸í„°í˜ì´ìŠ¤)
- âœ… ì¸ìš© ì¶œì²˜ í‘œì‹œ
- âœ… ì—…ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ

## ê¸°ì¡´ ì†”ë£¨ì…˜ê³¼ì˜ ë¹„êµ

### OpenAI Assistants File Search vs Gemini File Search

| íŠ¹ì§• | OpenAI Assistants | Gemini File Search |
|------|-------------------|-------------------|
| <strong>ì§€ì› íŒŒì¼ í˜•ì‹</strong> | 20+ ì¢…ë¥˜ | 300+ ì¢…ë¥˜ |
| <strong>ìµœëŒ€ íŒŒì¼ í¬ê¸°</strong> | 512MB | 100MB |
| <strong>ë¬´ë£Œ ì¿¼ë¦¬ ì„ë² ë”©</strong> | âœ— | âœ“ |
| <strong>ì²­í‚¹ ì»¤ìŠ¤í„°ë§ˆì´ì§•</strong> | ì œí•œì  | ì„¸ë°€í•œ ì œì–´ |
| <strong>ë©”íƒ€ë°ì´í„° í•„í„°ë§</strong> | âœ“ | âœ“ (í–¥í›„ ê°•í™” ì˜ˆì •) |
| <strong>ê°€ê²© (ì¸ë±ì‹±)</strong> | $0.10 / GB/day | $0.15 / 1M í† í° |
| <strong>ëª¨ë¸ ì„±ëŠ¥</strong> | GPT-4 Turbo | Gemini 2.5 Pro/Flash |

### LangChain + Vector DB vs Managed RAG

| ì¸¡ë©´ | ìì²´ êµ¬ì¶• (LangChain) | Gemini File Search |
|------|---------------------|-------------------|
| <strong>ì„¤ì • ë³µì¡ë„</strong> | ë†’ìŒ (ì²­í‚¹, ì„ë² ë”©, ë²¡í„° DB ì„¤ì •) | ë‚®ìŒ (íŒŒì¼ ì—…ë¡œë“œë§Œ) |
| <strong>ê°œë°œ ì‹œê°„</strong> | ë©°ì¹ ã€œëª‡ ì£¼ | ëª‡ ë¶„ |
| <strong>ìœ ì§€ë³´ìˆ˜</strong> | ì§€ì†ì  ê´€ë¦¬ í•„ìš” | Googleì´ ê´€ë¦¬ |
| <strong>ìŠ¤ì¼€ì¼ë§</strong> | ìˆ˜ë™ ìŠ¤ì¼€ì¼ë§ | ìë™ ìŠ¤ì¼€ì¼ë§ |
| <strong>ë¹„ìš© ì˜ˆì¸¡</strong> | ë³µì¡ (ì¸í”„ë¼ + ìš´ì˜) | ëª…í™• (ì‚¬ìš©ëŸ‰ ê¸°ë°˜) |
| <strong>ì»¤ìŠ¤í„°ë§ˆì´ì§•</strong> | ì™„ì „í•œ ì œì–´ | ì œí•œì  ì œì–´ |
| <strong>ì‹œì‘ ë¹„ìš©</strong> | ë†’ìŒ (í•™ìŠµ ê³¡ì„ ) | ë‚®ìŒ (ì¦‰ì‹œ ì‹œì‘) |

### ì–¸ì œ ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?

<strong>Gemini File Searchë¥¼ ì„ íƒí•˜ì„¸ìš”</strong>:
- âœ… ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ë° MVP ê°œë°œ
- âœ… ì†Œê·œëª¨ã€œì¤‘ê·œëª¨ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
- âœ… ê°œë°œ ë¦¬ì†ŒìŠ¤ê°€ ì œí•œì ì¸ ê²½ìš°
- âœ… ì¸í”„ë¼ ê´€ë¦¬ë¥¼ ìµœì†Œí™”í•˜ê³  ì‹¶ì€ ê²½ìš°

<strong>ìì²´ êµ¬ì¶•ì„ ê³ ë ¤í•˜ì„¸ìš”</strong>:
- âœ… ì™„ì „í•œ ì œì–´ì™€ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ í•„ìš”í•œ ê²½ìš°
- âœ… íŠ¹ìˆ˜í•œ ì„ë² ë”© ëª¨ë¸ì´ í•„ìš”í•œ ê²½ìš°
- âœ… ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬ê°€ í•„ìˆ˜ì¸ ê²½ìš°
- âœ… ê·¹ë„ë¡œ í° ê·œëª¨ì˜ ë¬¸ì„œ (ìˆ˜ë°± GB ì´ìƒ)

## ì‹¤ì „ í™œìš© ì‚¬ë¡€

### 1. ê³ ê° ì§€ì› ì‹œìŠ¤í…œ

<strong>ì‹œë‚˜ë¦¬ì˜¤</strong>: SaaS ì œí’ˆì˜ FAQ ë° ê¸°ìˆ  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ 24/7 ìë™ ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•

```python
# Store ìƒì„±
support_store = client.file_search_stores.create(
    config={'display_name': 'Customer Support KB'}
)

# FAQ ë¬¸ì„œ ì—…ë¡œë“œ (ì§§ì€ ì²­í¬ ì‚¬ìš©)
faq_files = ['general_faq.pdf', 'technical_faq.pdf', 'billing_faq.pdf']

for faq in faq_files:
    operation = client.file_search_stores.upload_to_file_search_store(
        file=faq,
        file_search_store_name=support_store.name,
        config={
            'chunking_config': {
                'white_space_config': {
                    'max_tokens_per_chunk': 200,  # FAQëŠ” ì§§ì€ ë‹µë³€
                    'max_overlap_tokens': 20
                }
            }
        }
    )
    # ì™„ë£Œ ëŒ€ê¸°...

# ê³ ê° ì§ˆë¬¸ ì²˜ë¦¬
def answer_customer(question):
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=f"""ê³ ê° ì§ˆë¬¸: {question}

        ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ FAQ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
        1. ê°„ê²°í•˜ê³  ëª…í™•í•œ ë‹µë³€
        2. ê´€ë ¨ ë¬¸ì„œ ë§í¬ (ìˆë‹¤ë©´)
        3. ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•œ ê²½ìš° ì•ˆë‚´
        """,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    file_search=types.FileSearch(
                        file_search_store_names=[support_store.name]
                    )
                )
            ],
            temperature=0.2  # ì¼ê´€ëœ ë‹µë³€
        )
    )
    return response.text
```

<strong>ì˜ˆìƒ íš¨ê³¼</strong>:
- ğŸ“‰ ê³ ê° ì§€ì› í‹°ì¼“ 30ã€œ50% ê°ì†Œ
- âš¡ í‰ê·  ì‘ë‹µ ì‹œê°„ ëª‡ ì‹œê°„ â†’ ëª‡ ì´ˆ
- ğŸ’° ì—°ê°„ ìˆ˜ë°±ë§Œ ì›ì˜ ì¸ê±´ë¹„ ì ˆê°

### 2. ì—°êµ¬ ë…¼ë¬¸ ë¶„ì„

<strong>ì‹œë‚˜ë¦¬ì˜¤</strong>: íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ìˆ˜ì‹­ í¸ì˜ ë…¼ë¬¸ì„ ì—…ë¡œë“œí•˜ê³  ì¢…í•© ë¶„ì„

```python
# ì—°êµ¬ Store ìƒì„±
research_store = client.file_search_stores.create(
    config={'display_name': 'AI Research Papers 2024-2025'}
)

# ë…¼ë¬¸ í´ë”ì—ì„œ PDF ì¼ê´„ ì—…ë¡œë“œ
import os
papers_dir = './papers'
pdf_files = [f for f in os.listdir(papers_dir) if f.endswith('.pdf')]

for pdf in pdf_files:
    operation = client.file_search_stores.upload_to_file_search_store(
        file=os.path.join(papers_dir, pdf),
        file_search_store_name=research_store.name,
        config={
            'display_name': pdf,
            'chunking_config': {
                'white_space_config': {
                    'max_tokens_per_chunk': 600,  # ë…¼ë¬¸ì€ ê¸´ ë§¥ë½
                    'max_overlap_tokens': 60
                }
            },
            'custom_metadata': [
                {'key': 'type', 'string_value': 'research_paper'},
                {'key': 'year', 'numeric_value': 2025}
            ]
        }
    )
    # ì™„ë£Œ ëŒ€ê¸°...

# ë¬¸í—Œ ê²€í†  ì¿¼ë¦¬
def literature_review(topic):
    prompt = f"""
    ì£¼ì œ: {topic}

    ì—…ë¡œë“œëœ ì—°êµ¬ ë…¼ë¬¸ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

    1. <strong>ì—°êµ¬ ë™í–¥</strong>: ì´ ì£¼ì œì˜ ìµœê·¼ ì—°êµ¬ íë¦„
    2. <strong>ì£¼ìš” ë°©ë²•ë¡ </strong>: ê° ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ì ‘ê·¼ë²•
    3. <strong>ê³µí†µì ê³¼ ì°¨ì´ì </strong>: ì—°êµ¬ë“¤ ê°„ì˜ ë¹„êµ ë¶„ì„
    4. <strong>ì—°êµ¬ ê°­</strong>: ì•„ì§ ë‹¤ë£¨ì§€ ì•Šì€ ì˜ì—­
    5. <strong>í–¥í›„ ë°©í–¥</strong>: ì œì•ˆë˜ëŠ” ì—°êµ¬ ì£¼ì œ

    ê° í•­ëª©ë§ˆë‹¤ ê´€ë ¨ ë…¼ë¬¸ì„ ì¸ìš©í•´ì£¼ì„¸ìš”.
    """

    response = client.models.generate_content(
        model="gemini-2.5-pro",  # ë³µì¡í•œ ë¶„ì„ì€ Pro ëª¨ë¸
        contents=prompt,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    file_search=types.FileSearch(
                        file_search_store_names=[research_store.name]
                    )
                )
            ],
            temperature=0.3
        )
    )
    return response.text

# ì‚¬ìš©
review = literature_review("Transformer ì•„í‚¤í…ì²˜ì˜ íš¨ìœ¨ì„± ê°œì„ ")
print(review)
```

<strong>ì˜ˆìƒ íš¨ê³¼</strong>:
- ğŸ“š ìˆ˜ì‹­ í¸ì˜ ë…¼ë¬¸ì„ ëª‡ ë¶„ ë§Œì— ë¶„ì„
- ğŸ” ìˆ¨ê²¨ì§„ íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë°œê²¬
- ğŸ“ ë¬¸í—Œ ê²€í†  ì‘ì„± ì‹œê°„ 80% ë‹¨ì¶•

### 3. ê¸°ì—… ì§€ì‹ ê´€ë¦¬

<strong>ì‹œë‚˜ë¦¬ì˜¤</strong>: ë¶€ì„œë³„ ë¬¸ì„œë¥¼ í†µí•© ê´€ë¦¬í•˜ê³  ì „ì‚¬ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•

```python
# ë¶€ì„œë³„ Store ìƒì„±
departments = ['Engineering', 'Marketing', 'Sales', 'HR']
stores = {}

for dept in departments:
    store = client.file_search_stores.create(
        config={'display_name': f'{dept} Knowledge Base'}
    )
    stores[dept] = store

# í†µí•© ê²€ìƒ‰ í•¨ìˆ˜
def search_company_knowledge(question, departments=None):
    """ì „ì‚¬ ë˜ëŠ” íŠ¹ì • ë¶€ì„œ ê²€ìƒ‰"""
    if departments is None:
        departments = list(stores.keys())

    store_names = [stores[dept].name for dept in departments]

    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=question,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    file_search=types.FileSearch(
                        file_search_store_names=store_names
                    )
                )
            ]
        )
    )
    return response.text

# ì‚¬ìš© ì˜ˆì‹œ
# ì „ì‚¬ ê²€ìƒ‰
answer = search_company_knowledge("ì‹ ì… ì‚¬ì› ì˜¨ë³´ë”© ì ˆì°¨ëŠ”?")

# íŠ¹ì • ë¶€ì„œë§Œ ê²€ìƒ‰
answer = search_company_knowledge(
    "API ì¸ì¦ ë°©ë²•ì€?",
    departments=['Engineering']
)
```

<strong>ì˜ˆìƒ íš¨ê³¼</strong>:
- ğŸš€ ì •ë³´ ê²€ìƒ‰ ì‹œê°„ 90% ë‹¨ì¶•
- ğŸ¤ ë¶€ì„œ ê°„ ì§€ì‹ ê³µìœ  í™œì„±í™”
- ğŸ’¡ ìˆ¨ê²¨ì§„ ì •ë³´ ìì‚° í™œìš©

### 4. ê¸°ìˆ  ë¬¸ì„œ ê²€ìƒ‰

<strong>ì‹œë‚˜ë¦¬ì˜¤</strong>: ëŒ€ê·œëª¨ ì½”ë“œë² ì´ìŠ¤ì˜ ë¬¸ì„œí™” ë° ê°œë°œì ì§€ì›

```python
# ì½”ë“œë² ì´ìŠ¤ ë¬¸ì„œ Store
docs_store = client.file_search_stores.create(
    config={'display_name': 'Codebase Documentation'}
)

# ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ ì—…ë¡œë“œ
doc_types = {
    'api_docs': ['*.md', '*.rst'],
    'code_comments': ['*.py', '*.js', '*.go'],
    'config': ['*.yaml', '*.json', '*.toml']
}

# ê°œë°œì ì§ˆë¬¸ ì²˜ë¦¬
def ask_codebase(question):
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=f"""
        ê°œë°œì ì§ˆë¬¸: {question}

        ì½”ë“œë² ì´ìŠ¤ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:
        1. ì§ì ‘ì ì¸ ë‹µë³€
        2. ê´€ë ¨ ì½”ë“œ ì˜ˆì œ (ìˆë‹¤ë©´)
        3. ì°¸ê³ í•  ë¬¸ì„œ ë§í¬
        4. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
        """,
        config=types.GenerateContentConfig(
            tools=[
                types.Tool(
                    file_search=types.FileSearch(
                        file_search_store_names=[docs_store.name]
                    )
                )
            ]
        )
    )
    return response.text
```

## ì œí•œ ì‚¬í•­ ë° ê³ ë ¤ì‚¬í•­

### í˜„ì¬ ì œí•œ

| í•­ëª© | ì œí•œ | ë¹„ê³  |
|------|------|------|
| <strong>ìµœëŒ€ íŒŒì¼ í¬ê¸°</strong> | 100 MB/íŒŒì¼ | ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ë¶„í•  í•„ìš” |
| <strong>ì €ì¥ì†Œ í¬ê¸° (Free)</strong> | 1 GB | í”„ë¡œë•ì…˜ì€ ìœ ë£Œ í”Œëœ ê¶Œì¥ |
| <strong>ì €ì¥ì†Œ í¬ê¸° (Tier 1)</strong> | 10 GB | ì¤‘ì†Œê¸°ì—… ì í•© |
| <strong>ì €ì¥ì†Œ í¬ê¸° (Tier 2)</strong> | 100 GB | ëŒ€ê¸°ì—… ì í•© |
| <strong>ì €ì¥ì†Œ í¬ê¸° (Tier 3)</strong> | 1 TB | ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ |
| <strong>ê¶Œì¥ Store í¬ê¸°</strong> | < 20 GB | ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™” |
| <strong>ì›ë³¸ íŒŒì¼ ë³´ì¡´</strong> | 48ì‹œê°„ | ì´í›„ ìë™ ì‚­ì œ |

### ì£¼ì˜ì‚¬í•­

<strong>1. ë°ì´í„° ë³´ì•ˆ</strong>

- íŒŒì¼ì€ Google ì„œë²„ì— ì €ì¥ë©ë‹ˆë‹¤
- ë¯¼ê°í•œ ë°ì´í„°ëŠ” ì•”í˜¸í™” ë˜ëŠ” ë§ˆìŠ¤í‚¹ í›„ ì—…ë¡œë“œ
- ë°ì´í„° ì£¼ê¶Œ ì´ìŠˆ (íŠ¹ì • êµ­ê°€ì˜ ë²•ì  ìš”êµ¬ì‚¬í•­) í™•ì¸ í•„ìš”

<strong>2. ë¹„ìš© ê´€ë¦¬</strong>

```python
# ì¸ë±ì‹± ë¹„ìš© ì˜ˆì¸¡
ë¬¸ì„œ í¬ê¸° = 10 MB
í† í° ìˆ˜ â‰ˆ 10 MB Ã— 1,000,000 bytes Ã— 0.3 tokens/byte â‰ˆ 3M í† í°
ë¹„ìš© = 3M Ã— $0.15 / 1M = $0.45
```

- ì¤‘ë³µ ì¸ë±ì‹± ë°©ì§€ (ë™ì¼ íŒŒì¼ ì¬ì—…ë¡œë“œ ì£¼ì˜)
- ì •ê¸°ì ì¸ Store ì •ë¦¬ (ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ)
- ìºì‹± ì „ëµ ê³ ë ¤ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì€ ìºì‹œ)

<strong>3. Rate Limits</strong>

API í˜¸ì¶œì—ëŠ” ì†ë„ ì œí•œì´ ìˆìŠµë‹ˆë‹¤:
- ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì œí•œ
- ë™ì‹œ ì—…ë¡œë“œ ì œí•œ
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ êµ¬í˜„ ê¶Œì¥

```python
import time
from google.api_core.exceptions import ResourceExhausted

def upload_with_retry(file, store_name, max_retries=3):
    for attempt in range(max_retries):
        try:
            operation = client.file_search_stores.upload_to_file_search_store(
                file=file,
                file_search_store_name=store_name
            )
            return operation

        except ResourceExhausted:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1s, 2s, 4s
                print(f"Rate limited. Retrying in {wait_time}s...")
                time.sleep(wait_time)
            else:
                raise
```

<strong>4. ê²€ìƒ‰ í’ˆì§ˆ ìµœì í™”</strong>

ê²€ìƒ‰ ê²°ê³¼ê°€ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì„ ë•Œ:

```python
# 1. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ ì‘ì„±
ë‚˜ìœ ì˜ˆ: "ì„¤ì¹˜ ë°©ë²•ì€?"
ì¢‹ì€ ì˜ˆ: "Linux Ubuntu 22.04ì—ì„œ Dockerë¥¼ ì‚¬ìš©í•œ ì´ˆê¸° ì„¤ì¹˜ ì ˆì°¨ëŠ”?"

# 2. ì²­í‚¹ í¬ê¸° ì¡°ì •
config={
    'chunking_config': {
        'white_space_config': {
            'max_tokens_per_chunk': 200,  # ê¸°ë³¸ 400ì—ì„œ ê°ì†Œ
            'max_overlap_tokens': 40      # ì˜¤ë²„ë© ì¦ê°€
        }
    }
}

# 3. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
prompt = f"""
ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ì •ë°€í•˜ê²Œ ê²€ìƒ‰í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ìš”êµ¬ì‚¬í•­:
- ë¬¸ì„œì˜ ì •í™•í•œ ë‚´ìš©ë§Œ ì‚¬ìš©í•  ê²ƒ
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ì§€ì‹ì€ ë°°ì œí•  ê²ƒ
- ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•  ê²ƒ
- ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•  ê²ƒ
"""
```

### ê°€ê²© ì •ì±…

| í•­ëª© | ê°€ê²© | ì„¤ëª… |
|------|------|------|
| <strong>ì¸ë±ì‹± (ì„ë² ë”© ìƒì„±)</strong> | $0.15 / 1M í† í° | íŒŒì¼ ì—…ë¡œë“œ ì‹œ 1íšŒ |
| <strong>ìŠ¤í† ë¦¬ì§€</strong> | ë¬´ë£Œ | í˜„ì¬ ë¬´ë£Œ (í–¥í›„ ë³€ê²½ ê°€ëŠ¥) |
| <strong>ì¿¼ë¦¬ ì„ë² ë”©</strong> | ë¬´ë£Œ | ì§ˆë¬¸ ì‹œ ì„ë² ë”© ìƒì„± ë¬´ë£Œ |
| <strong>ê²€ìƒ‰ëœ í† í°</strong> | í‘œì¤€ ìš”ê¸ˆ | ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©ëœ í† í° |
| <strong>ìƒì„± í† í°</strong> | í‘œì¤€ ìš”ê¸ˆ | Gemini ëª¨ë¸ ì¶œë ¥ |

<strong>ë¹„ìš© ì ˆê° íŒ</strong>:
- ë™ì¼ íŒŒì¼ ì¬ì¸ë±ì‹± ë°©ì§€
- ë¶ˆí•„ìš”í•œ ë¬¸ì„œ ì •ë¦¬
- ì ì ˆí•œ ì²­í¬ í¬ê¸° ì„¤ì • (ë„ˆë¬´ ì‘ìœ¼ë©´ ë¹„ìš© ì¦ê°€)
- ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±

## ê²°ë¡ 

Google Gemini File Search Toolì€ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì˜ <strong>íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜</strong>ì…ë‹ˆë‹¤. ë³µì¡í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •, ì„ë² ë”© ê´€ë¦¬, ì¸í”„ë¼ ìŠ¤ì¼€ì¼ë§ ë“±ì˜ ê³ ë¯¼ ì—†ì´, íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë°”ë¡œ ì§ˆë¬¸í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ ì¥ì  ìš”ì•½

âœ… <strong>ì§„ì… ì¥ë²½ ì œê±°</strong>: ë©°ì¹  ê±¸ë¦¬ë˜ ì„¤ì •ì´ ëª‡ ë¶„ìœ¼ë¡œ ë‹¨ì¶•
âœ… <strong>ë¹„ìš© íš¨ìœ¨ì„±</strong>: ì¸í”„ë¼ ë¹„ìš© ì—†ì´ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê³¼ê¸ˆ
âœ… <strong>ìë™ ìŠ¤ì¼€ì¼ë§</strong>: Googleì´ ì¸í”„ë¼ ê´€ë¦¬
âœ… <strong>ê´‘ë²”ìœ„í•œ ì§€ì›</strong>: 300+ íŒŒì¼ í˜•ì‹
âœ… <strong>ë†’ì€ í’ˆì§ˆ</strong>: Gemini ëª¨ë¸ì˜ ê°•ë ¥í•œ ì´í•´ë ¥

### í–¥í›„ ì „ë§

Googleì€ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„  ì‚¬í•­ì„ ë¡œë“œë§µì— í¬í•¨í–ˆìŠµë‹ˆë‹¤:

- ğŸ” ê³ ê¸‰ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¿¼ë¦¬
- ğŸ“Š ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ (ì´ë¯¸ì§€, í‘œ ì¸ì‹)
- âš¡ ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ì¦ë¶„ ì¸ë±ì‹±)
- ğŸŒ ë” ë§ì€ íŒŒì¼ í˜•ì‹ ì§€ì›

### ì‹œì‘í•´ë³´ì„¸ìš”!

RAG ì‹œìŠ¤í…œì´ í•„ìš”í•˜ë‹¤ë©´, ë” ì´ìƒ ë³µì¡í•œ êµ¬ì¶• ê³¼ì •ì„ ê±°ì¹  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ê³ , 5ë¶„ ë§Œì— ì²« ë²ˆì§¸ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”.

```bash
# ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ê¸°
pip install google-genai
export GEMINI_API_KEY="your-key"
python your_first_rag.py
```

<strong>ë¬¸ì„œ ê²€ìƒ‰ì˜ ë¯¸ë˜ëŠ” ì´ë¯¸ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. ğŸš€</strong>

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [File Search ê³µì‹ ë¬¸ì„œ](https://ai.google.dev/gemini-api/docs/file-search)
- [File Search API ë ˆí¼ëŸ°ìŠ¤](https://ai.google.dev/api/file-search/file-search-stores)
- [Google AI Studio](https://aistudio.google.com)
- [ê³µì‹ ë°œí‘œ ë¸”ë¡œê·¸](https://blog.google/technology/developers/file-search-gemini-api/)

### ê´€ë ¨ ê¸°ìˆ 
- [RAG ê°œë… ë…¼ë¬¸](https://arxiv.org/abs/2005.11401)
- [Semantic Search ì´í•´](https://en.wikipedia.org/wiki/Semantic_search)
- [Vector Databases ê°€ì´ë“œ](https://www.pinecone.io/learn/vector-database/)

### GitHub ì €ì¥ì†Œ
- [Gemini API Python SDK](https://github.com/google-gemini/generative-ai-python)
- [ì˜ˆì œ ì½”ë“œ ëª¨ìŒ](https://github.com/google-gemini/cookbook)
